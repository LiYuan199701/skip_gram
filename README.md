# Distributed Representations of Words and Phrases and their Compositionality
Transformers paper presentation

## Overview

### The problem the paper is addressing:

How to train distributed representations of words and phrases with Skip-gram model.

### Characterise the approach:

Skip-gram models computes the probability for each word of appearing in the context independently of its distance to the center word.


<img width="968" alt="Screen Shot 2022-03-28 at 12 30 18 PM" src="https://user-images.githubusercontent.com/65924566/160454237-4d3afb9e-10b5-4efd-9adb-8ee58ccacd5e.png">

## The diagram of Skip-gram architecture:

<img width="1103" alt="Screen Shot 2022-03-28 at 12 31 49 PM" src="https://user-images.githubusercontent.com/65924566/160454469-e44ab701-7cff-4a35-8502-f28d116560ce.png">

## Discussion Topic 1:

<img width="999" alt="Screen Shot 2022-03-28 at 12 33 52 PM" src="https://user-images.githubusercontent.com/65924566/160454797-11e92c4f-6e29-4e7c-80eb-e53b97bf4be1.png">

## Discussion Topic 2:

<img width="1011" alt="Screen Shot 2022-03-28 at 12 34 49 PM" src="https://user-images.githubusercontent.com/65924566/160454936-2a091962-dcc9-44dd-adb3-5bda86defdd6.png">

<img width="1051" alt="Screen Shot 2022-03-28 at 12 35 05 PM" src="https://user-images.githubusercontent.com/65924566/160454969-61f91d82-3f9e-437a-aec4-8b4f85addb29.png">

## Discussion Topic 3:

<img width="1010" alt="Screen Shot 2022-03-28 at 12 37 12 PM" src="https://user-images.githubusercontent.com/65924566/160455270-aaccc1f0-4c72-4c14-9d9f-91dde66755ab.png">

<img width="1115" alt="Screen Shot 2022-03-28 at 12 36 57 PM" src="https://user-images.githubusercontent.com/65924566/160455241-7117353c-f6ad-4c61-a4c6-1be4b377affd.png">


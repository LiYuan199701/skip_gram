{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Word2Vec Model\n",
    "==============\n",
    "\n",
    "Introduces Gensim's Word2Vec model and demonstrates its use on the `Lee Evaluation Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you missed the buzz, Word2Vec is a widely used algorithm based on neural\n",
    "networks, commonly referred to as \"deep learning\" (though word2vec itself is rather shallow).\n",
    "Using large amounts of unannotated plain text, word2vec learns relationships\n",
    "between words automatically. The output are vectors, one vector per word,\n",
    "with remarkable linear relationships that allow us to do things like:\n",
    "\n",
    "* vec(\"king\") - vec(\"man\") + vec(\"woman\") =~ vec(\"queen\")\n",
    "* vec(\"Montreal Canadiens\") – vec(\"Montreal\") + vec(\"Toronto\") =~ vec(\"Toronto Maple Leafs\").\n",
    "\n",
    "Word2vec is very useful in `automatic text tagging\n",
    "<https://github.com/RaRe-Technologies/movie-plots-by-genre>`_\\ , recommender\n",
    "systems and machine translation.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "#. Introduces ``Word2Vec`` as an improvement over traditional bag-of-words\n",
    "#. Shows off a demo of ``Word2Vec`` using a pre-trained model\n",
    "#. Demonstrates training a new model from your own data\n",
    "#. Demonstrates loading and saving models\n",
    "#. Introduces several training parameters and demonstrates their effect\n",
    "#. Discusses memory requirements\n",
    "#. Visualizes Word2Vec embeddings by applying dimensionality reduction\n",
    "\n",
    "Review: Bag-of-words\n",
    "--------------------\n",
    "\n",
    ".. Note:: Feel free to skip these review sections if you're already familiar with the models.\n",
    "\n",
    "You may be familiar with the `bag-of-words model\n",
    "<https://en.wikipedia.org/wiki/Bag-of-words_model>`_ from the\n",
    "`core_concepts_vector` section.\n",
    "This model transforms each document to a fixed-length vector of integers.\n",
    "For example, given the sentences:\n",
    "\n",
    "- ``John likes to watch movies. Mary likes movies too.``\n",
    "- ``John also likes to watch football games. Mary hates football.``\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "- ``[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]``\n",
    "- ``[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]``\n",
    "\n",
    "Each vector has 10 elements, where each element counts the number of times a\n",
    "particular word occurred in the document.\n",
    "The order of elements is arbitrary.\n",
    "In the example above, the order of the elements corresponds to the words:\n",
    "``[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]``.\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "First, they lose all information about word order: \"John likes Mary\" and\n",
    "\"Mary likes John\" correspond to identical vectors. There is a solution: bag\n",
    "of `n-grams <https://en.wikipedia.org/wiki/N-gram>`__\n",
    "models consider word phrases of length n to represent documents as\n",
    "fixed-length vectors to capture local word order but suffer from data\n",
    "sparsity and high dimensionality.\n",
    "\n",
    "Second, the model does not attempt to learn the meaning of the underlying\n",
    "words, and as a consequence, the distance between vectors doesn't always\n",
    "reflect the difference in meaning.  The ``Word2Vec`` model addresses this\n",
    "second problem.\n",
    "\n",
    "Introducing: the ``Word2Vec`` Model\n",
    "-----------------------------------\n",
    "\n",
    "``Word2Vec`` is a more recent model that embeds words in a lower-dimensional\n",
    "vector space using a shallow neural network. The result is a set of\n",
    "word-vectors where vectors close together in vector space have similar\n",
    "meanings based on context, and word-vectors distant to each other have\n",
    "differing meanings. For example, ``strong`` and ``powerful`` would be close\n",
    "together and ``strong`` and ``Paris`` would be relatively far.\n",
    "\n",
    "The are two versions of this model and :py:class:`~gensim.models.word2vec.Word2Vec`\n",
    "class implements them both:\n",
    "\n",
    "1. Skip-grams (SG)\n",
    "2. Continuous-bag-of-words (CBOW)\n",
    "\n",
    ".. Important::\n",
    "  Don't let the implementation details below scare you.\n",
    "  They're advanced material: if it's too much, then move on to the next section.\n",
    "\n",
    "The `Word2Vec Skip-gram <http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model>`__\n",
    "model, for example, takes in pairs (word1, word2) generated by moving a\n",
    "window across text data, and trains a 1-hidden-layer neural network based on\n",
    "the synthetic task of given an input word, giving us a predicted probability\n",
    "distribution of nearby words to the input. A virtual `one-hot\n",
    "<https://en.wikipedia.org/wiki/One-hot>`__ encoding of words\n",
    "goes through a 'projection layer' to the hidden layer; these projection\n",
    "weights are later interpreted as the word embeddings. So if the hidden layer\n",
    "has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It\n",
    "is also a 1-hidden-layer neural network. The synthetic training task now uses\n",
    "the average of multiple input context words, rather than a single word as in\n",
    "skip-gram, to predict the center word. Again, the projection weights that\n",
    "turn one-hot words into averageable vectors, of the same width as the hidden\n",
    "layer, are interpreted as the word embeddings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Demo\n",
    "-------------\n",
    "\n",
    "To see what ``Word2Vec`` can do, let's download a pre-trained model and play\n",
    "around with it. We will fetch the Word2Vec model trained on part of the\n",
    "Google News dataset, covering approximately 3 million words and phrases. Such\n",
    "a model can take hours to train, but since it's already available,\n",
    "downloading and loading it with Gensim takes minutes.\n",
    "\n",
    ".. Important::\n",
    "  The model is approximately 2GB, so you'll need a decent network connection\n",
    "  to proceed.  Otherwise, skip ahead to the \"Training Your Own Model\" section\n",
    "  below.\n",
    "\n",
    "You may also check out an `online word2vec demo\n",
    "<http://radimrehurek.com/2014/02/word2vec-tutorial/#app>`_ where you can try\n",
    "this vector algebra for yourself. That demo runs ``word2vec`` on the\n",
    "**entire** Google News dataset, of **about 100 billion words**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:13:40,933 : INFO : loading projection weights from /Users/liyuan/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2022-04-03 10:14:19,876 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/liyuan/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-04-03T10:14:19.835901', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to retrieve the vocabulary of a model. That is trivial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily obtain vectors for terms the model is familiar with:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model is unable to infer vectors for unfamiliar words.\n",
    "This is one limitation of Word2Vec: if this limitation matters to you, check\n",
    "out the FastText model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, ``Word2Vec`` supports several word similarity tasks out of the\n",
    "box.  You can see how the similarity intuitively decreases as the words get\n",
    "less and less similar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'women'\t'female'\t0.56\n",
      "'women'\t'male'\t0.44\n",
      "'women'\t'human'\t0.18\n",
      "'women'\t'girl'\t0.35\n",
      "'women'\t'adult'\t0.26\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('women', 'female'),   # a minivan is a kind of car\n",
    "    ('women', 'male'),   # still a wheeled vehicle\n",
    "    ('women', 'human'),  # ok, no wheels, but still a vehicle\n",
    "    ('women', 'girl'),    # ... and so on\n",
    "    ('women', 'adult'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 5 most similar words to \"car\" or \"minivan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('females', 0.7311514616012573), ('male', 0.7272859811782837), ('men', 0.6505424380302429), ('Female', 0.6494866013526917), ('Women', 0.6406480669975281)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['women', 'female'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the below does not belong in the sequence?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['women', 'woman', 'female', 'females', 'girl', 'lady', 'gender']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Your Own Model\n",
    "-----------------------\n",
    "\n",
    "To start, you'll need some data for training the model. For the following\n",
    "examples, we'll use the `Lee Evaluation Corpus\n",
    "<https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf>`_\n",
    "(which you `already have\n",
    "<https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/lee_background.cor>`_\n",
    "if you've installed Gensim).\n",
    "\n",
    "This corpus is small enough to fit entirely in memory, but we'll implement a\n",
    "memory-friendly iterator that reads it line-by-line to demonstrate how you\n",
    "would handle a larger corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:23:53,111 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-03-28 21:23:53,112 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2022-03-28 21:23:53,113 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\", 'datetime': '2022-03-28T21:23:53.113055', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to do any custom preprocessing, e.g. decode a non-standard\n",
    "encoding, lowercase, remove numbers, extract named entities... All of this can\n",
    "be done inside the ``MyCorpus`` iterator and ``word2vec`` doesn’t need to\n",
    "know. All that is required is that the input yields one sentence (list of\n",
    "utf8 words) after another.\n",
    "\n",
    "Let's go ahead and train a model on our corpus.  Don't worry about the\n",
    "training parameters much for now, we'll revisit them later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:25:26,854 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:25:26,855 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:25:26,923 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2022-03-28 21:25:26,924 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:25:26,931 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2022-03-28T21:25:26.930742', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:25:26,932 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2022-03-28T21:25:26.932089', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:25:26,940 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2022-03-28 21:25:26,947 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2022-03-28 21:25:26,947 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2022-03-28T21:25:26.947960', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:25:26,964 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2022-03-28 21:25:26,965 : INFO : resetting layer weights\n",
      "2022-03-28 21:25:26,969 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:25:26.969369', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:25:26,970 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:25:26.970239', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:25:27,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:25:27,047 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:25:27,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:25:27,051 : INFO : EPOCH - 1 : training on 58152 raw words (35868 effective words) took 0.1s, 477351 effective words/s\n",
      "2022-03-28 21:25:27,116 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:25:27,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:25:27,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:25:27,122 : INFO : EPOCH - 2 : training on 58152 raw words (35915 effective words) took 0.1s, 511597 effective words/s\n",
      "2022-03-28 21:25:27,189 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:25:27,190 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:25:27,193 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:25:27,194 : INFO : EPOCH - 3 : training on 58152 raw words (35972 effective words) took 0.1s, 512775 effective words/s\n",
      "2022-03-28 21:25:27,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:25:27,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:25:27,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:25:27,263 : INFO : EPOCH - 4 : training on 58152 raw words (35975 effective words) took 0.1s, 527266 effective words/s\n",
      "2022-03-28 21:25:27,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:25:27,331 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:25:27,332 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:25:27,333 : INFO : EPOCH - 5 : training on 58152 raw words (35934 effective words) took 0.1s, 528015 effective words/s\n",
      "2022-03-28 21:25:27,333 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179664 effective words) took 0.4s, 495012 effective words/s', 'datetime': '2022-03-28T21:25:27.333605', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:25:27,334 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:25:27.334494', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model, we can use it in the same way as in the demo above.\n",
    "\n",
    "The main part of the model is ``model.wv``\\ , where \"wv\" stands for \"word vectors\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vec_king = model.wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the vocabulary works the same way:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading models\n",
    "--------------------------\n",
    "\n",
    "You'll notice that training non-trivial models can take time.  Once you've\n",
    "trained your model and it works as expected, you can save it to disk.  That\n",
    "way, you don't have to spend time training it all over again later.\n",
    "\n",
    "You can store/load models using the standard gensim methods:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:29:01,655 : INFO : Word2Vec lifecycle event {'fname_or_handle': '/var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-03-28T21:29:01.655927', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2022-03-28 21:29:01,656 : INFO : not storing attribute cum_table\n",
      "2022-03-28 21:29:01,660 : INFO : saved /var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848\n",
      "2022-03-28 21:29:01,660 : INFO : loading Word2Vec object from /var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848\n",
      "2022-03-28 21:29:01,663 : INFO : loading wv recursively from /var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848.wv.* with mmap=None\n",
      "2022-03-28 21:29:01,663 : INFO : setting ignored attribute cum_table to None\n",
      "2022-03-28 21:29:01,676 : INFO : Word2Vec lifecycle event {'fname': '/var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848', 'datetime': '2022-03-28T21:29:01.676262', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which uses pickle internally, optionally ``mmap``\\ ‘ing the model’s internal\n",
    "large NumPy matrices into virtual memory directly from disk files, for\n",
    "inter-process memory sharing.\n",
    "\n",
    "In addition, you can load models created by the original C tool, both using\n",
    "its text and binary formats::\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:28:47,233 : INFO : loading projection weights from /tmp/vectors.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/vectors.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-176c4fdd3b6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/vectors.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# using gzipped/bz2 input works too, no need to unzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/vectors.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/vectors.txt'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.txt', binary=False)\n",
    "# using gzipped/bz2 input works too, no need to unzip\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters\n",
    "-------------------\n",
    "\n",
    "``Word2Vec`` accepts several parameters that affect both training speed and quality.\n",
    "\n",
    "min_count\n",
    "---------\n",
    "\n",
    "``min_count`` is for pruning the internal dictionary. Words that appear only\n",
    "once or twice in a billion-word corpus are probably uninteresting typos and\n",
    "garbage. In addition, there’s not enough data to make any meaningful training\n",
    "on those words, so it’s best to ignore them:\n",
    "\n",
    "default value of min_count=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:29:52,648 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:29:52,650 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:29:52,713 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2022-03-28 21:29:52,714 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:29:52,719 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 889 unique words (12.734565248531728%% of original 6981, drops 6092)', 'datetime': '2022-03-28T21:29:52.719105', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:29:52,719 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 43776 word corpus (75.2785802723896%% of original 58152, drops 14376)', 'datetime': '2022-03-28T21:29:52.719685', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:29:52,724 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2022-03-28 21:29:52,724 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2022-03-28 21:29:52,725 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 29691.39528319831 word corpus (67.8%% of prior 43776)', 'datetime': '2022-03-28T21:29:52.725449', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:29:52,732 : INFO : estimated required memory for 889 words and 100 dimensions: 1155700 bytes\n",
      "2022-03-28 21:29:52,732 : INFO : resetting layer weights\n",
      "2022-03-28 21:29:52,733 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:29:52.733884', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:29:52,734 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 889 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:29:52.734389', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:29:52,805 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:29:52,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:29:52,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:29:52,808 : INFO : EPOCH - 1 : training on 58152 raw words (29702 effective words) took 0.1s, 414974 effective words/s\n",
      "2022-03-28 21:29:52,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:29:52,874 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:29:52,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:29:52,877 : INFO : EPOCH - 2 : training on 58152 raw words (29595 effective words) took 0.1s, 437711 effective words/s\n",
      "2022-03-28 21:29:52,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:29:52,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:29:52,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:29:52,946 : INFO : EPOCH - 3 : training on 58152 raw words (29734 effective words) took 0.1s, 441509 effective words/s\n",
      "2022-03-28 21:29:53,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:29:53,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:29:53,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:29:53,017 : INFO : EPOCH - 4 : training on 58152 raw words (29639 effective words) took 0.1s, 428626 effective words/s\n",
      "2022-03-28 21:29:53,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:29:53,084 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:29:53,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:29:53,085 : INFO : EPOCH - 5 : training on 58152 raw words (29711 effective words) took 0.1s, 440409 effective words/s\n",
      "2022-03-28 21:29:53,086 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (148381 effective words) took 0.4s, 422281 effective words/s', 'datetime': '2022-03-28T21:29:53.086193', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:29:53,086 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=889, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:29:53.086642', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector_size\n",
    "-----------\n",
    "\n",
    "``vector_size`` is the number of dimensions (N) of the N-dimensional space that\n",
    "gensim Word2Vec maps the words onto.\n",
    "\n",
    "Bigger size values require more training data, but can lead to better (more\n",
    "accurate) models. Reasonable values are in the tens to hundreds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:30:20,654 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:30:20,655 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:30:20,718 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2022-03-28 21:30:20,719 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:30:20,725 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2022-03-28T21:30:20.724989', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:20,726 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2022-03-28T21:30:20.726429', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:20,735 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2022-03-28 21:30:20,736 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2022-03-28 21:30:20,736 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2022-03-28T21:30:20.736513', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:20,749 : INFO : estimated required memory for 1750 words and 200 dimensions: 3675000 bytes\n",
      "2022-03-28 21:30:20,750 : INFO : resetting layer weights\n",
      "2022-03-28 21:30:20,752 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:30:20.752825', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:30:20,753 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:30:20.753261', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:30:20,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:20,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:20,833 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:20,833 : INFO : EPOCH - 1 : training on 58152 raw words (35868 effective words) took 0.1s, 455442 effective words/s\n",
      "2022-03-28 21:30:20,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:20,902 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:20,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:20,904 : INFO : EPOCH - 2 : training on 58152 raw words (35915 effective words) took 0.1s, 514758 effective words/s\n",
      "2022-03-28 21:30:20,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:20,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:20,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:20,977 : INFO : EPOCH - 3 : training on 58152 raw words (35954 effective words) took 0.1s, 500028 effective words/s\n",
      "2022-03-28 21:30:21,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:21,047 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:21,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:21,050 : INFO : EPOCH - 4 : training on 58152 raw words (35918 effective words) took 0.1s, 503512 effective words/s\n",
      "2022-03-28 21:30:21,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:21,119 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:21,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:21,123 : INFO : EPOCH - 5 : training on 58152 raw words (35905 effective words) took 0.1s, 497954 effective words/s\n",
      "2022-03-28 21:30:21,124 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179560 effective words) took 0.4s, 484704 effective words/s', 'datetime': '2022-03-28T21:30:21.124044', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:30:21,124 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=200, alpha=0.025)', 'datetime': '2022-03-28T21:30:21.124323', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# The default value of vector_size is 100.\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers\n",
    "-------\n",
    "\n",
    "``workers`` , the last of the major parameters (full list `here\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec>`_)\n",
    "is for training parallelization, to speed up training:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:30:59,514 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:30:59,515 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:30:59,585 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2022-03-28 21:30:59,585 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:30:59,591 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1750 unique words (25.068041827818366%% of original 6981, drops 5231)', 'datetime': '2022-03-28T21:30:59.591400', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:59,592 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 49335 word corpus (84.83801073049938%% of original 58152, drops 8817)', 'datetime': '2022-03-28T21:30:59.592046', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:59,600 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2022-03-28 21:30:59,600 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2022-03-28 21:30:59,601 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 35935.33721568072 word corpus (72.8%% of prior 49335)', 'datetime': '2022-03-28T21:30:59.601070', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:30:59,614 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2022-03-28 21:30:59,615 : INFO : resetting layer weights\n",
      "2022-03-28 21:30:59,616 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:30:59.616811', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:30:59,617 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:30:59.617320', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:30:59,683 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-28 21:30:59,685 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:59,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:59,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:59,691 : INFO : EPOCH - 1 : training on 58152 raw words (35883 effective words) took 0.1s, 494615 effective words/s\n",
      "2022-03-28 21:30:59,755 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-28 21:30:59,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:59,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:59,761 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:59,762 : INFO : EPOCH - 2 : training on 58152 raw words (35909 effective words) took 0.1s, 526581 effective words/s\n",
      "2022-03-28 21:30:59,830 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-28 21:30:59,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:59,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:59,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:59,836 : INFO : EPOCH - 3 : training on 58152 raw words (36052 effective words) took 0.1s, 493149 effective words/s\n",
      "2022-03-28 21:30:59,898 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-28 21:30:59,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:59,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:59,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:59,907 : INFO : EPOCH - 4 : training on 58152 raw words (36046 effective words) took 0.1s, 519407 effective words/s\n",
      "2022-03-28 21:30:59,971 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-28 21:30:59,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:30:59,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:30:59,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:30:59,978 : INFO : EPOCH - 5 : training on 58152 raw words (35952 effective words) took 0.1s, 514024 effective words/s\n",
      "2022-03-28 21:30:59,979 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (179842 effective words) took 0.4s, 497533 effective words/s', 'datetime': '2022-03-28T21:30:59.979102', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:30:59,979 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1750, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:30:59.979544', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# default value of workers=3 (tutorial says 1...)\n",
    "model = gensim.models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``workers`` parameter only has an effect if you have `Cython\n",
    "<http://cython.org/>`_ installed. Without Cython, you’ll only be able to use\n",
    "one core because of the `GIL\n",
    "<https://wiki.python.org/moin/GlobalInterpreterLock>`_ (and ``word2vec``\n",
    "training will be `miserably slow\n",
    "<http://rare-technologies.com/word2vec-in-python-part-two-optimizing/>`_\\ ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory\n",
    "------\n",
    "\n",
    "At its core, ``word2vec`` model parameters are stored as matrices (NumPy\n",
    "arrays). Each array is **#vocabulary** (controlled by the ``min_count`` parameter)\n",
    "times **vector size** (the ``vector_size`` parameter) of floats (single precision aka 4 bytes).\n",
    "\n",
    "Three such matrices are held in RAM (work is underway to reduce that number\n",
    "to two, or even one). So if your input contains 100,000 unique words, and you\n",
    "asked for layer ``vector_size=200``\\ , the model will require approx.\n",
    "``100,000*200*4*3 bytes = ~229MB``.\n",
    "\n",
    "There’s a little extra memory needed for storing the vocabulary tree (100,000 words would\n",
    "take a few megabytes), but unless your words are extremely loooong strings, memory\n",
    "footprint will be dominated by the three matrices above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating\n",
    "----------\n",
    "\n",
    "``Word2Vec`` training is an unsupervised task, there’s no good way to\n",
    "objectively evaluate the result. Evaluation depends on your end application.\n",
    "\n",
    "Google has released their testing set of about 20,000 syntactic and semantic\n",
    "test examples, following the “A is to B as C is to D” task. It is provided in\n",
    "the 'datasets' folder.\n",
    "\n",
    "For example a syntactic analogy of comparative type is ``bad:worse;good:?``.\n",
    "There are total of 9 types of syntactic comparisons in the dataset like\n",
    "plural nouns and nouns of opposite meaning.\n",
    "\n",
    "The semantic questions contain five types of semantic analogies, such as\n",
    "capital cities (``Paris:France;Tokyo:?``) or family members\n",
    "(``brother:sister;dad:?``).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim supports the same evaluation set, in exactly the same format:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:32:42,733 : INFO : Evaluating word analogies for top 300000 words in the model on /Users/liyuan/opt/anaconda3/lib/python3.8/site-packages/gensim/test/test_data/questions-words.txt\n",
      "2022-03-28 21:32:42,737 : INFO : capital-common-countries: 0.0% (0/6)\n",
      "2022-03-28 21:32:42,749 : INFO : capital-world: 0.0% (0/2)\n",
      "2022-03-28 21:32:42,763 : INFO : family: 0.0% (0/6)\n",
      "2022-03-28 21:32:42,775 : INFO : gram3-comparative: 0.0% (0/20)\n",
      "2022-03-28 21:32:42,781 : INFO : gram4-superlative: 0.0% (0/12)\n",
      "2022-03-28 21:32:42,787 : INFO : gram5-present-participle: 0.0% (0/20)\n",
      "2022-03-28 21:32:42,796 : INFO : gram6-nationality-adjective: 0.0% (0/30)\n",
      "2022-03-28 21:32:42,802 : INFO : gram7-past-tense: 0.0% (0/20)\n",
      "2022-03-28 21:32:42,811 : INFO : gram8-plural: 0.0% (0/30)\n",
      "2022-03-28 21:32:42,814 : INFO : Quadruplets with out-of-vocabulary words: 99.3%\n",
      "2022-03-28 21:32:42,815 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2022-03-28 21:32:42,816 : INFO : Total accuracy: 0.0% (0/146)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " [{'section': 'capital-common-countries',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n",
       "  {'section': 'capital-world',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n",
       "  {'section': 'currency', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'family',\n",
       "   'correct': [],\n",
       "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER')]},\n",
       "  {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram3-comparative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n",
       "  {'section': 'gram4-superlative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n",
       "  {'section': 'gram5-present-participle',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n",
       "  {'section': 'gram6-nationality-adjective',\n",
       "   'correct': [],\n",
       "   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n",
       "  {'section': 'gram7-past-tense',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n",
       "  {'section': 'gram8-plural',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n",
       "  {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'Total accuracy',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER'),\n",
       "    ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n",
       "    ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
       "    ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n",
       "    ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ``evaluate_word_analogies`` method takes an `optional parameter\n",
    "<http://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.evaluate_word_analogies>`_\n",
    "``restrict_vocab`` which limits which test examples are to be considered.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.\n",
    "\n",
    "By default it uses an academic dataset WS-353 but one can create a dataset\n",
    "specific to your business based on it. It contains word pairs together with\n",
    "human-assigned similarity judgments. It measures the relatedness or\n",
    "co-occurrence of two words. For example, 'coast' and 'shore' are very similar\n",
    "as they appear in the same context. At the same time 'clothes' and 'closet'\n",
    "are less similar because they are related but not interchangeable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:34:03,218 : INFO : Pearson correlation coefficient against /Users/liyuan/opt/anaconda3/lib/python3.8/site-packages/gensim/test/test_data/wordsim353.tsv: 0.1458\n",
      "2022-03-28 21:34:03,219 : INFO : Spearman rank-order correlation coefficient against /Users/liyuan/opt/anaconda3/lib/python3.8/site-packages/gensim/test/test_data/wordsim353.tsv: 0.1144\n",
      "2022-03-28 21:34:03,219 : INFO : Pairs with unknown words ratio: 83.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.1458031958054551, 0.2663180494461411),\n",
       " SpearmanrResult(correlation=0.11435320342982952, pvalue=0.38429946183608577),\n",
       " 83.0028328611898)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Important::\n",
    "  Good performance on Google's or WS-353 test set doesn’t mean word2vec will\n",
    "  work well in your application, or vice versa. It’s always best to evaluate\n",
    "  directly on your intended task. For an example of how to use word2vec in a\n",
    "  classifier pipeline, see this `tutorial\n",
    "  <https://github.com/RaRe-Technologies/movie-plots-by-genre>`_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online training / Resuming training\n",
    "-----------------------------------\n",
    "\n",
    "Advanced users can load a model and continue training it with more sentences\n",
    "and `new vocabulary words <online_w2v_tutorial.ipynb>`_:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:34:57,624 : INFO : loading Word2Vec object from /var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848\n",
      "2022-03-28 21:34:57,628 : INFO : loading wv recursively from /var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848.wv.* with mmap=None\n",
      "2022-03-28 21:34:57,629 : INFO : setting ignored attribute cum_table to None\n",
      "2022-03-28 21:34:57,643 : INFO : Word2Vec lifecycle event {'fname': '/var/folders/5g/qg1r2s0s7k1bx6zh6b6sx7t00000gn/T/gensim-model-729rq848', 'datetime': '2022-03-28T21:34:57.643734', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n",
      "2022-03-28 21:34:57,644 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:34:57,645 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:34:57,645 : INFO : collected 13 word types from a corpus of 13 raw words and 1 sentences\n",
      "2022-03-28 21:34:57,646 : INFO : Updating model with new vocabulary\n",
      "2022-03-28 21:34:57,651 : INFO : Word2Vec lifecycle event {'msg': 'added 0 new unique words (0.0%% of original 13) and increased the count of 0 pre-existing words (0.0%% of original 13)', 'datetime': '2022-03-28T21:34:57.651585', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:34:57,652 : INFO : deleting the raw counts dictionary of 13 items\n",
      "2022-03-28 21:34:57,652 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2022-03-28 21:34:57,652 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 0 word corpus (0.0%% of prior 0)', 'datetime': '2022-03-28T21:34:57.652628', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:34:57,666 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2022-03-28 21:34:57,667 : INFO : updating layer weights\n",
      "2022-03-28 21:34:57,668 : INFO : Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2022-03-28T21:34:57.668172', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:34:57,668 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2022-03-28 21:34:57,669 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:34:57.668997', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:34:57,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:34:57,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:34:57,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:34:57,672 : INFO : EPOCH - 1 : training on 13 raw words (5 effective words) took 0.0s, 3617 effective words/s\n",
      "2022-03-28 21:34:57,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:34:57,673 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:34:57,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:34:57,674 : INFO : EPOCH - 2 : training on 13 raw words (4 effective words) took 0.0s, 3866 effective words/s\n",
      "2022-03-28 21:34:57,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:34:57,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:34:57,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:34:57,676 : INFO : EPOCH - 3 : training on 13 raw words (6 effective words) took 0.0s, 5917 effective words/s\n",
      "2022-03-28 21:34:57,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:34:57,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:34:57,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:34:57,679 : INFO : EPOCH - 4 : training on 13 raw words (6 effective words) took 0.0s, 5590 effective words/s\n",
      "2022-03-28 21:34:57,681 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:34:57,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:34:57,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:34:57,682 : INFO : EPOCH - 5 : training on 13 raw words (7 effective words) took 0.0s, 4293 effective words/s\n",
      "2022-03-28 21:34:57,683 : INFO : Word2Vec lifecycle event {'msg': 'training on 65 raw words (28 effective words) took 0.0s, 1936 effective words/s', 'datetime': '2022-03-28T21:34:57.683806', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences'],\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to tweak the ``total_words`` parameter to ``train()``,\n",
    "depending on what learning rate decay you want to simulate.\n",
    "\n",
    "Note that it’s not possible to resume training with models generated by the C\n",
    "tool, ``KeyedVectors.load_word2vec_format()``. You can still use them for\n",
    "querying/similarity, but information vital for training (the vocab tree) is\n",
    "missing there.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loss Computation\n",
    "-------------------------\n",
    "\n",
    "The parameter ``compute_loss`` can be used to toggle computation of loss\n",
    "while training the Word2Vec model. The computed loss is stored in the model\n",
    "attribute ``running_training_loss`` and can be retrieved using the function\n",
    "``get_latest_training_loss`` as follows :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:35:45,168 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:35:45,170 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:35:45,242 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2022-03-28 21:35:45,242 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:35:45,260 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6981 unique words (100.0%% of original 6981, drops 0)', 'datetime': '2022-03-28T21:35:45.259978', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:35:45,260 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 58152 word corpus (100.0%% of original 58152, drops 0)', 'datetime': '2022-03-28T21:35:45.260529', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:35:45,290 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2022-03-28 21:35:45,290 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2022-03-28 21:35:45,291 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 45723.4541622429 word corpus (78.6%% of prior 58152)', 'datetime': '2022-03-28T21:35:45.291052', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:35:45,341 : INFO : estimated required memory for 6981 words and 100 dimensions: 9075300 bytes\n",
      "2022-03-28 21:35:45,342 : INFO : resetting layer weights\n",
      "2022-03-28 21:35:45,345 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:35:45.345154', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:35:45,345 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 6981 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:35:45.345619', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:35:45,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:35:45,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:35:45,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:35:45,459 : INFO : EPOCH - 1 : training on 58152 raw words (45666 effective words) took 0.1s, 405000 effective words/s\n",
      "2022-03-28 21:35:45,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:35:45,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:35:45,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:35:45,571 : INFO : EPOCH - 2 : training on 58152 raw words (45568 effective words) took 0.1s, 410203 effective words/s\n",
      "2022-03-28 21:35:45,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:35:45,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:35:45,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:35:45,690 : INFO : EPOCH - 3 : training on 58152 raw words (45760 effective words) took 0.1s, 390818 effective words/s\n",
      "2022-03-28 21:35:45,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:35:45,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:35:45,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:35:45,818 : INFO : EPOCH - 4 : training on 58152 raw words (45680 effective words) took 0.1s, 360605 effective words/s\n",
      "2022-03-28 21:35:45,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:35:45,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:35:45,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:35:45,921 : INFO : EPOCH - 5 : training on 58152 raw words (45658 effective words) took 0.1s, 446203 effective words/s\n",
      "2022-03-28 21:35:45,922 : INFO : Word2Vec lifecycle event {'msg': 'training on 290760 raw words (228332 effective words) took 0.6s, 396227 effective words/s', 'datetime': '2022-03-28T21:35:45.922212', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:35:45,922 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=6981, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:35:45.922821', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484671.0\n"
     ]
    }
   ],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "----------\n",
    "\n",
    "Let's run some benchmarks to see effect of the training loss computation code\n",
    "on training time.\n",
    "\n",
    "We'll use the following data for the benchmarks:\n",
    "\n",
    "#. Lee Background corpus: included in gensim's test data\n",
    "#. Text8 corpus.  To demonstrate the effect of corpus size, we'll look at the\n",
    "   first 1MB, 10MB, 50MB of the corpus, as well as the entire thing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:36:34,084 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = datapath('lee_background.cor')\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = api.load('text8').fn\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the training time taken for different combinations of input\n",
    "data and model training parameters like ``hs`` and ``sg``.\n",
    "\n",
    "For each combination, we repeat the test several times to obtain the mean and\n",
    "standard deviation of the test duration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:36:57,900 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:57,901 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:57,915 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:57,915 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:57,922 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:57.922165', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:57,922 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:57.922904', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:57,931 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:57,932 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:57,932 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:57.932445', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:57,946 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:57,947 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:57,948 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:57.948687', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:57,949 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:57.949199', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:57,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:57,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:57,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:57,974 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1333169 effective words/s\n",
      "2022-03-28 21:36:57,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:57,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:57,997 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:57,997 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1517926 effective words/s\n",
      "2022-03-28 21:36:58,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,019 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,020 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1619479 effective words/s\n",
      "2022-03-28 21:36:58,037 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,039 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,042 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,042 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1524261 effective words/s\n",
      "2022-03-28 21:36:58,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,066 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1444740 effective words/s\n",
      "2022-03-28 21:36:58,066 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1386845 effective words/s', 'datetime': '2022-03-28T21:36:58.066934', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,067 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.067250', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,067 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,068 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,082 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,083 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,089 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.089926', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,090 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.090567', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,098 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,099 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,099 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.099664', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,113 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:58,113 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,115 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.115345', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,115 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.115890', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,140 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1466805 effective words/s\n",
      "2022-03-28 21:36:58,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,163 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1491951 effective words/s\n",
      "2022-03-28 21:36:58,180 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,185 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1545633 effective words/s\n",
      "2022-03-28 21:36:58,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,207 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1572230 effective words/s\n",
      "2022-03-28 21:36:58,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,230 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1522892 effective words/s\n",
      "2022-03-28 21:36:58,230 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1426324 effective words/s', 'datetime': '2022-03-28T21:36:58.230678', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,230 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.230956', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,231 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,232 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,246 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,246 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,253 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.253027', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,253 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.253677', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,261 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,262 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,262 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.262914', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,276 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:58,276 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,277 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.277866', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,278 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.278356', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,302 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1458371 effective words/s\n",
      "2022-03-28 21:36:58,320 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,321 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,324 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1514641 effective words/s\n",
      "2022-03-28 21:36:58,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,347 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1508897 effective words/s\n",
      "2022-03-28 21:36:58,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,370 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1512124 effective words/s\n",
      "2022-03-28 21:36:58,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,393 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1500064 effective words/s\n",
      "2022-03-28 21:36:58,394 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1408423 effective words/s', 'datetime': '2022-03-28T21:36:58.394349', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,394 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.394858', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,395 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,396 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,410 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,410 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,417 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.417374', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,418 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.417989', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,426 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,427 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,427 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.427462', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,441 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:58,441 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,442 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.442707', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,443 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.443133', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,467 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1374271 effective words/s\n",
      "2022-03-28 21:36:58,485 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,489 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1584416 effective words/s\n",
      "2022-03-28 21:36:58,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,512 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1536439 effective words/s\n",
      "2022-03-28 21:36:58,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,534 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1589087 effective words/s\n",
      "2022-03-28 21:36:58,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,556 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1572297 effective words/s\n",
      "2022-03-28 21:36:58,556 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1439891 effective words/s', 'datetime': '2022-03-28T21:36:58.556555', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,556 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.556859', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,557 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,558 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,572 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,572 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,579 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.579425', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,580 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.580087', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,587 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,588 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,588 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.588834', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.1650686264038086, 'train_time_std': 0.0018142516672401553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:36:58,602 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:58,603 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,604 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.604271', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,604 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.604655', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,623 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,628 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1433875 effective words/s\n",
      "2022-03-28 21:36:58,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,650 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1601787 effective words/s\n",
      "2022-03-28 21:36:58,667 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,672 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1567163 effective words/s\n",
      "2022-03-28 21:36:58,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,691 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,693 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1619197 effective words/s\n",
      "2022-03-28 21:36:58,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,715 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1596920 effective words/s\n",
      "2022-03-28 21:36:58,715 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1472008 effective words/s', 'datetime': '2022-03-28T21:36:58.715622', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,715 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.715907', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,716 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,717 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,731 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,731 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,738 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.737973', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,738 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.738584', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,746 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,747 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,747 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.747826', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,761 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:36:58,761 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,762 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.762848', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,763 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.763349', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,781 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,783 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,786 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1486116 effective words/s\n",
      "2022-03-28 21:36:58,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,808 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1547852 effective words/s\n",
      "2022-03-28 21:36:58,826 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,831 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1516993 effective words/s\n",
      "2022-03-28 21:36:58,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,856 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1351090 effective words/s\n",
      "2022-03-28 21:36:58,875 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:58,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:58,879 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:58,879 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1485873 effective words/s\n",
      "2022-03-28 21:36:58,880 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.1s, 1396831 effective words/s', 'datetime': '2022-03-28T21:36:58.880258', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:58,880 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:58.880608', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:58,881 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:58,882 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:58,897 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:58,897 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:58,904 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:58.904121', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,904 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:58.904747', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,913 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:58,913 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:58,914 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:58.914147', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:58,915 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:36:58,949 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:36:58,962 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:36:58,963 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:58,964 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:58.964433', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:58,964 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:58.964870', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,008 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 772245 effective words/s\n",
      "2022-03-28 21:36:59,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,048 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 852761 effective words/s\n",
      "2022-03-28 21:36:59,080 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.1618664264678955, 'train_time_std': 0.0022923492558404764}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:36:59,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,088 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 850185 effective words/s\n",
      "2022-03-28 21:36:59,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,122 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,127 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 863068 effective words/s\n",
      "2022-03-28 21:36:59,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,164 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,165 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 898412 effective words/s\n",
      "2022-03-28 21:36:59,165 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 812767 effective words/s', 'datetime': '2022-03-28T21:36:59.165581', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,165 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:59.165900', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:59,166 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:59,167 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:59,180 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:59,181 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:59,187 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:59.187371', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,187 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:59.187974', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,196 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:59,196 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:59,197 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:59.197040', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,198 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:36:59,230 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:36:59,242 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:36:59,243 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:59,244 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:59.244370', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:59,244 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:59.244853', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,280 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,285 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,285 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 823114 effective words/s\n",
      "2022-03-28 21:36:59,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,323 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 897318 effective words/s\n",
      "2022-03-28 21:36:59,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,371 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 701181 effective words/s\n",
      "2022-03-28 21:36:59,402 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,408 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,408 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 900682 effective words/s\n",
      "2022-03-28 21:36:59,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,447 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 884846 effective words/s\n",
      "2022-03-28 21:36:59,447 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 803496 effective words/s', 'datetime': '2022-03-28T21:36:59.447919', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,448 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:59.448251', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:59,449 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:59,450 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:59,463 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:59,464 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:59,470 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:59.470804', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,471 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:59.471429', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,479 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:59,480 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:59,480 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:59.480776', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,481 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:36:59,514 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:36:59,527 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:36:59,527 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:59,528 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:59.528861', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:59,529 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:59.529354', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,570 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 826652 effective words/s\n",
      "2022-03-28 21:36:59,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,609 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 864899 effective words/s\n",
      "2022-03-28 21:36:59,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,647 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 867094 effective words/s\n",
      "2022-03-28 21:36:59,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,686 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 879049 effective words/s\n",
      "2022-03-28 21:36:59,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,725 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 853447 effective words/s\n",
      "2022-03-28 21:36:59,726 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 830656 effective words/s', 'datetime': '2022-03-28T21:36:59.726005', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,726 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:36:59.726326', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:36:59,727 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:36:59,728 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:36:59,741 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:36:59,742 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:36:59,749 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:36:59.749021', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,749 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:36:59.749646', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,757 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:36:59,758 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:36:59,758 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:36:59.758493', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:36:59,759 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:36:59,792 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:36:59,805 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:36:59,806 : INFO : resetting layer weights\n",
      "2022-03-28 21:36:59,807 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:36:59.807246', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:36:59,807 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:36:59.807809', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:36:59,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,858 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 658785 effective words/s\n",
      "2022-03-28 21:36:59,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,893 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,896 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 890324 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.28197193145751953, 'train_time_std': 0.002957810444126415}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:36:59,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,933 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 910519 effective words/s\n",
      "2022-03-28 21:36:59,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:36:59,968 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:36:59,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:36:59,971 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 893561 effective words/s\n",
      "2022-03-28 21:37:00,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,006 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,010 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 876787 effective words/s\n",
      "2022-03-28 21:37:00,010 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 805407 effective words/s', 'datetime': '2022-03-28T21:37:00.010401', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,010 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:00.010737', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:00,011 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:00,012 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:00,026 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:00,027 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:00,034 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:00.034715', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,035 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:00.035368', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,043 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:00,044 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:00,044 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:00.044506', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,045 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:00,077 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:00,090 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:00,091 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:00,092 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:00.092484', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:00,092 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:00.092885', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,124 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,132 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 853258 effective words/s\n",
      "2022-03-28 21:37:00,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,166 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,171 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 860936 effective words/s\n",
      "2022-03-28 21:37:00,202 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,209 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 879579 effective words/s\n",
      "2022-03-28 21:37:00,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,248 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 882018 effective words/s\n",
      "2022-03-28 21:37:00,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,282 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,285 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,285 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 892979 effective words/s\n",
      "2022-03-28 21:37:00,286 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 843738 effective words/s', 'datetime': '2022-03-28T21:37:00.286240', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,286 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:00.286573', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:00,287 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:00,288 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:00,302 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:00,302 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:00,308 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:00.308943', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,309 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:00.309559', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,317 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:00,318 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:00,318 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:00.318659', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,319 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:00,352 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:00,365 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:00,365 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:00,366 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:00.366934', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:00,367 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:00.367376', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,406 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 857538 effective words/s\n",
      "2022-03-28 21:37:00,438 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,440 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,444 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 896197 effective words/s\n",
      "2022-03-28 21:37:00,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,478 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,482 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 888926 effective words/s\n",
      "2022-03-28 21:37:00,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,521 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 881552 effective words/s\n",
      "2022-03-28 21:37:00,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,558 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,558 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 889748 effective words/s\n",
      "2022-03-28 21:37:00,559 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.2s, 851126 effective words/s', 'datetime': '2022-03-28T21:37:00.559183', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,559 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:00.559481', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:00,569 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:00,569 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:00,583 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:00,583 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:00,590 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:00.590185', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,590 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:00.590803', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,598 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:00,599 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:00,599 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:00.599720', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,612 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:00,613 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:00,614 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:00.614675', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:00,615 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:00.615094', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,674 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 559337 effective words/s\n",
      "2022-03-28 21:37:00,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,728 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,732 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 573158 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.28041807810465497, 'train_time_std': 0.003571472845431297}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:00,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,791 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 564728 effective words/s\n",
      "2022-03-28 21:37:00,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,850 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 570816 effective words/s\n",
      "2022-03-28 21:37:00,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:00,905 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:00,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:00,908 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 571155 effective words/s\n",
      "2022-03-28 21:37:00,909 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 554695 effective words/s', 'datetime': '2022-03-28T21:37:00.909044', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:00,909 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:00.909388', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:00,910 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:00,911 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:00,924 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:00,925 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:00,931 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:00.931411', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,931 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:00.931977', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,939 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:00,940 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:00,940 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:00.940951', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:00,953 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:00,954 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:00,955 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:00.955720', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:00,956 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:00.956176', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,015 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 561996 effective words/s\n",
      "2022-03-28 21:37:01,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,073 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 570270 effective words/s\n",
      "2022-03-28 21:37:01,126 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,132 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 567965 effective words/s\n",
      "2022-03-28 21:37:01,184 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,191 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 563616 effective words/s\n",
      "2022-03-28 21:37:01,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,250 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 567644 effective words/s\n",
      "2022-03-28 21:37:01,250 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 554042 effective words/s', 'datetime': '2022-03-28T21:37:01.250500', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,251 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:01.251013', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:01,251 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:01,252 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:01,265 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:01,266 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:01,272 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:01.272686', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,273 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:01.273325', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,281 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:01,281 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:01,282 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:01.282260', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,295 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:01,296 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:01,297 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:01.297358', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:01,297 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:01.297789', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,357 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 558303 effective words/s\n",
      "2022-03-28 21:37:01,410 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,415 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 570039 effective words/s\n",
      "2022-03-28 21:37:01,469 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,470 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,474 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 558723 effective words/s\n",
      "2022-03-28 21:37:01,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,532 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 574125 effective words/s\n",
      "2022-03-28 21:37:01,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,587 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,591 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 571471 effective words/s\n",
      "2022-03-28 21:37:01,591 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 554447 effective words/s', 'datetime': '2022-03-28T21:37:01.591892', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,592 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:01.592179', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:01,593 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:01,593 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:01,608 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:01,609 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:01,615 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:01.615681', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,616 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:01.616223', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,624 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:01,625 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:01,625 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:01.625655', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,638 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:01,639 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:01,640 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:01.640655', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:01,641 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:01.641156', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,696 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,699 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 567949 effective words/s\n",
      "2022-03-28 21:37:01,752 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,756 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,757 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 582432 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 0.341310977935791, 'train_time_std': 0.00016115438218045357}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:01,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,815 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 573673 effective words/s\n",
      "2022-03-28 21:37:01,866 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,872 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 579728 effective words/s\n",
      "2022-03-28 21:37:01,924 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:01,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:01,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:01,930 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 578927 effective words/s\n",
      "2022-03-28 21:37:01,930 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 563833 effective words/s', 'datetime': '2022-03-28T21:37:01.930446', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:01,930 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:01.930786', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:01,931 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:01,932 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:01,945 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:01,946 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:01,953 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:01.953383', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,954 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:01.954114', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,961 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:01,962 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:01,962 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:01.962830', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:01,976 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:01,976 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:01,977 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:01.977555', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:01,977 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:01.977976', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:02,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,038 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 552446 effective words/s\n",
      "2022-03-28 21:37:02,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,092 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,095 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 579395 effective words/s\n",
      "2022-03-28 21:37:02,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,153 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,154 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 570668 effective words/s\n",
      "2022-03-28 21:37:02,207 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,212 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 575805 effective words/s\n",
      "2022-03-28 21:37:02,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,271 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 564080 effective words/s\n",
      "2022-03-28 21:37:02,271 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 554936 effective words/s', 'datetime': '2022-03-28T21:37:02.271777', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:02,272 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:02.272098', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:02,273 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:02,273 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:02,287 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:02,287 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:02,294 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:02.294274', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,294 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:02.294828', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,303 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:02,304 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:02,304 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:02.304488', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,317 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2022-03-28 21:37:02,318 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:02,319 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:02.319556', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:02,319 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:02.319978', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:02,373 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,378 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 569533 effective words/s\n",
      "2022-03-28 21:37:02,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,435 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 585104 effective words/s\n",
      "2022-03-28 21:37:02,487 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,493 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 572756 effective words/s\n",
      "2022-03-28 21:37:02,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,550 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 581381 effective words/s\n",
      "2022-03-28 21:37:02,603 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,608 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 574374 effective words/s\n",
      "2022-03-28 21:37:02,609 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.3s, 563721 effective words/s', 'datetime': '2022-03-28T21:37:02.609221', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:02,609 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:02.609526', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:02,610 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:02,611 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:02,624 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:02,625 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:02,631 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:02.631619', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,632 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:02.632184', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,640 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:02,640 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:02,641 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:02.641349', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:02,642 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:02,675 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:02,687 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:02,688 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:02,689 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:02.689668', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:02,690 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:02.690121', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:02,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,805 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 285733 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 0.33908724784851074, 'train_time_std': 0.0017776349518906147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:02,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:02,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:02,919 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:02,920 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 287334 effective words/s\n",
      "2022-03-28 21:37:03,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,034 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 289761 effective words/s\n",
      "2022-03-28 21:37:03,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,141 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,147 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 291451 effective words/s\n",
      "2022-03-28 21:37:03,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,255 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,260 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,261 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 290009 effective words/s\n",
      "2022-03-28 21:37:03,261 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 285352 effective words/s', 'datetime': '2022-03-28T21:37:03.261306', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:03,261 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:03.261591', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:03,262 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:03,263 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:03,276 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:03,277 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:03,283 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:03.283484', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,284 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:03.284159', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,292 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:03,292 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:03,293 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:03.293192', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,294 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:03,326 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:03,339 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:03,340 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:03,341 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:03.341038', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:03,341 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:03.341455', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:03,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,457 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 282732 effective words/s\n",
      "2022-03-28 21:37:03,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,567 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,572 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 285886 effective words/s\n",
      "2022-03-28 21:37:03,681 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,688 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 285142 effective words/s\n",
      "2022-03-28 21:37:03,795 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,801 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,802 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 289797 effective words/s\n",
      "2022-03-28 21:37:03,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:03,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:03,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:03,917 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 287124 effective words/s\n",
      "2022-03-28 21:37:03,917 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 282999 effective words/s', 'datetime': '2022-03-28T21:37:03.917346', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:03,917 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:03.917759', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:03,919 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:03,919 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:03,932 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:03,933 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:03,939 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:03.939800', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,940 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:03.940432', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,948 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:03,948 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:03,949 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:03.949252', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:03,950 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:03,983 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:03,996 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:03,996 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:03,998 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:03.998311', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:03,998 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:03.998724', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:04,108 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,116 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 278760 effective words/s\n",
      "2022-03-28 21:37:04,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,230 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 290159 effective words/s\n",
      "2022-03-28 21:37:04,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,339 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,345 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 285647 effective words/s\n",
      "2022-03-28 21:37:04,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,459 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 289144 effective words/s\n",
      "2022-03-28 21:37:04,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,574 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 287184 effective words/s\n",
      "2022-03-28 21:37:04,574 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 282926 effective words/s', 'datetime': '2022-03-28T21:37:04.574753', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:04,575 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:04.575042', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:04,576 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:04,576 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:04,590 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:04,591 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:04,597 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:04.597503', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:04,598 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:04.598060', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:04,606 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:04,606 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:04,607 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:04.607266', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:04,608 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:04,641 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:04,654 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:04,654 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:04,655 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:04.655853', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:04,656 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:04.656316', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:04,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,770 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 287315 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 0.6552314758300781, 'train_time_std': 0.002333884337913735}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:04,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,883 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 292738 effective words/s\n",
      "2022-03-28 21:37:04,989 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:04,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:04,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:04,996 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 291167 effective words/s\n",
      "2022-03-28 21:37:05,103 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,109 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 290956 effective words/s\n",
      "2022-03-28 21:37:05,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,224 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 287145 effective words/s\n",
      "2022-03-28 21:37:05,224 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 286762 effective words/s', 'datetime': '2022-03-28T21:37:05.224622', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:05,224 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:05.224919', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:05,226 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:05,226 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:05,240 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:05,240 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:05,246 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:05.246759', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,247 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:05.247260', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,255 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:05,255 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:05,256 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:05.256128', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,257 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:05,289 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:05,303 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:05,303 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:05,304 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:05.304800', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:05,305 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:05.305240', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:05,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,418 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 290441 effective words/s\n",
      "2022-03-28 21:37:05,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,530 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 295807 effective words/s\n",
      "2022-03-28 21:37:05,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,646 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 282788 effective words/s\n",
      "2022-03-28 21:37:05,752 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,753 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,759 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 292989 effective words/s\n",
      "2022-03-28 21:37:05,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:05,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:05,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:05,872 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 290675 effective words/s\n",
      "2022-03-28 21:37:05,873 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 286919 effective words/s', 'datetime': '2022-03-28T21:37:05.873325', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:05,873 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:05.873623', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:05,874 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:05,875 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:05,889 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2022-03-28 21:37:05,889 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:05,895 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1762 unique words (16.343567387069847%% of original 10781, drops 9019)', 'datetime': '2022-03-28T21:37:05.895819', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,896 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 46084 word corpus (76.94773751878444%% of original 59890, drops 13806)', 'datetime': '2022-03-28T21:37:05.896361', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,904 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2022-03-28 21:37:05,905 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2022-03-28 21:37:05,905 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 32610.61883565215 word corpus (70.8%% of prior 46084)', 'datetime': '2022-03-28T21:37:05.905600', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:05,906 : INFO : constructing a huffman tree from 1762 words\n",
      "2022-03-28 21:37:05,940 : INFO : built huffman tree with maximum node depth 13\n",
      "2022-03-28 21:37:05,953 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2022-03-28 21:37:05,954 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:05,955 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:05.955553', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:05,956 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:05.956058', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:06,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,082 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 260118 effective words/s\n",
      "2022-03-28 21:37:06,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,202 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 277313 effective words/s\n",
      "2022-03-28 21:37:06,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,310 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,315 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 289941 effective words/s\n",
      "2022-03-28 21:37:06,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,428 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,429 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 291736 effective words/s\n",
      "2022-03-28 21:37:06,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,542 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 290684 effective words/s\n",
      "2022-03-28 21:37:06,542 : INFO : Word2Vec lifecycle event {'msg': 'training on 299450 raw words (162877 effective words) took 0.6s, 277692 effective words/s', 'datetime': '2022-03-28T21:37:06.542874', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:06,543 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=1762, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:06.543177', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:06,544 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:06,558 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:06,582 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:06,583 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:06,597 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:06.597310', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:06,598 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:06.597986', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:06,616 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:06,617 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:06,617 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:06.617709', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:06,648 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:06,649 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:06,651 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:06.651685', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:06,652 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:06.652312', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:06,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,719 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1969385 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 0.655987024307251, 'train_time_std': 0.009578668286210653}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:06,782 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,787 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 1920289 effective words/s\n",
      "2022-03-28 21:37:06,850 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,855 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 1948911 effective words/s\n",
      "2022-03-28 21:37:06,919 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,924 : INFO : EPOCH - 4 : training on 175599 raw words (110129 effective words) took 0.1s, 1916607 effective words/s\n",
      "2022-03-28 21:37:06,991 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:06,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:06,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:06,994 : INFO : EPOCH - 5 : training on 175599 raw words (110244 effective words) took 0.1s, 1882640 effective words/s\n",
      "2022-03-28 21:37:06,994 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551136 effective words) took 0.3s, 1610088 effective words/s', 'datetime': '2022-03-28T21:37:06.994973', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:06,995 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:06.995432', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:06,996 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:07,008 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:07,034 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:07,034 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:07,049 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:07.048994', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,049 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:07.049632', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,067 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:07,069 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:07,069 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:07.069644', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,100 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:07,100 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:07,103 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:07.102995', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:07,103 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:07.103568', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:07,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,171 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,171 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.1s, 1918047 effective words/s\n",
      "2022-03-28 21:37:07,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,238 : INFO : EPOCH - 2 : training on 175599 raw words (110198 effective words) took 0.1s, 1957258 effective words/s\n",
      "2022-03-28 21:37:07,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,306 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,307 : INFO : EPOCH - 3 : training on 175599 raw words (110405 effective words) took 0.1s, 1903717 effective words/s\n",
      "2022-03-28 21:37:07,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,375 : INFO : EPOCH - 4 : training on 175599 raw words (110267 effective words) took 0.1s, 1914080 effective words/s\n",
      "2022-03-28 21:37:07,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,440 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,441 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,442 : INFO : EPOCH - 5 : training on 175599 raw words (110239 effective words) took 0.1s, 1962777 effective words/s\n",
      "2022-03-28 21:37:07,442 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551393 effective words) took 0.3s, 1627266 effective words/s', 'datetime': '2022-03-28T21:37:07.442762', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:07,443 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:07.443093', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:07,444 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:07,454 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:07,479 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:07,479 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:07,493 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:07.493719', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,494 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:07.494240', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,512 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:07,513 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:07,513 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:07.513535', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,543 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:07,544 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:07,546 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:07.545998', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:07,546 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:07.546433', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:07,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,614 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1936478 effective words/s\n",
      "2022-03-28 21:37:07,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,679 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,681 : INFO : EPOCH - 2 : training on 175599 raw words (110215 effective words) took 0.1s, 1953261 effective words/s\n",
      "2022-03-28 21:37:07,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,747 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,749 : INFO : EPOCH - 3 : training on 175599 raw words (110315 effective words) took 0.1s, 1965730 effective words/s\n",
      "2022-03-28 21:37:07,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,816 : INFO : EPOCH - 4 : training on 175599 raw words (110010 effective words) took 0.1s, 1945098 effective words/s\n",
      "2022-03-28 21:37:07,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:07,883 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:07,884 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:07,885 : INFO : EPOCH - 5 : training on 175599 raw words (110125 effective words) took 0.1s, 1931714 effective words/s\n",
      "2022-03-28 21:37:07,885 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551009 effective words) took 0.3s, 1625881 effective words/s', 'datetime': '2022-03-28T21:37:07.885634', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:07,886 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:07.886035', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:07,887 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:07,897 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:07,923 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:07,923 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:07,937 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:07.937506', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,938 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:07.938093', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,955 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:07,957 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:07,957 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:07.957521', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:07,988 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:07,988 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:07,990 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:07.990202', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:07,990 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:07.990619', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:08,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,059 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1972463 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.44763533274332684, 'train_time_std': 0.003708188956837034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:08,123 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,126 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,127 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,128 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 1909172 effective words/s\n",
      "2022-03-28 21:37:08,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,195 : INFO : EPOCH - 3 : training on 175599 raw words (110159 effective words) took 0.1s, 1983016 effective words/s\n",
      "2022-03-28 21:37:08,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,262 : INFO : EPOCH - 4 : training on 175599 raw words (110138 effective words) took 0.1s, 2001325 effective words/s\n",
      "2022-03-28 21:37:08,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,329 : INFO : EPOCH - 5 : training on 175599 raw words (110247 effective words) took 0.1s, 2000789 effective words/s\n",
      "2022-03-28 21:37:08,329 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550955 effective words) took 0.3s, 1627875 effective words/s', 'datetime': '2022-03-28T21:37:08.329420', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:08,329 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:08.329744', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:08,330 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:08,340 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:08,365 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:08,366 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:08,379 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:08.379930', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,380 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:08.380484', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,398 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:08,399 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:08,399 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:08.399845', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,430 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:08,431 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:08,433 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:08.433039', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:08,433 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:08.433491', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:08,499 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,503 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1890196 effective words/s\n",
      "2022-03-28 21:37:08,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,569 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,571 : INFO : EPOCH - 2 : training on 175599 raw words (110215 effective words) took 0.1s, 1938692 effective words/s\n",
      "2022-03-28 21:37:08,633 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,638 : INFO : EPOCH - 3 : training on 175599 raw words (110334 effective words) took 0.1s, 1984798 effective words/s\n",
      "2022-03-28 21:37:08,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,704 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,706 : INFO : EPOCH - 4 : training on 175599 raw words (110122 effective words) took 0.1s, 1918861 effective words/s\n",
      "2022-03-28 21:37:08,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,774 : INFO : EPOCH - 5 : training on 175599 raw words (110093 effective words) took 0.1s, 1936190 effective words/s\n",
      "2022-03-28 21:37:08,774 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551108 effective words) took 0.3s, 1618263 effective words/s', 'datetime': '2022-03-28T21:37:08.774401', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:08,774 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:08.774755', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:08,775 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:08,785 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:08,811 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:08,811 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:08,825 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:08.825831', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,826 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:08.826411', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,843 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:08,844 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:08,845 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:08.845349', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:08,875 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:08,876 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:08,877 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:08.877929', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:08,878 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:08.878398', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:08,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:08,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:08,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:08,945 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.1s, 1967495 effective words/s\n",
      "2022-03-28 21:37:09,008 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,012 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,012 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.1s, 1963121 effective words/s\n",
      "2022-03-28 21:37:09,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,080 : INFO : EPOCH - 3 : training on 175599 raw words (110068 effective words) took 0.1s, 1967032 effective words/s\n",
      "2022-03-28 21:37:09,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,149 : INFO : EPOCH - 4 : training on 175599 raw words (110128 effective words) took 0.1s, 1938821 effective words/s\n",
      "2022-03-28 21:37:09,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,214 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,216 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,217 : INFO : EPOCH - 5 : training on 175599 raw words (110103 effective words) took 0.1s, 1947236 effective words/s\n",
      "2022-03-28 21:37:09,217 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550471 effective words) took 0.3s, 1625469 effective words/s', 'datetime': '2022-03-28T21:37:09.217409', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:09,217 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:09.217715', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:09,219 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:09,229 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:09,255 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:09,256 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:09,269 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:09.269689', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:09,270 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:09.270315', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:09,288 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:09,289 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:09,289 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:09.289939', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:09,291 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:09,373 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:09,402 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:09,403 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:09,404 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:09.404744', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:09,405 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:09.405204', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.4438509941101074, 'train_time_std': 0.0007887298845359125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:09,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,532 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 960628 effective words/s\n",
      "2022-03-28 21:37:09,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,658 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.1s, 953127 effective words/s\n",
      "2022-03-28 21:37:09,774 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,784 : INFO : EPOCH - 3 : training on 175599 raw words (110076 effective words) took 0.1s, 966497 effective words/s\n",
      "2022-03-28 21:37:09,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:09,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:09,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:09,910 : INFO : EPOCH - 4 : training on 175599 raw words (110309 effective words) took 0.1s, 963640 effective words/s\n",
      "2022-03-28 21:37:10,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,037 : INFO : EPOCH - 5 : training on 175599 raw words (110396 effective words) took 0.1s, 945876 effective words/s\n",
      "2022-03-28 21:37:10,038 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551240 effective words) took 0.6s, 871558 effective words/s', 'datetime': '2022-03-28T21:37:10.038043', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:10,038 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:10.038370', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:10,039 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:10,049 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:10,075 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:10,075 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:10,089 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:10.089659', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,090 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:10.090255', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,108 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:10,109 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:10,109 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:10.109976', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,111 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:10,251 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:10,281 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:10,281 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:10,284 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:10.284003', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:10,284 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:10.284576', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:10,403 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,412 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 949481 effective words/s\n",
      "2022-03-28 21:37:10,528 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,534 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,539 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 959829 effective words/s\n",
      "2022-03-28 21:37:10,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,666 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 954223 effective words/s\n",
      "2022-03-28 21:37:10,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,792 : INFO : EPOCH - 4 : training on 175599 raw words (110233 effective words) took 0.1s, 964961 effective words/s\n",
      "2022-03-28 21:37:10,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:10,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:10,917 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:10,918 : INFO : EPOCH - 5 : training on 175599 raw words (110149 effective words) took 0.1s, 956517 effective words/s\n",
      "2022-03-28 21:37:10,918 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551145 effective words) took 0.6s, 869769 effective words/s', 'datetime': '2022-03-28T21:37:10.918665', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:10,918 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:10.918970', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:10,921 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:10,930 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:10,955 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:10,956 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:10,970 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:10.970317', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,970 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:10.970901', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,988 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:10,989 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:10,990 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:10.990391', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:10,992 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:11,071 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:11,100 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:11,101 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:11,103 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:11.103412', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:11,104 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:11.104008', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:11,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:11,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:11,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:11,230 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 964257 effective words/s\n",
      "2022-03-28 21:37:11,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:11,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:11,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:11,353 : INFO : EPOCH - 2 : training on 175599 raw words (110313 effective words) took 0.1s, 976641 effective words/s\n",
      "2022-03-28 21:37:11,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:11,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:11,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:11,480 : INFO : EPOCH - 3 : training on 175599 raw words (110382 effective words) took 0.1s, 956369 effective words/s\n",
      "2022-03-28 21:37:11,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:11,602 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:11,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:11,607 : INFO : EPOCH - 4 : training on 175599 raw words (110250 effective words) took 0.1s, 949977 effective words/s\n",
      "2022-03-28 21:37:11,724 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:11,728 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:11,731 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:11,731 : INFO : EPOCH - 5 : training on 175599 raw words (110454 effective words) took 0.1s, 973493 effective words/s\n",
      "2022-03-28 21:37:11,732 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551743 effective words) took 0.6s, 878784 effective words/s', 'datetime': '2022-03-28T21:37:11.732174', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:11,732 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:11.732630', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:11,734 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:11,744 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:11,769 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:11,770 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:11,784 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:11.784196', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:11,784 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:11.784756', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:11,802 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:11,804 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:11,804 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:11.804852', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:11,806 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:11,885 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:11,914 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:11,914 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:11,916 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:11.916419', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:11,916 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:11.916894', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8383564949035645, 'train_time_std': 0.030722654319712037}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:12,037 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,047 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 937748 effective words/s\n",
      "2022-03-28 21:37:12,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,173 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.1s, 959091 effective words/s\n",
      "2022-03-28 21:37:12,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,296 : INFO : EPOCH - 3 : training on 175599 raw words (110219 effective words) took 0.1s, 980203 effective words/s\n",
      "2022-03-28 21:37:12,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,418 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,422 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,423 : INFO : EPOCH - 4 : training on 175599 raw words (110060 effective words) took 0.1s, 963438 effective words/s\n",
      "2022-03-28 21:37:12,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,546 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,550 : INFO : EPOCH - 5 : training on 175599 raw words (110266 effective words) took 0.1s, 945467 effective words/s\n",
      "2022-03-28 21:37:12,551 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551103 effective words) took 0.6s, 869348 effective words/s', 'datetime': '2022-03-28T21:37:12.551177', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:12,551 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:12.551561', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:12,553 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:12,563 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:12,589 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:12,590 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:12,603 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:12.603791', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:12,604 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:12.604344', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:12,622 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:12,623 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:12,623 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:12.623940', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:12,625 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:12,703 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:12,732 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:12,732 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:12,734 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:12.734522', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:12,735 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:12.735012', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:12,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,861 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.1s, 963417 effective words/s\n",
      "2022-03-28 21:37:12,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:12,978 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:12,981 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:12,982 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.1s, 1008193 effective words/s\n",
      "2022-03-28 21:37:13,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,104 : INFO : EPOCH - 3 : training on 175599 raw words (110198 effective words) took 0.1s, 992049 effective words/s\n",
      "2022-03-28 21:37:13,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,229 : INFO : EPOCH - 4 : training on 175599 raw words (110131 effective words) took 0.1s, 978247 effective words/s\n",
      "2022-03-28 21:37:13,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,361 : INFO : EPOCH - 5 : training on 175599 raw words (110103 effective words) took 0.1s, 912558 effective words/s\n",
      "2022-03-28 21:37:13,361 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550463 effective words) took 0.6s, 879013 effective words/s', 'datetime': '2022-03-28T21:37:13.361596', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:13,361 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:13.361885', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:13,363 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:13,373 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:13,398 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:13,398 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:13,412 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:13.412605', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:13,413 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:13.413145', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:13,430 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:13,431 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:13,432 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:13.432022', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:13,433 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:13,509 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:13,537 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:13,538 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:13,540 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:13.540372', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:13,540 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:13.540980', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:13,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,663 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 997224 effective words/s\n",
      "2022-03-28 21:37:13,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,790 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.1s, 950242 effective words/s\n",
      "2022-03-28 21:37:13,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:13,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:13,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:13,913 : INFO : EPOCH - 3 : training on 175599 raw words (110219 effective words) took 0.1s, 984632 effective words/s\n",
      "2022-03-28 21:37:14,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:14,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:14,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:14,033 : INFO : EPOCH - 4 : training on 175599 raw words (110060 effective words) took 0.1s, 1006969 effective words/s\n",
      "2022-03-28 21:37:14,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:14,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:14,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:14,151 : INFO : EPOCH - 5 : training on 175599 raw words (110289 effective words) took 0.1s, 1028601 effective words/s\n",
      "2022-03-28 21:37:14,151 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551126 effective words) took 0.6s, 902818 effective words/s', 'datetime': '2022-03-28T21:37:14.151794', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:14,152 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:14.152146', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:14,154 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:14,163 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:14,187 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:14,187 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:14,200 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:14.200891', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:14,201 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:14.201411', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:14,218 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:14,219 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:14,220 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:14.220268', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:14,249 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:14,250 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:14,252 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:14.252258', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:14,252 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:14.252803', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.8065182367960612, 'train_time_std': 0.011977707515825237}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:14,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:14,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:14,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:14,454 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.2s, 579302 effective words/s\n",
      "2022-03-28 21:37:14,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:14,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:14,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:14,650 : INFO : EPOCH - 2 : training on 175599 raw words (110008 effective words) took 0.2s, 595220 effective words/s\n",
      "2022-03-28 21:37:14,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:14,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:14,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:14,848 : INFO : EPOCH - 3 : training on 175599 raw words (110417 effective words) took 0.2s, 590916 effective words/s\n",
      "2022-03-28 21:37:15,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:15,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:15,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:15,048 : INFO : EPOCH - 4 : training on 175599 raw words (110155 effective words) took 0.2s, 584664 effective words/s\n",
      "2022-03-28 21:37:15,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:15,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:15,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:15,247 : INFO : EPOCH - 5 : training on 175599 raw words (110257 effective words) took 0.2s, 589598 effective words/s\n",
      "2022-03-28 21:37:15,247 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551121 effective words) took 1.0s, 554345 effective words/s', 'datetime': '2022-03-28T21:37:15.247353', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:15,247 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:15.247643', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:15,249 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:15,259 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:15,284 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:15,285 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:15,298 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:15.298785', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:15,299 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:15.299338', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:15,317 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:15,318 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:15,318 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:15.318761', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:15,348 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:15,349 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:15,351 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:15.351022', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:15,351 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:15.351456', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:15,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:15,543 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:15,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:15,549 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 591295 effective words/s\n",
      "2022-03-28 21:37:15,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:15,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:15,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:15,747 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.2s, 589473 effective words/s\n",
      "2022-03-28 21:37:15,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:15,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:15,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:15,945 : INFO : EPOCH - 3 : training on 175599 raw words (110198 effective words) took 0.2s, 589599 effective words/s\n",
      "2022-03-28 21:37:16,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:16,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:16,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:16,146 : INFO : EPOCH - 4 : training on 175599 raw words (110099 effective words) took 0.2s, 582372 effective words/s\n",
      "2022-03-28 21:37:16,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:16,339 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:16,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:16,344 : INFO : EPOCH - 5 : training on 175599 raw words (110324 effective words) took 0.2s, 591683 effective words/s\n",
      "2022-03-28 21:37:16,344 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550652 effective words) took 1.0s, 554532 effective words/s', 'datetime': '2022-03-28T21:37:16.344797', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:16,345 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:16.345105', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:16,346 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:16,356 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:16,380 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:16,381 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:16,394 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:16.394669', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:16,395 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:16.395193', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:16,412 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:16,413 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:16,413 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:16.413692', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:16,443 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:16,443 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:16,445 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:16.445671', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:16,446 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:16.446122', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:16,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:16,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:16,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:16,640 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 602821 effective words/s\n",
      "2022-03-28 21:37:16,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:16,832 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:16,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:16,838 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.2s, 590387 effective words/s\n",
      "2022-03-28 21:37:17,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:17,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:17,035 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:17,036 : INFO : EPOCH - 3 : training on 175599 raw words (110198 effective words) took 0.2s, 592332 effective words/s\n",
      "2022-03-28 21:37:17,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:17,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:17,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:17,231 : INFO : EPOCH - 4 : training on 175599 raw words (110131 effective words) took 0.2s, 598985 effective words/s\n",
      "2022-03-28 21:37:17,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:17,424 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:17,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:17,429 : INFO : EPOCH - 5 : training on 175599 raw words (109991 effective words) took 0.2s, 588554 effective words/s\n",
      "2022-03-28 21:37:17,429 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550351 effective words) took 1.0s, 559639 effective words/s', 'datetime': '2022-03-28T21:37:17.429883', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:17,430 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:17.430211', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:17,431 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:17,441 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:17,466 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:17,467 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:17,481 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:17.481016', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:17,481 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:17.481595', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:17,499 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:17,500 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:17,501 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:17.501427', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:17,531 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:17,532 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:17,533 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:17.533897', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:17,534 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:17.534339', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 1.092354377110799, 'train_time_std': 0.005113639851014316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:17,719 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:17,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:17,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:17,730 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.2s, 597598 effective words/s\n",
      "2022-03-28 21:37:17,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:17,918 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:17,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:17,923 : INFO : EPOCH - 2 : training on 175599 raw words (110198 effective words) took 0.2s, 605050 effective words/s\n",
      "2022-03-28 21:37:18,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:18,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:18,120 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:18,121 : INFO : EPOCH - 3 : training on 175599 raw words (110258 effective words) took 0.2s, 590121 effective words/s\n",
      "2022-03-28 21:37:18,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:18,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:18,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:18,317 : INFO : EPOCH - 4 : training on 175599 raw words (110278 effective words) took 0.2s, 598099 effective words/s\n",
      "2022-03-28 21:37:18,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:18,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:18,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:18,510 : INFO : EPOCH - 5 : training on 175599 raw words (110216 effective words) took 0.2s, 602117 effective words/s\n",
      "2022-03-28 21:37:18,511 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551234 effective words) took 1.0s, 564510 effective words/s', 'datetime': '2022-03-28T21:37:18.511158', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:18,511 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:18.511551', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:18,512 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:18,523 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:18,546 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:18,547 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:18,560 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:18.560941', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:18,561 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:18.561575', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:18,578 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:18,579 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:18,579 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:18.579956', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:18,609 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:18,610 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:18,611 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:18.611524', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:18,611 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:18.611968', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:18,795 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:18,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:18,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:18,805 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 606711 effective words/s\n",
      "2022-03-28 21:37:18,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:18,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:18,998 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:18,999 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.2s, 603717 effective words/s\n",
      "2022-03-28 21:37:19,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:19,185 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:19,191 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:19,191 : INFO : EPOCH - 3 : training on 175599 raw words (110102 effective words) took 0.2s, 606597 effective words/s\n",
      "2022-03-28 21:37:19,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:19,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:19,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:19,388 : INFO : EPOCH - 4 : training on 175599 raw words (110331 effective words) took 0.2s, 593106 effective words/s\n",
      "2022-03-28 21:37:19,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:19,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:19,579 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:19,579 : INFO : EPOCH - 5 : training on 175599 raw words (110239 effective words) took 0.2s, 612025 effective words/s\n",
      "2022-03-28 21:37:19,580 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551083 effective words) took 1.0s, 569261 effective words/s', 'datetime': '2022-03-28T21:37:19.580347', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:19,580 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:19.580694', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:19,582 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:19,592 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:19,617 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:19,617 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:19,631 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:19.631295', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:19,631 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:19.631878', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:19,649 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:19,650 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:19,650 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:19.650855', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:19,679 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2022-03-28 21:37:19,680 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:19,682 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:19.682236', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:19,682 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:19.682711', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:19,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:19,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:19,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:19,875 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 607434 effective words/s\n",
      "2022-03-28 21:37:20,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:20,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:20,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:20,069 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 0.2s, 602440 effective words/s\n",
      "2022-03-28 21:37:20,252 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:20,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:20,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:20,263 : INFO : EPOCH - 3 : training on 175599 raw words (110145 effective words) took 0.2s, 601387 effective words/s\n",
      "2022-03-28 21:37:20,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:20,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:20,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:20,454 : INFO : EPOCH - 4 : training on 175599 raw words (110095 effective words) took 0.2s, 613019 effective words/s\n",
      "2022-03-28 21:37:20,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:20,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:20,645 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:20,645 : INFO : EPOCH - 5 : training on 175599 raw words (110334 effective words) took 0.2s, 613937 effective words/s\n",
      "2022-03-28 21:37:20,645 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550745 effective words) took 1.0s, 572098 effective words/s', 'datetime': '2022-03-28T21:37:20.645781', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:20,646 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:20.646094', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:20,647 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:20,658 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:20,682 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:20,682 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:20,696 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:20.696316', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:20,696 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:20.696931', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:20,718 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:20,719 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:20,720 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:20.720576', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:20,722 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:20,800 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:20,828 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:20,829 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:20,831 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:20.831514', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:20,832 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:20.832071', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 1.0719184080759685, 'train_time_std': 0.006723973412252684}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:21,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:21,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:21,225 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:21,225 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.4s, 288706 effective words/s\n",
      "2022-03-28 21:37:21,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:21,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:21,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:21,618 : INFO : EPOCH - 2 : training on 175599 raw words (110008 effective words) took 0.4s, 288113 effective words/s\n",
      "2022-03-28 21:37:21,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:22,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:22,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:22,014 : INFO : EPOCH - 3 : training on 175599 raw words (110417 effective words) took 0.4s, 286971 effective words/s\n",
      "2022-03-28 21:37:22,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:22,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:22,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:22,412 : INFO : EPOCH - 4 : training on 175599 raw words (110001 effective words) took 0.4s, 284320 effective words/s\n",
      "2022-03-28 21:37:22,783 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:22,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:22,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:22,805 : INFO : EPOCH - 5 : training on 175599 raw words (110184 effective words) took 0.4s, 287401 effective words/s\n",
      "2022-03-28 21:37:22,806 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550894 effective words) took 2.0s, 279120 effective words/s', 'datetime': '2022-03-28T21:37:22.806101', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:22,806 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:22.806463', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:22,807 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:22,818 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:22,841 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:22,842 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:22,855 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:22.855516', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:22,856 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:22.856038', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:22,873 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:22,874 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:22,874 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:22.874811', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:22,876 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:22,951 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:22,978 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:22,979 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:22,981 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:22.981742', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:22,982 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:22.982312', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:23,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:23,378 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:23,382 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:23,383 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 282674 effective words/s\n",
      "2022-03-28 21:37:23,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:23,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:23,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:23,783 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.4s, 282937 effective words/s\n",
      "2022-03-28 21:37:24,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:24,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:24,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:24,197 : INFO : EPOCH - 3 : training on 175599 raw words (110227 effective words) took 0.4s, 273926 effective words/s\n",
      "2022-03-28 21:37:24,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:24,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:24,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:24,596 : INFO : EPOCH - 4 : training on 175599 raw words (109947 effective words) took 0.4s, 282920 effective words/s\n",
      "2022-03-28 21:37:24,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:24,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:24,992 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:24,992 : INFO : EPOCH - 5 : training on 175599 raw words (110179 effective words) took 0.4s, 286600 effective words/s\n",
      "2022-03-28 21:37:24,993 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550525 effective words) took 2.0s, 273846 effective words/s', 'datetime': '2022-03-28T21:37:24.993093', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:24,993 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:24.993472', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:24,995 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:25,005 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:25,028 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:25,029 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:25,043 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:25.043185', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:25,043 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:25.043722', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:25,060 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:25,061 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:25,062 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:25.062268', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:25,064 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:25,138 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:25,166 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:25,167 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:25,169 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:25.169193', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:25,169 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:25.169706', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:25,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:25,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:25,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:25,567 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.4s, 285748 effective words/s\n",
      "2022-03-28 21:37:25,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:25,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:25,964 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:25,965 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.4s, 285191 effective words/s\n",
      "2022-03-28 21:37:26,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:26,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:26,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:26,360 : INFO : EPOCH - 3 : training on 175599 raw words (110315 effective words) took 0.4s, 287424 effective words/s\n",
      "2022-03-28 21:37:26,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:26,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:26,754 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:26,754 : INFO : EPOCH - 4 : training on 175599 raw words (110259 effective words) took 0.4s, 287785 effective words/s\n",
      "2022-03-28 21:37:27,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:27,145 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:27,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:27,150 : INFO : EPOCH - 5 : training on 175599 raw words (110361 effective words) took 0.4s, 288018 effective words/s\n",
      "2022-03-28 21:37:27,150 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551493 effective words) took 2.0s, 278490 effective words/s', 'datetime': '2022-03-28T21:37:27.150363', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:27,150 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:27.150663', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:27,152 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:27,163 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:27,186 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:27,187 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:27,201 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:27.201096', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:27,201 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:27.201599', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:27,218 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:27,219 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:27,220 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:27.220341', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:27,222 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:27,297 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:27,325 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:27,325 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:27,327 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:27.327792', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:27,328 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:27.328363', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 2.168355147043864, 'train_time_std': 0.013759521220440708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:27,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:27,712 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:27,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:27,716 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 291225 effective words/s\n",
      "2022-03-28 21:37:28,083 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:28,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:28,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:28,105 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.4s, 291043 effective words/s\n",
      "2022-03-28 21:37:28,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:28,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:28,497 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:28,498 : INFO : EPOCH - 3 : training on 175599 raw words (110216 effective words) took 0.4s, 289198 effective words/s\n",
      "2022-03-28 21:37:28,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:28,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:28,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:28,893 : INFO : EPOCH - 4 : training on 175599 raw words (110088 effective words) took 0.4s, 286701 effective words/s\n",
      "2022-03-28 21:37:29,268 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:29,284 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:29,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:29,291 : INFO : EPOCH - 5 : training on 175599 raw words (110001 effective words) took 0.4s, 284518 effective words/s\n",
      "2022-03-28 21:37:29,291 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550336 effective words) took 2.0s, 280363 effective words/s', 'datetime': '2022-03-28T21:37:29.291693', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:29,291 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:29.291975', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:29,293 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:29,303 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:29,328 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:29,328 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:29,342 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:29.342408', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:29,343 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:29.343074', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:29,362 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:29,363 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:29,364 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:29.364227', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:29,365 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:29,442 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:29,470 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:29,471 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:29,473 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:29.473428', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:29,474 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:29.473999', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:29,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:29,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:29,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:29,866 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.4s, 289204 effective words/s\n",
      "2022-03-28 21:37:30,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:30,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:30,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:30,266 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.4s, 283009 effective words/s\n",
      "2022-03-28 21:37:30,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:30,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:30,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:30,660 : INFO : EPOCH - 3 : training on 175599 raw words (110137 effective words) took 0.4s, 288309 effective words/s\n",
      "2022-03-28 21:37:31,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:31,045 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:31,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:31,048 : INFO : EPOCH - 4 : training on 175599 raw words (110074 effective words) took 0.4s, 292109 effective words/s\n",
      "2022-03-28 21:37:31,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:31,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:31,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:31,438 : INFO : EPOCH - 5 : training on 175599 raw words (110184 effective words) took 0.4s, 290740 effective words/s\n",
      "2022-03-28 21:37:31,439 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (550893 effective words) took 2.0s, 280379 effective words/s', 'datetime': '2022-03-28T21:37:31.439187', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:31,439 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:31.439618', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:31,441 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:31,451 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:31,475 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2022-03-28 21:37:31,476 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:31,489 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4125 unique words (23.91165729522926%% of original 17251, drops 13126)', 'datetime': '2022-03-28T21:37:31.489466', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:31,490 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 154201 word corpus (87.81428140251369%% of original 175599, drops 21398)', 'datetime': '2022-03-28T21:37:31.490001', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:31,507 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2022-03-28 21:37:31,508 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-03-28 21:37:31,508 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 110199.4281334271 word corpus (71.5%% of prior 154201)', 'datetime': '2022-03-28T21:37:31.508855', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:31,510 : INFO : constructing a huffman tree from 4125 words\n",
      "2022-03-28 21:37:31,585 : INFO : built huffman tree with maximum node depth 15\n",
      "2022-03-28 21:37:31,615 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2022-03-28 21:37:31,616 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:31,618 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:31.618326', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:31,618 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:31.618880', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:31,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:32,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:32,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:32,009 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.4s, 290860 effective words/s\n",
      "2022-03-28 21:37:32,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:32,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:32,396 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:32,397 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.4s, 292413 effective words/s\n",
      "2022-03-28 21:37:32,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:32,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:32,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:32,789 : INFO : EPOCH - 3 : training on 175599 raw words (110315 effective words) took 0.4s, 289280 effective words/s\n",
      "2022-03-28 21:37:33,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:33,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:33,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:33,177 : INFO : EPOCH - 4 : training on 175599 raw words (110291 effective words) took 0.4s, 292323 effective words/s\n",
      "2022-03-28 21:37:33,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:33,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:33,566 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:33,567 : INFO : EPOCH - 5 : training on 175599 raw words (110262 effective words) took 0.4s, 291561 effective words/s\n",
      "2022-03-28 21:37:33,567 : INFO : Word2Vec lifecycle event {'msg': 'training on 877995 raw words (551426 effective words) took 1.9s, 283055 effective words/s', 'datetime': '2022-03-28T21:37:33.567487', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:33,567 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4125, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:33.567838', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:33,570 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:33,726 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 2.1390543778737388, 'train_time_std': 0.008087454305176144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:33,976 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:33,976 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:34,039 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:34.039130', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:34,039 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:34.039596', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:34,122 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:34,125 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:34,126 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:34.126179', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:34,268 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:34,268 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:34,275 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:34.275394', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:34,275 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:34.275908', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:35,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:35,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:35,023 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:35,024 : INFO : EPOCH - 1 : training on 1788017 raw words (1242954 effective words) took 0.6s, 1955211 effective words/s\n",
      "2022-03-28 21:37:35,741 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:35,747 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:35,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:35,747 : INFO : EPOCH - 2 : training on 1788017 raw words (1242297 effective words) took 0.6s, 1951064 effective words/s\n",
      "2022-03-28 21:37:36,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:36,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:36,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:36,462 : INFO : EPOCH - 3 : training on 1788017 raw words (1241904 effective words) took 0.6s, 1976107 effective words/s\n",
      "2022-03-28 21:37:37,173 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:37,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:37,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:37,179 : INFO : EPOCH - 4 : training on 1788017 raw words (1242427 effective words) took 0.6s, 1975377 effective words/s\n",
      "2022-03-28 21:37:37,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:37,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:37,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:37,897 : INFO : EPOCH - 5 : training on 1788017 raw words (1241905 effective words) took 0.6s, 1962884 effective words/s\n",
      "2022-03-28 21:37:37,898 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211487 effective words) took 3.6s, 1714979 effective words/s', 'datetime': '2022-03-28T21:37:37.898147', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:37,898 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:37.898527', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:37,900 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:37,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:38,234 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:38,235 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:38,297 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:38.297679', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:38,298 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:38.298150', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:38,380 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:38,383 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:38,384 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:38.384247', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:38,528 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:38,529 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:38,535 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:38.535833', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:38,536 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:38.536328', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:39,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:39,283 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:39,284 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:39,284 : INFO : EPOCH - 1 : training on 1788017 raw words (1242194 effective words) took 0.7s, 1694472 effective words/s\n",
      "2022-03-28 21:37:40,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:40,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:40,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:40,017 : INFO : EPOCH - 2 : training on 1788017 raw words (1241922 effective words) took 0.7s, 1732461 effective words/s\n",
      "2022-03-28 21:37:40,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:40,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:40,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:40,743 : INFO : EPOCH - 3 : training on 1788017 raw words (1242512 effective words) took 0.7s, 1747031 effective words/s\n",
      "2022-03-28 21:37:41,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:41,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:41,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:41,464 : INFO : EPOCH - 4 : training on 1788017 raw words (1242209 effective words) took 0.6s, 1969112 effective words/s\n",
      "2022-03-28 21:37:42,182 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:42,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:42,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:42,190 : INFO : EPOCH - 5 : training on 1788017 raw words (1242564 effective words) took 0.7s, 1747710 effective words/s\n",
      "2022-03-28 21:37:42,191 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211401 effective words) took 3.7s, 1699612 effective words/s', 'datetime': '2022-03-28T21:37:42.191267', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:42,191 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:42.191734', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:42,194 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:42,282 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:42,532 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:42,533 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:42,594 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:42.594121', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:42,594 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:42.594612', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:42,677 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:42,680 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:42,681 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:42.681375', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:42,822 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:42,822 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:42,829 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:42.829277', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:42,829 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:42.829778', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:43,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:43,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:43,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:43,564 : INFO : EPOCH - 1 : training on 1788017 raw words (1242954 effective words) took 0.6s, 1935154 effective words/s\n",
      "2022-03-28 21:37:44,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:44,289 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:44,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:44,291 : INFO : EPOCH - 2 : training on 1788017 raw words (1242231 effective words) took 0.7s, 1745267 effective words/s\n",
      "2022-03-28 21:37:45,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:45,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:45,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:45,017 : INFO : EPOCH - 3 : training on 1788017 raw words (1241966 effective words) took 0.7s, 1745779 effective words/s\n",
      "2022-03-28 21:37:45,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:45,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:45,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:45,750 : INFO : EPOCH - 4 : training on 1788017 raw words (1242427 effective words) took 0.7s, 1733649 effective words/s\n",
      "2022-03-28 21:37:46,466 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:46,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:46,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:46,475 : INFO : EPOCH - 5 : training on 1788017 raw words (1242005 effective words) took 0.7s, 1748322 effective words/s\n",
      "2022-03-28 21:37:46,475 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211583 effective words) took 3.6s, 1703903 effective words/s', 'datetime': '2022-03-28T21:37:46.475713', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:46,476 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:46.476229', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:46,479 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:46,566 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 4.303004503250122, 'train_time_std': 0.019665723616777448}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:37:46,818 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:46,818 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:46,880 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:46.880535', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:46,881 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:46.881040', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:46,964 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:46,967 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:46,968 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:46.968195', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:47,107 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:47,108 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:47,114 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:47.114708', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:47,115 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:47.115370', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:47,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:47,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:47,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:47,872 : INFO : EPOCH - 1 : training on 1788017 raw words (1242954 effective words) took 0.7s, 1890097 effective words/s\n",
      "2022-03-28 21:37:48,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:48,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:48,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:48,601 : INFO : EPOCH - 2 : training on 1788017 raw words (1242297 effective words) took 0.6s, 1968515 effective words/s\n",
      "2022-03-28 21:37:49,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:49,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:49,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:49,328 : INFO : EPOCH - 3 : training on 1788017 raw words (1241904 effective words) took 0.6s, 1964329 effective words/s\n",
      "2022-03-28 21:37:50,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:50,073 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:50,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:50,074 : INFO : EPOCH - 4 : training on 1788017 raw words (1242395 effective words) took 0.7s, 1702259 effective words/s\n",
      "2022-03-28 21:37:50,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:50,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:50,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:50,826 : INFO : EPOCH - 5 : training on 1788017 raw words (1242611 effective words) took 0.7s, 1888048 effective words/s\n",
      "2022-03-28 21:37:50,827 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212161 effective words) took 3.7s, 1673779 effective words/s', 'datetime': '2022-03-28T21:37:50.827303', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:50,827 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:50.827911', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:50,831 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:50,925 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:51,202 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:51,202 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:51,268 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:51.268016', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:51,268 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:51.268541', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:51,355 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:51,358 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:51,359 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:51.359515', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:51,502 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:51,503 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:51,509 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:51.509345', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:51,509 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:51.509850', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:52,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:52,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:52,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:52,269 : INFO : EPOCH - 1 : training on 1788017 raw words (1242465 effective words) took 0.7s, 1669190 effective words/s\n",
      "2022-03-28 21:37:53,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:53,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:53,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:53,027 : INFO : EPOCH - 2 : training on 1788017 raw words (1242184 effective words) took 0.7s, 1891635 effective words/s\n",
      "2022-03-28 21:37:53,795 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:53,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:53,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:53,802 : INFO : EPOCH - 3 : training on 1788017 raw words (1242619 effective words) took 0.7s, 1834852 effective words/s\n",
      "2022-03-28 21:37:54,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:54,545 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:54,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:54,548 : INFO : EPOCH - 4 : training on 1788017 raw words (1242890 effective words) took 0.7s, 1704343 effective words/s\n",
      "2022-03-28 21:37:55,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:55,291 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:55,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:55,293 : INFO : EPOCH - 5 : training on 1788017 raw words (1241985 effective words) took 0.7s, 1701792 effective words/s\n",
      "2022-03-28 21:37:55,293 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212143 effective words) took 3.8s, 1641948 effective words/s', 'datetime': '2022-03-28T21:37:55.293585', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:55,293 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:55.293930', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:55,297 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:55,389 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:37:55,667 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:37:55,667 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:37:55,734 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:37:55.734199', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:55,734 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:37:55.734715', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:55,820 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:37:55,823 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:37:55,823 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:37:55.823977', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:37:55,971 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:37:55,971 : INFO : resetting layer weights\n",
      "2022-03-28 21:37:55,977 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:37:55.977633', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:37:55,978 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:37:55.978370', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:56,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:56,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:56,744 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:56,744 : INFO : EPOCH - 1 : training on 1788017 raw words (1243024 effective words) took 0.7s, 1865300 effective words/s\n",
      "2022-03-28 21:37:57,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:57,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:57,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:57,498 : INFO : EPOCH - 2 : training on 1788017 raw words (1241814 effective words) took 0.7s, 1890163 effective words/s\n",
      "2022-03-28 21:37:58,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:58,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:58,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:58,297 : INFO : EPOCH - 3 : training on 1788017 raw words (1242410 effective words) took 0.7s, 1769684 effective words/s\n",
      "2022-03-28 21:37:59,085 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:59,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:59,092 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:59,092 : INFO : EPOCH - 4 : training on 1788017 raw words (1242935 effective words) took 0.8s, 1599858 effective words/s\n",
      "2022-03-28 21:37:59,839 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:37:59,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:37:59,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:37:59,846 : INFO : EPOCH - 5 : training on 1788017 raw words (1242092 effective words) took 0.7s, 1897853 effective words/s\n",
      "2022-03-28 21:37:59,847 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212275 effective words) took 3.9s, 1605902 effective words/s', 'datetime': '2022-03-28T21:37:59.847269', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:37:59,847 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:37:59.847566', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:37:59,850 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:37:59,942 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 4.456883668899536, 'train_time_std': 0.08273736603526577}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:38:00,228 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:00,229 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:00,294 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:00.294012', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:00,294 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:00.294502', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:00,380 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:00,383 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:00,384 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:00.384309', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:00,391 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:00,858 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:01,002 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:01,003 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:01,011 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:01.011000', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:01,011 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:01.011679', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:02,034 : INFO : EPOCH 1 - PROGRESS: at 68.16% examples, 842773 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:38:02,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:02,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:02,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:02,470 : INFO : EPOCH - 1 : training on 1788017 raw words (1243116 effective words) took 1.4s, 862534 effective words/s\n",
      "2022-03-28 21:38:03,488 : INFO : EPOCH 2 - PROGRESS: at 66.48% examples, 823280 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:03,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:03,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:03,939 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:03,940 : INFO : EPOCH - 2 : training on 1788017 raw words (1242177 effective words) took 1.5s, 854339 effective words/s\n",
      "2022-03-28 21:38:05,047 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 941935 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:05,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:05,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:05,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:05,363 : INFO : EPOCH - 3 : training on 1788017 raw words (1242597 effective words) took 1.3s, 935808 effective words/s\n",
      "2022-03-28 21:38:06,469 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 942098 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:06,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:06,779 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:06,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:06,780 : INFO : EPOCH - 4 : training on 1788017 raw words (1242163 effective words) took 1.3s, 939171 effective words/s\n",
      "2022-03-28 21:38:07,883 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 944454 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:08,184 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:08,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:08,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:08,199 : INFO : EPOCH - 5 : training on 1788017 raw words (1241967 effective words) took 1.3s, 937927 effective words/s\n",
      "2022-03-28 21:38:08,199 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212020 effective words) took 7.2s, 864289 effective words/s', 'datetime': '2022-03-28T21:38:08.199512', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:08,199 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:08.199885', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:08,203 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:08,292 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:38:08,546 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:08,547 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:08,611 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:08.611436', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:08,611 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:08.611906', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:08,694 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:08,697 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:08,698 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:08.698353', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:08,706 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:09,098 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:09,232 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:09,233 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:09,239 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:09.239793', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:09,240 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:09.240297', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:10,267 : INFO : EPOCH 1 - PROGRESS: at 69.83% examples, 858926 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:10,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:10,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:10,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:10,670 : INFO : EPOCH - 1 : training on 1788017 raw words (1243015 effective words) took 1.4s, 879100 effective words/s\n",
      "2022-03-28 21:38:11,772 : INFO : EPOCH 2 - PROGRESS: at 76.54% examples, 946705 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:12,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:12,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:12,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:12,083 : INFO : EPOCH - 2 : training on 1788017 raw words (1242179 effective words) took 1.3s, 942865 effective words/s\n",
      "2022-03-28 21:38:13,105 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 868963 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:13,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:13,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:13,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:13,496 : INFO : EPOCH - 3 : training on 1788017 raw words (1241966 effective words) took 1.4s, 888446 effective words/s\n",
      "2022-03-28 21:38:14,596 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 950588 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:14,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:14,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:14,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:14,913 : INFO : EPOCH - 4 : training on 1788017 raw words (1242418 effective words) took 1.3s, 941957 effective words/s\n",
      "2022-03-28 21:38:15,934 : INFO : EPOCH 5 - PROGRESS: at 69.83% examples, 862469 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:16,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:16,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:16,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:16,338 : INFO : EPOCH - 5 : training on 1788017 raw words (1242078 effective words) took 1.4s, 880754 effective words/s\n",
      "2022-03-28 21:38:16,339 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211656 effective words) took 7.1s, 875048 effective words/s', 'datetime': '2022-03-28T21:38:16.339341', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:16,339 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:16.339671', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:16,347 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:16,439 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:38:16,695 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:16,696 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:16,758 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:16.758644', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:16,759 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:16.759115', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:16,842 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:16,845 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:16,845 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:16.845759', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:16,854 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:17,298 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:17,434 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:17,434 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:17,441 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:17.441815', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:17,442 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:17.442494', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:18,543 : INFO : EPOCH 1 - PROGRESS: at 76.54% examples, 947295 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:18,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:18,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:18,874 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:18,874 : INFO : EPOCH - 1 : training on 1788017 raw words (1242437 effective words) took 1.3s, 928945 effective words/s\n",
      "2022-03-28 21:38:19,903 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 835186 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:20,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:20,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:20,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:20,344 : INFO : EPOCH - 2 : training on 1788017 raw words (1242168 effective words) took 1.5s, 853804 effective words/s\n",
      "2022-03-28 21:38:21,361 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 845217 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:21,774 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:21,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:21,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:21,788 : INFO : EPOCH - 3 : training on 1788017 raw words (1242197 effective words) took 1.4s, 869467 effective words/s\n",
      "2022-03-28 21:38:22,894 : INFO : EPOCH 4 - PROGRESS: at 74.86% examples, 928033 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:23,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:23,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:23,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:23,236 : INFO : EPOCH - 4 : training on 1788017 raw words (1242521 effective words) took 1.3s, 922908 effective words/s\n",
      "2022-03-28 21:38:24,266 : INFO : EPOCH 5 - PROGRESS: at 68.16% examples, 835288 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:24,688 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:24,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:24,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:24,702 : INFO : EPOCH - 5 : training on 1788017 raw words (1242873 effective words) took 1.4s, 857367 effective words/s\n",
      "2022-03-28 21:38:24,702 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212196 effective words) took 7.3s, 855727 effective words/s', 'datetime': '2022-03-28T21:38:24.702542', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:24,702 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:24.702854', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:24,710 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:24,800 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 8.286598523457846, 'train_time_std': 0.10070368940955701}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:38:25,060 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:25,061 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:25,124 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:25.124814', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:25,125 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:25.125295', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:25,210 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:25,213 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:25,213 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:25.213643', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:25,221 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:25,611 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:25,747 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:25,747 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:25,754 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:25.754616', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:25,755 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:25.755157', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:26,771 : INFO : EPOCH 1 - PROGRESS: at 69.83% examples, 867520 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:27,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:27,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:27,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:27,173 : INFO : EPOCH - 1 : training on 1788017 raw words (1243030 effective words) took 1.4s, 885890 effective words/s\n",
      "2022-03-28 21:38:28,196 : INFO : EPOCH 2 - PROGRESS: at 68.16% examples, 840441 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:28,612 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:28,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:28,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:28,627 : INFO : EPOCH - 2 : training on 1788017 raw words (1242200 effective words) took 1.4s, 864579 effective words/s\n",
      "2022-03-28 21:38:29,755 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 878985 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:30,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:30,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:30,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:30,135 : INFO : EPOCH - 3 : training on 1788017 raw words (1242310 effective words) took 1.4s, 893208 effective words/s\n",
      "2022-03-28 21:38:31,152 : INFO : EPOCH 4 - PROGRESS: at 68.16% examples, 844640 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:31,609 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:31,621 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:31,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:31,623 : INFO : EPOCH - 4 : training on 1788017 raw words (1242141 effective words) took 1.5s, 842899 effective words/s\n",
      "2022-03-28 21:38:32,647 : INFO : EPOCH 5 - PROGRESS: at 69.83% examples, 861183 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:33,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:33,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:33,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:33,068 : INFO : EPOCH - 5 : training on 1788017 raw words (1243358 effective words) took 1.4s, 869757 effective words/s\n",
      "2022-03-28 21:38:33,068 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6213039 effective words) took 7.3s, 849552 effective words/s', 'datetime': '2022-03-28T21:38:33.068808', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:33,069 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:33.069109', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:33,076 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:33,169 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:38:33,446 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:33,447 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:33,512 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:33.512601', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:33,513 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:33.513273', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:33,600 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:33,603 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:33,603 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:33.603909', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:33,612 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:34,077 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:34,218 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:34,219 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:34,225 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:34.225894', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:34,226 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:34.226436', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:35,334 : INFO : EPOCH 1 - PROGRESS: at 74.86% examples, 922557 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:35,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:35,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:35,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:35,676 : INFO : EPOCH - 1 : training on 1788017 raw words (1242978 effective words) took 1.4s, 919137 effective words/s\n",
      "2022-03-28 21:38:36,786 : INFO : EPOCH 2 - PROGRESS: at 75.98% examples, 934358 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:37,115 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:37,126 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:37,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:37,128 : INFO : EPOCH - 2 : training on 1788017 raw words (1242343 effective words) took 1.4s, 917464 effective words/s\n",
      "2022-03-28 21:38:38,145 : INFO : EPOCH 3 - PROGRESS: at 63.69% examples, 790331 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:38,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:38,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:38,643 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:38,643 : INFO : EPOCH - 3 : training on 1788017 raw words (1242545 effective words) took 1.5s, 828449 effective words/s\n",
      "2022-03-28 21:38:39,665 : INFO : EPOCH 4 - PROGRESS: at 68.72% examples, 848323 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:40,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:40,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:40,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:40,085 : INFO : EPOCH - 4 : training on 1788017 raw words (1242659 effective words) took 1.4s, 871012 effective words/s\n",
      "2022-03-28 21:38:41,188 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 904176 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:41,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:41,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:41,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:41,541 : INFO : EPOCH - 5 : training on 1788017 raw words (1242796 effective words) took 1.4s, 913852 effective words/s\n",
      "2022-03-28 21:38:41,542 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6213321 effective words) took 7.3s, 849331 effective words/s', 'datetime': '2022-03-28T21:38:41.542336', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:41,542 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:41.542714', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:41,550 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:41,643 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:38:41,898 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:41,898 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:41,961 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:41.960974', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:41,961 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:41.961666', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:42,045 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:42,048 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:42,049 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:42.049131', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:42,057 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:38:42,448 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:38:42,584 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:38:42,584 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:42,591 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:42.591548', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:42,592 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:42.592115', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:43,693 : INFO : EPOCH 1 - PROGRESS: at 73.74% examples, 912727 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:44,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:44,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:44,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:44,065 : INFO : EPOCH - 1 : training on 1788017 raw words (1243021 effective words) took 1.4s, 902450 effective words/s\n",
      "2022-03-28 21:38:45,171 : INFO : EPOCH 2 - PROGRESS: at 76.54% examples, 945436 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:45,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:45,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:45,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:45,488 : INFO : EPOCH - 2 : training on 1788017 raw words (1241749 effective words) took 1.3s, 938195 effective words/s\n",
      "2022-03-28 21:38:46,592 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 945281 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:46,894 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:46,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:46,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:46,908 : INFO : EPOCH - 3 : training on 1788017 raw words (1242606 effective words) took 1.3s, 938789 effective words/s\n",
      "2022-03-28 21:38:48,006 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 950937 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:48,309 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:48,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:48,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:48,323 : INFO : EPOCH - 4 : training on 1788017 raw words (1243201 effective words) took 1.3s, 942047 effective words/s\n",
      "2022-03-28 21:38:49,427 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 946499 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:49,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:49,741 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:49,745 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:49,745 : INFO : EPOCH - 5 : training on 1788017 raw words (1242211 effective words) took 1.3s, 937670 effective words/s\n",
      "2022-03-28 21:38:49,746 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212788 effective words) took 7.2s, 868429 effective words/s', 'datetime': '2022-03-28T21:38:49.746516', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:49,747 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:38:49.747091', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:38:49,755 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:38:49,851 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 8.348137696584066, 'train_time_std': 0.11088457735931269}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:38:50,131 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:38:50,132 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:38:50,200 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:38:50.200094', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:50,200 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:38:50.200624', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:50,285 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:38:50,289 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:38:50,289 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:38:50.289649', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:38:50,436 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:38:50,436 : INFO : resetting layer weights\n",
      "2022-03-28 21:38:50,443 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:38:50.443339', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:38:50,444 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:38:50.443990', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:38:51,549 : INFO : EPOCH 1 - PROGRESS: at 43.02% examples, 539431 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:52,561 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 548293 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:52,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:52,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:52,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:52,807 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 2.3s, 549200 effective words/s\n",
      "2022-03-28 21:38:53,825 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 489663 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:54,831 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 510816 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:55,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:55,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:55,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:55,224 : INFO : EPOCH - 2 : training on 1788017 raw words (1241311 effective words) took 2.4s, 516310 effective words/s\n",
      "2022-03-28 21:38:56,252 : INFO : EPOCH 3 - PROGRESS: at 40.78% examples, 505783 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:57,259 : INFO : EPOCH 3 - PROGRESS: at 87.15% examples, 536281 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:57,524 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:57,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:57,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:57,557 : INFO : EPOCH - 3 : training on 1788017 raw words (1242984 effective words) took 2.3s, 535613 effective words/s\n",
      "2022-03-28 21:38:58,662 : INFO : EPOCH 4 - PROGRESS: at 44.13% examples, 548296 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:59,671 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 557589 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:38:59,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:38:59,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:38:59,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:38:59,892 : INFO : EPOCH - 4 : training on 1788017 raw words (1242714 effective words) took 2.2s, 554399 effective words/s\n",
      "2022-03-28 21:39:01,004 : INFO : EPOCH 5 - PROGRESS: at 44.13% examples, 544888 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:02,006 : INFO : EPOCH 5 - PROGRESS: at 89.94% examples, 554092 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:02,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:02,240 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:02,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:02,246 : INFO : EPOCH - 5 : training on 1788017 raw words (1242331 effective words) took 2.3s, 549602 effective words/s\n",
      "2022-03-28 21:39:02,247 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210787 effective words) took 11.8s, 526215 effective words/s', 'datetime': '2022-03-28T21:39:02.247057', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:02,247 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:39:02.247364', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:39:02,255 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:39:02,351 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:39:02,630 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:39:02,630 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:39:02,694 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:39:02.694577', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:02,695 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:39:02.695041', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:02,778 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:39:02,781 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:39:02,782 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:39:02.782251', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:02,929 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:39:02,930 : INFO : resetting layer weights\n",
      "2022-03-28 21:39:02,936 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:39:02.936517', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:39:02,937 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:39:02.937073', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:04,052 : INFO : EPOCH 1 - PROGRESS: at 44.13% examples, 544095 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:05,062 : INFO : EPOCH 1 - PROGRESS: at 88.83% examples, 544362 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:05,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:05,289 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:05,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:05,305 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 2.3s, 546446 effective words/s\n",
      "2022-03-28 21:39:06,330 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 506244 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:07,350 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 522578 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:07,659 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:07,685 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:07,691 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:07,691 : INFO : EPOCH - 2 : training on 1788017 raw words (1241586 effective words) took 2.4s, 522939 effective words/s\n",
      "2022-03-28 21:39:08,706 : INFO : EPOCH 3 - PROGRESS: at 39.66% examples, 497332 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:09,709 : INFO : EPOCH 3 - PROGRESS: at 84.92% examples, 526169 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:10,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:10,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:10,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:10,071 : INFO : EPOCH - 3 : training on 1788017 raw words (1241918 effective words) took 2.4s, 524479 effective words/s\n",
      "2022-03-28 21:39:11,167 : INFO : EPOCH 4 - PROGRESS: at 43.58% examples, 546883 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:12,167 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 552162 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:12,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:12,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:12,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:12,436 : INFO : EPOCH - 4 : training on 1788017 raw words (1242930 effective words) took 2.3s, 547252 effective words/s\n",
      "2022-03-28 21:39:13,538 : INFO : EPOCH 5 - PROGRESS: at 43.58% examples, 543742 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:14,546 : INFO : EPOCH 5 - PROGRESS: at 88.83% examples, 548617 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:14,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:14,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:14,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:14,808 : INFO : EPOCH - 5 : training on 1788017 raw words (1242414 effective words) took 2.3s, 545841 effective words/s\n",
      "2022-03-28 21:39:14,808 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210295 effective words) took 11.9s, 523124 effective words/s', 'datetime': '2022-03-28T21:39:14.808906', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:14,809 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:39:14.809295', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:39:14,813 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:39:14,909 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:39:15,169 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:39:15,169 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:39:15,238 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:39:15.238605', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:15,239 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:39:15.239238', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:15,328 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:39:15,331 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:39:15,332 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:39:15.332261', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:15,477 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:39:15,478 : INFO : resetting layer weights\n",
      "2022-03-28 21:39:15,486 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:39:15.486208', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:39:15,486 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:39:15.486899', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:16,511 : INFO : EPOCH 1 - PROGRESS: at 39.11% examples, 489193 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:17,526 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 525320 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:17,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:17,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:17,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:17,866 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 2.4s, 525531 effective words/s\n",
      "2022-03-28 21:39:18,980 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 543879 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:19,994 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 554036 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:20,182 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:20,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:20,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:20,215 : INFO : EPOCH - 2 : training on 1788017 raw words (1241586 effective words) took 2.3s, 551106 effective words/s\n",
      "2022-03-28 21:39:21,335 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 541902 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:22,346 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 546912 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:22,565 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:22,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:22,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:22,594 : INFO : EPOCH - 3 : training on 1788017 raw words (1241921 effective words) took 2.3s, 544460 effective words/s\n",
      "2022-03-28 21:39:23,714 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 521067 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:24,715 : INFO : EPOCH 4 - PROGRESS: at 88.27% examples, 542693 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:24,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:24,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:24,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:24,989 : INFO : EPOCH - 4 : training on 1788017 raw words (1243115 effective words) took 2.3s, 540694 effective words/s\n",
      "2022-03-28 21:39:26,096 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 527826 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:27,102 : INFO : EPOCH 5 - PROGRESS: at 86.03% examples, 530570 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:39:27,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:27,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:27,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:27,434 : INFO : EPOCH - 5 : training on 1788017 raw words (1242478 effective words) took 2.3s, 528764 effective words/s\n",
      "2022-03-28 21:39:27,434 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210547 effective words) took 11.9s, 519814 effective words/s', 'datetime': '2022-03-28T21:39:27.434984', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:27,435 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:39:27.435280', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:39:27,439 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:39:27,540 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 12.56143856048584, 'train_time_std': 0.051312316806866466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:39:27,811 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:39:27,811 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:39:27,875 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:39:27.875608', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:27,876 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:39:27.876105', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:27,960 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:39:27,963 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:39:27,964 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:39:27.964317', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:28,104 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:39:28,105 : INFO : resetting layer weights\n",
      "2022-03-28 21:39:28,112 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:39:28.112502', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:39:28,113 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:39:28.113048', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:29,230 : INFO : EPOCH 1 - PROGRESS: at 44.13% examples, 543827 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:30,239 : INFO : EPOCH 1 - PROGRESS: at 90.50% examples, 554891 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:30,438 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:30,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:30,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:30,470 : INFO : EPOCH - 1 : training on 1788017 raw words (1241572 effective words) took 2.3s, 549532 effective words/s\n",
      "2022-03-28 21:39:31,587 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 543798 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:32,589 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 550360 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:32,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:32,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:32,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:32,836 : INFO : EPOCH - 2 : training on 1788017 raw words (1242497 effective words) took 2.3s, 547771 effective words/s\n",
      "2022-03-28 21:39:33,849 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 463494 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:34,853 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 485539 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:35,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:35,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:35,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:35,359 : INFO : EPOCH - 3 : training on 1788017 raw words (1242125 effective words) took 2.5s, 494815 effective words/s\n",
      "2022-03-28 21:39:36,375 : INFO : EPOCH 4 - PROGRESS: at 36.31% examples, 454987 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:37,376 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 488857 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:37,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:37,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:37,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:37,854 : INFO : EPOCH - 4 : training on 1788017 raw words (1242192 effective words) took 2.5s, 500465 effective words/s\n",
      "2022-03-28 21:39:38,973 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 524236 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:39,978 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 535923 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:40,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:40,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:40,274 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:40,275 : INFO : EPOCH - 5 : training on 1788017 raw words (1242241 effective words) took 2.3s, 535397 effective words/s\n",
      "2022-03-28 21:39:40,275 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210627 effective words) took 12.2s, 510636 effective words/s', 'datetime': '2022-03-28T21:39:40.275911', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:40,276 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:39:40.276413', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:39:40,280 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:39:40,381 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:39:40,656 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:39:40,657 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:39:40,725 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:39:40.725387', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:40,725 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:39:40.725858', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:40,813 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:39:40,816 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:39:40,816 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:39:40.816664', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:40,960 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:39:40,961 : INFO : resetting layer weights\n",
      "2022-03-28 21:39:40,969 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:39:40.968980', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:39:40,969 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:39:40.969572', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:42,008 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 502356 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:39:43,023 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 531949 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:43,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:43,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:43,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:43,319 : INFO : EPOCH - 1 : training on 1788017 raw words (1241630 effective words) took 2.3s, 531969 effective words/s\n",
      "2022-03-28 21:39:44,420 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 491090 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:45,424 : INFO : EPOCH 2 - PROGRESS: at 81.56% examples, 505553 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:39:45,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:45,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:45,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:45,899 : INFO : EPOCH - 2 : training on 1788017 raw words (1242155 effective words) took 2.5s, 500632 effective words/s\n",
      "2022-03-28 21:39:47,018 : INFO : EPOCH 3 - PROGRESS: at 44.13% examples, 545678 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:48,036 : INFO : EPOCH 3 - PROGRESS: at 91.06% examples, 557029 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:48,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:48,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:48,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:48,458 : INFO : EPOCH - 3 : training on 1788017 raw words (1242134 effective words) took 2.5s, 505708 effective words/s\n",
      "2022-03-28 21:39:49,643 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 346072 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:50,656 : INFO : EPOCH 4 - PROGRESS: at 72.63% examples, 447714 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:51,236 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:51,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:51,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:51,269 : INFO : EPOCH - 4 : training on 1788017 raw words (1241879 effective words) took 2.6s, 472266 effective words/s\n",
      "2022-03-28 21:39:52,290 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 509301 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:53,291 : INFO : EPOCH 5 - PROGRESS: at 86.59% examples, 536506 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:53,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:53,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:53,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:53,601 : INFO : EPOCH - 5 : training on 1788017 raw words (1242757 effective words) took 2.3s, 535846 effective words/s\n",
      "2022-03-28 21:39:53,601 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210555 effective words) took 12.6s, 491656 effective words/s', 'datetime': '2022-03-28T21:39:53.601820', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:53,602 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:39:53.602158', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:39:53,606 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:39:53,705 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:39:53,983 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:39:53,984 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:39:54,048 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:39:54.048254', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:54,048 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:39:54.048856', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:54,132 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:39:54,135 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:39:54,136 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:39:54.136420', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:39:54,286 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2022-03-28 21:39:54,287 : INFO : resetting layer weights\n",
      "2022-03-28 21:39:54,294 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:39:54.294516', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:39:54,295 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:39:54.295211', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:39:55,317 : INFO : EPOCH 1 - PROGRESS: at 39.66% examples, 495560 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:56,321 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 528111 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:56,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:56,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:56,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:56,647 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 2.3s, 530901 effective words/s\n",
      "2022-03-28 21:39:57,661 : INFO : EPOCH 2 - PROGRESS: at 40.22% examples, 505630 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:58,663 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 530280 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:39:58,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:39:59,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:39:59,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:39:59,007 : INFO : EPOCH - 2 : training on 1788017 raw words (1241542 effective words) took 2.3s, 528956 effective words/s\n",
      "2022-03-28 21:40:00,144 : INFO : EPOCH 3 - PROGRESS: at 40.78% examples, 502720 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:01,144 : INFO : EPOCH 3 - PROGRESS: at 83.80% examples, 515587 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:01,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:01,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:01,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:01,530 : INFO : EPOCH - 3 : training on 1788017 raw words (1242433 effective words) took 2.4s, 515927 effective words/s\n",
      "2022-03-28 21:40:02,644 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 505718 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:03,652 : INFO : EPOCH 4 - PROGRESS: at 84.92% examples, 521825 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:40:03,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:04,023 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:04,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:04,030 : INFO : EPOCH - 4 : training on 1788017 raw words (1241826 effective words) took 2.4s, 517389 effective words/s\n",
      "2022-03-28 21:40:05,133 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 512173 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:06,134 : INFO : EPOCH 5 - PROGRESS: at 84.36% examples, 523781 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:40:06,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:06,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:06,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:06,501 : INFO : EPOCH - 5 : training on 1788017 raw words (1241938 effective words) took 2.4s, 523930 effective words/s\n",
      "2022-03-28 21:40:06,502 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209186 effective words) took 12.2s, 508680 effective words/s', 'datetime': '2022-03-28T21:40:06.502067', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:40:06,502 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:40:06.502429', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:40:06,506 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:40:06,608 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 13.022214968999227, 'train_time_std': 0.21586570198123972}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:40:06,894 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:40:06,895 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:40:06,960 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:40:06.960473', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:06,961 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:40:06.961025', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:07,045 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:40:07,048 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:40:07,049 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:40:07.049320', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:07,057 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:40:07,460 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:40:07,601 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:40:07,602 : INFO : resetting layer weights\n",
      "2022-03-28 21:40:07,608 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:40:07.608944', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:40:07,609 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:40:07.609541', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:40:08,633 : INFO : EPOCH 1 - PROGRESS: at 17.88% examples, 225871 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:09,648 : INFO : EPOCH 1 - PROGRESS: at 36.31% examples, 226148 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:10,655 : INFO : EPOCH 1 - PROGRESS: at 58.10% examples, 238936 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:11,674 : INFO : EPOCH 1 - PROGRESS: at 79.89% examples, 245445 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:12,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:12,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:12,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:12,617 : INFO : EPOCH - 1 : training on 1788017 raw words (1241455 effective words) took 5.0s, 248735 effective words/s\n",
      "2022-03-28 21:40:13,686 : INFO : EPOCH 2 - PROGRESS: at 18.99% examples, 229154 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:14,699 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 248475 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:15,704 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 253152 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:16,719 : INFO : EPOCH 2 - PROGRESS: at 84.36% examples, 256814 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:17,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:17,436 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:17,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:17,449 : INFO : EPOCH - 2 : training on 1788017 raw words (1241586 effective words) took 4.8s, 257872 effective words/s\n",
      "2022-03-28 21:40:18,552 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 239802 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:19,559 : INFO : EPOCH 3 - PROGRESS: at 40.22% examples, 251490 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:20,560 : INFO : EPOCH 3 - PROGRESS: at 61.45% examples, 253432 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:21,581 : INFO : EPOCH 3 - PROGRESS: at 82.68% examples, 254875 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:22,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:22,418 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:22,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:22,428 : INFO : EPOCH - 3 : training on 1788017 raw words (1241928 effective words) took 4.9s, 254471 effective words/s\n",
      "2022-03-28 21:40:23,552 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 237540 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:24,554 : INFO : EPOCH 4 - PROGRESS: at 39.66% examples, 247470 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:25,562 : INFO : EPOCH 4 - PROGRESS: at 61.45% examples, 252432 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:26,573 : INFO : EPOCH 4 - PROGRESS: at 82.68% examples, 254749 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:27,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:27,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:27,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:27,414 : INFO : EPOCH - 4 : training on 1788017 raw words (1242208 effective words) took 4.9s, 254663 effective words/s\n",
      "2022-03-28 21:40:28,497 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 225802 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:29,513 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 246363 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:30,522 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 251322 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:31,525 : INFO : EPOCH 5 - PROGRESS: at 83.80% examples, 254483 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:32,226 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:32,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:32,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:32,298 : INFO : EPOCH - 5 : training on 1788017 raw words (1242046 effective words) took 4.9s, 255100 effective words/s\n",
      "2022-03-28 21:40:32,299 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209223 effective words) took 24.7s, 251492 effective words/s', 'datetime': '2022-03-28T21:40:32.299394', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:40:32,300 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:40:32.300043', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:40:32,302 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:40:32,402 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:40:32,677 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:40:32,678 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:40:32,744 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:40:32.744357', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:32,744 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:40:32.744869', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:32,830 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:40:32,833 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:40:32,833 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:40:32.833960', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:32,841 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:40:33,316 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:40:33,453 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:40:33,454 : INFO : resetting layer weights\n",
      "2022-03-28 21:40:33,461 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:40:33.461034', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:40:33,461 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:40:33.461862', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:40:34,567 : INFO : EPOCH 1 - PROGRESS: at 19.55% examples, 246181 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:35,591 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 252637 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:36,599 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 255621 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:37,615 : INFO : EPOCH 1 - PROGRESS: at 84.36% examples, 258656 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:38,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:38,339 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:38,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:38,351 : INFO : EPOCH - 1 : training on 1788017 raw words (1241449 effective words) took 4.8s, 259025 effective words/s\n",
      "2022-03-28 21:40:39,489 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 252270 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:40,518 : INFO : EPOCH 2 - PROGRESS: at 41.34% examples, 251241 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:41,534 : INFO : EPOCH 2 - PROGRESS: at 62.57% examples, 251922 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:42,552 : INFO : EPOCH 2 - PROGRESS: at 83.24% examples, 252320 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:43,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:43,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:43,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:43,368 : INFO : EPOCH - 2 : training on 1788017 raw words (1241652 effective words) took 4.9s, 252472 effective words/s\n",
      "2022-03-28 21:40:44,491 : INFO : EPOCH 3 - PROGRESS: at 18.99% examples, 235841 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:45,521 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 229449 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:40:46,570 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 231272 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:47,615 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 234659 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:48,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:48,631 : INFO : EPOCH 3 - PROGRESS: at 99.44% examples, 239242 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-28 21:40:48,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:48,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:48,641 : INFO : EPOCH - 3 : training on 1788017 raw words (1241779 effective words) took 5.2s, 240097 effective words/s\n",
      "2022-03-28 21:40:49,742 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 248080 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:50,769 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 253282 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:51,777 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 256096 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:52,779 : INFO : EPOCH 4 - PROGRESS: at 83.80% examples, 258220 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:53,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:53,519 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:53,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:53,531 : INFO : EPOCH - 4 : training on 1788017 raw words (1242309 effective words) took 4.8s, 259392 effective words/s\n",
      "2022-03-28 21:40:54,603 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 228459 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:55,637 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 245692 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:56,658 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 249878 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:57,695 : INFO : EPOCH 5 - PROGRESS: at 83.80% examples, 251384 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:40:58,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:40:58,438 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:40:58,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:40:58,449 : INFO : EPOCH - 5 : training on 1788017 raw words (1242589 effective words) took 4.9s, 253501 effective words/s\n",
      "2022-03-28 21:40:58,449 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209778 effective words) took 25.0s, 248520 effective words/s', 'datetime': '2022-03-28T21:40:58.449470', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:40:58,449 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:40:58.449828', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:40:58,457 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:40:58,552 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:40:58,813 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:40:58,813 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:40:58,877 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:40:58.877635', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:58,878 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:40:58.878238', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:58,962 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:40:58,965 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:40:58,965 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:40:58.965682', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:40:58,973 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:40:59,363 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:40:59,502 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:40:59,503 : INFO : resetting layer weights\n",
      "2022-03-28 21:40:59,510 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:40:59.510646', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:40:59,511 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:40:59.511246', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:41:00,661 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 248507 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:01,677 : INFO : EPOCH 1 - PROGRESS: at 42.46% examples, 257724 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:41:02,686 : INFO : EPOCH 1 - PROGRESS: at 64.80% examples, 261328 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:03,697 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 261449 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:04,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:04,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:04,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:04,345 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 4.7s, 261909 effective words/s\n",
      "2022-03-28 21:41:05,487 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 251063 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:06,497 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 259574 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:07,514 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 261908 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:08,522 : INFO : EPOCH 2 - PROGRESS: at 86.03% examples, 262146 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:09,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:09,153 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:09,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:09,165 : INFO : EPOCH - 2 : training on 1788017 raw words (1241586 effective words) took 4.7s, 262844 effective words/s\n",
      "2022-03-28 21:41:10,302 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 252604 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:11,315 : INFO : EPOCH 3 - PROGRESS: at 42.46% examples, 259909 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:12,323 : INFO : EPOCH 3 - PROGRESS: at 64.80% examples, 262995 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:13,324 : INFO : EPOCH 3 - PROGRESS: at 86.03% examples, 263508 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:13,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:13,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:13,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:13,970 : INFO : EPOCH - 3 : training on 1788017 raw words (1241928 effective words) took 4.7s, 263837 effective words/s\n",
      "2022-03-28 21:41:15,027 : INFO : EPOCH 4 - PROGRESS: at 18.99% examples, 231606 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:16,042 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 249691 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:17,050 : INFO : EPOCH 4 - PROGRESS: at 63.13% examples, 256001 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:18,059 : INFO : EPOCH 4 - PROGRESS: at 84.36% examples, 257812 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:18,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:18,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:18,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:18,794 : INFO : EPOCH - 4 : training on 1788017 raw words (1243116 effective words) took 4.8s, 258548 effective words/s\n",
      "2022-03-28 21:41:19,847 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 232285 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:20,862 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 250088 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:21,875 : INFO : EPOCH 5 - PROGRESS: at 63.13% examples, 255798 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:22,898 : INFO : EPOCH 5 - PROGRESS: at 83.24% examples, 253236 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:23,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:23,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:23,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:23,690 : INFO : EPOCH - 5 : training on 1788017 raw words (1241974 effective words) took 4.9s, 254498 effective words/s\n",
      "2022-03-28 21:41:23,690 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6210051 effective words) took 24.2s, 256836 effective words/s', 'datetime': '2022-03-28T21:41:23.690590', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:41:23,690 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:41:23.690956', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:41:23,700 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:41:23,793 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 25.73131004969279, 'train_time_std': 0.3753458229353182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:41:24,052 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:41:24,053 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:41:24,116 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:41:24.116892', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:24,117 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:41:24.117370', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:24,201 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:41:24,204 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:41:24,205 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:41:24.205362', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:24,213 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:41:24,665 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:41:24,801 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:41:24,802 : INFO : resetting layer weights\n",
      "2022-03-28 21:41:24,809 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:41:24.809566', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:41:24,810 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:41:24.810115', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:41:25,860 : INFO : EPOCH 1 - PROGRESS: at 18.99% examples, 232848 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:26,864 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 251867 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:27,868 : INFO : EPOCH 1 - PROGRESS: at 63.13% examples, 257654 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:28,919 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 259525 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:29,536 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:29,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:29,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:29,584 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 4.8s, 260889 effective words/s\n",
      "2022-03-28 21:41:30,643 : INFO : EPOCH 2 - PROGRESS: at 18.99% examples, 231297 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:31,667 : INFO : EPOCH 2 - PROGRESS: at 41.34% examples, 251412 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:32,695 : INFO : EPOCH 2 - PROGRESS: at 64.25% examples, 257788 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:33,702 : INFO : EPOCH 2 - PROGRESS: at 86.03% examples, 260809 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:34,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:34,329 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:34,341 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:34,341 : INFO : EPOCH - 2 : training on 1788017 raw words (1241586 effective words) took 4.7s, 261886 effective words/s\n",
      "2022-03-28 21:41:35,460 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 256870 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:36,462 : INFO : EPOCH 3 - PROGRESS: at 42.46% examples, 263505 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:37,510 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 266392 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:38,521 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 267131 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:39,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:39,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:39,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:39,073 : INFO : EPOCH - 3 : training on 1788017 raw words (1241556 effective words) took 4.6s, 267876 effective words/s\n",
      "2022-03-28 21:41:40,208 : INFO : EPOCH 4 - PROGRESS: at 20.67% examples, 252412 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:41,214 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 260795 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:42,217 : INFO : EPOCH 4 - PROGRESS: at 65.36% examples, 266331 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:43,224 : INFO : EPOCH 4 - PROGRESS: at 87.15% examples, 267309 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:43,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:43,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:43,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:43,827 : INFO : EPOCH - 4 : training on 1788017 raw words (1242178 effective words) took 4.7s, 266651 effective words/s\n",
      "2022-03-28 21:41:44,857 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 237597 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:45,882 : INFO : EPOCH 5 - PROGRESS: at 41.34% examples, 254925 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:46,894 : INFO : EPOCH 5 - PROGRESS: at 64.25% examples, 261533 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:47,895 : INFO : EPOCH 5 - PROGRESS: at 85.47% examples, 262320 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:48,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:48,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:48,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:48,551 : INFO : EPOCH - 5 : training on 1788017 raw words (1242385 effective words) took 4.7s, 263854 effective words/s\n",
      "2022-03-28 21:41:48,551 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6209152 effective words) took 23.7s, 261535 effective words/s', 'datetime': '2022-03-28T21:41:48.551548', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:41:48,551 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:41:48.551925', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:41:48,560 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:41:48,652 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:41:48,911 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:41:48,911 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:41:48,975 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:41:48.975758', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:48,976 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:41:48.976315', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:49,060 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:41:49,063 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:41:49,064 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:41:49.064201', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:41:49,072 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:41:49,454 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:41:49,590 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:41:49,591 : INFO : resetting layer weights\n",
      "2022-03-28 21:41:49,600 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:41:49.600101', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:41:49,600 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:41:49.600741', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:41:50,721 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 256242 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:51,731 : INFO : EPOCH 1 - PROGRESS: at 43.02% examples, 265877 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:52,735 : INFO : EPOCH 1 - PROGRESS: at 65.36% examples, 267527 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:53,766 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 266581 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:54,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:54,339 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:54,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:54,351 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 4.7s, 267010 effective words/s\n",
      "2022-03-28 21:41:55,464 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 258582 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:56,471 : INFO : EPOCH 2 - PROGRESS: at 43.02% examples, 267351 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:57,490 : INFO : EPOCH 2 - PROGRESS: at 65.36% examples, 267134 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:58,508 : INFO : EPOCH 2 - PROGRESS: at 87.15% examples, 267080 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:41:59,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:41:59,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:41:59,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:41:59,082 : INFO : EPOCH - 2 : training on 1788017 raw words (1242297 effective words) took 4.6s, 268092 effective words/s\n",
      "2022-03-28 21:42:00,222 : INFO : EPOCH 3 - PROGRESS: at 20.67% examples, 251980 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:01,234 : INFO : EPOCH 3 - PROGRESS: at 42.46% examples, 259873 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:02,245 : INFO : EPOCH 3 - PROGRESS: at 64.80% examples, 262634 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:03,269 : INFO : EPOCH 3 - PROGRESS: at 86.03% examples, 261697 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:03,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:03,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:03,903 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:03,903 : INFO : EPOCH - 3 : training on 1788017 raw words (1241904 effective words) took 4.7s, 262938 effective words/s\n",
      "2022-03-28 21:42:04,984 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 206626 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:06,005 : INFO : EPOCH 4 - PROGRESS: at 37.43% examples, 225921 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:07,020 : INFO : EPOCH 4 - PROGRESS: at 58.10% examples, 233568 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:08,054 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 235494 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:09,056 : INFO : EPOCH 4 - PROGRESS: at 98.88% examples, 239533 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-28 21:42:09,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:09,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:09,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:09,108 : INFO : EPOCH - 4 : training on 1788017 raw words (1242427 effective words) took 5.2s, 239484 effective words/s\n",
      "2022-03-28 21:42:10,265 : INFO : EPOCH 5 - PROGRESS: at 20.67% examples, 247273 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:42:11,302 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 254457 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:12,309 : INFO : EPOCH 5 - PROGRESS: at 64.80% examples, 259314 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:13,329 : INFO : EPOCH 5 - PROGRESS: at 86.03% examples, 259490 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:13,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:13,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:13,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:13,975 : INFO : EPOCH - 5 : training on 1788017 raw words (1242630 effective words) took 4.8s, 260412 effective words/s\n",
      "2022-03-28 21:42:13,975 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6212206 effective words) took 24.4s, 254863 effective words/s', 'datetime': '2022-03-28T21:42:13.975749', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:42:13,976 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:42:13.976101', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-03-28 21:42:13,984 : INFO : collecting all words and their counts\n",
      "2022-03-28 21:42:14,079 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 21:42:14,337 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2022-03-28 21:42:14,338 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 21:42:14,402 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 20167 unique words (27.562972378257957%% of original 73167, drops 53000)', 'datetime': '2022-03-28T21:42:14.402385', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:42:14,402 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1703716 word corpus (95.28522379820774%% of original 1788017, drops 84301)', 'datetime': '2022-03-28T21:42:14.402861', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:42:14,486 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2022-03-28 21:42:14,488 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2022-03-28 21:42:14,489 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1242287.3013176506 word corpus (72.9%% of prior 1703716)', 'datetime': '2022-03-28T21:42:14.489300', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 21:42:14,498 : INFO : constructing a huffman tree from 20167 words\n",
      "2022-03-28 21:42:14,947 : INFO : built huffman tree with maximum node depth 18\n",
      "2022-03-28 21:42:15,081 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2022-03-28 21:42:15,081 : INFO : resetting layer weights\n",
      "2022-03-28 21:42:15,089 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T21:42:15.089258', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 21:42:15,089 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T21:42:15.089796', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:42:16,207 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 256942 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:17,224 : INFO : EPOCH 1 - PROGRESS: at 43.58% examples, 268661 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:18,255 : INFO : EPOCH 1 - PROGRESS: at 65.92% examples, 266765 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:19,279 : INFO : EPOCH 1 - PROGRESS: at 87.71% examples, 266564 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:19,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:19,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:19,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:19,855 : INFO : EPOCH - 1 : training on 1788017 raw words (1242204 effective words) took 4.7s, 266052 effective words/s\n",
      "2022-03-28 21:42:21,008 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 248509 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:22,038 : INFO : EPOCH 2 - PROGRESS: at 42.46% examples, 255874 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:23,039 : INFO : EPOCH 2 - PROGRESS: at 63.69% examples, 256310 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:24,065 : INFO : EPOCH 2 - PROGRESS: at 84.36% examples, 254997 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:24,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:24,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:24,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:24,827 : INFO : EPOCH - 2 : training on 1788017 raw words (1242135 effective words) took 4.9s, 254802 effective words/s\n",
      "2022-03-28 21:42:25,848 : INFO : EPOCH 3 - PROGRESS: at 17.88% examples, 226049 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:26,886 : INFO : EPOCH 3 - PROGRESS: at 39.11% examples, 241076 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:27,909 : INFO : EPOCH 3 - PROGRESS: at 60.89% examples, 246912 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:28,929 : INFO : EPOCH 3 - PROGRESS: at 82.68% examples, 251692 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:29,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:29,741 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:29,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:29,752 : INFO : EPOCH - 3 : training on 1788017 raw words (1242528 effective words) took 4.9s, 253094 effective words/s\n",
      "2022-03-28 21:42:30,852 : INFO : EPOCH 4 - PROGRESS: at 19.55% examples, 248208 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:31,878 : INFO : EPOCH 4 - PROGRESS: at 40.78% examples, 253357 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 21:42:32,887 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 256111 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:33,916 : INFO : EPOCH 4 - PROGRESS: at 84.36% examples, 258198 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:34,584 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:34,637 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:34,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:34,649 : INFO : EPOCH - 4 : training on 1788017 raw words (1242172 effective words) took 4.8s, 258897 effective words/s\n",
      "2022-03-28 21:42:35,803 : INFO : EPOCH 5 - PROGRESS: at 20.67% examples, 248730 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:36,809 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 258991 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:37,811 : INFO : EPOCH 5 - PROGRESS: at 64.80% examples, 262958 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:38,851 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 264316 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 21:42:39,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 21:42:39,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 21:42:39,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 21:42:39,441 : INFO : EPOCH - 5 : training on 1788017 raw words (1242411 effective words) took 4.7s, 264803 effective words/s\n",
      "2022-03-28 21:42:39,441 : INFO : Word2Vec lifecycle event {'msg': 'training on 8940085 raw words (6211450 effective words) took 24.4s, 255077 effective words/s', 'datetime': '2022-03-28T21:42:39.441363', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 21:42:39,441 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=20167, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T21:42:39.441687', 'gensim': '4.1.2', 'python': '3.8.3 (default, Jul  2 2020, 11:26:31) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 25.249700864156086, 'train_time_std': 0.27665106453907473}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         0.341311        0.000161\n",
      "5        25kB         False   1   0         0.339087        0.001778\n",
      "6        25kB          True   1   1         0.655231        0.002334\n",
      "7        25kB         False   1   1         0.655987        0.009579\n",
      "0        25kB          True   0   0         0.165069        0.001814\n",
      "1        25kB         False   0   0         0.161866        0.002292\n",
      "2        25kB          True   0   1         0.281972        0.002958\n",
      "3        25kB         False   0   1         0.280418        0.003571\n",
      "12        1MB          True   1   0         1.092354        0.005114\n",
      "13        1MB         False   1   0         1.071918        0.006724\n",
      "14        1MB          True   1   1         2.168355        0.013760\n",
      "15        1MB         False   1   1         2.139054        0.008087\n",
      "8         1MB          True   0   0         0.447635        0.003708\n",
      "9         1MB         False   0   0         0.443851        0.000789\n",
      "10        1MB          True   0   1         0.838356        0.030723\n",
      "11        1MB         False   0   1         0.806518        0.011978\n",
      "20       10MB          True   1   0        12.561439        0.051312\n",
      "21       10MB         False   1   0        13.022215        0.215866\n",
      "22       10MB          True   1   1        25.731310        0.375346\n",
      "23       10MB         False   1   1        25.249701        0.276651\n",
      "16       10MB          True   0   0         4.303005        0.019666\n",
      "17       10MB         False   0   0         4.456884        0.082737\n",
      "18       10MB          True   0   1         8.286599        0.100704\n",
      "19       10MB         False   0   1         8.348138        0.110885\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising Word Embeddings\n",
    "---------------------------\n",
    "\n",
    "The word embeddings made by the model can be visualised by reducing\n",
    "dimensionality of the words to 2 dimensions using tSNE.\n",
    "\n",
    "Visualisations can be used to notice semantic and syntactic trends in the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Semantic: words like cat, dog, cow, etc. have a tendency to lie close by\n",
    "* Syntactic: words like run, running or cut, cutting lie close together.\n",
    "\n",
    "Vector relations like vKing - vMan = vQueen - vWoman can also be noticed.\n",
    "\n",
    ".. Important::\n",
    "  The model used for the visualisation is trained on a small corpus. Thus\n",
    "  some of the relations might not be so clear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "the",
          "to",
          "of",
          "in",
          "and",
          "he",
          "is",
          "for",
          "on",
          "said",
          "that",
          "has",
          "says",
          "was",
          "have",
          "it",
          "be",
          "are",
          "with",
          "will",
          "at",
          "mr",
          "from",
          "by",
          "we",
          "been",
          "as",
          "an",
          "not",
          "his",
          "but",
          "they",
          "after",
          "were",
          "had",
          "there",
          "new",
          "this",
          "australia",
          "australian",
          "who",
          "palestinian",
          "people",
          "their",
          "government",
          "two",
          "up",
          "south",
          "us",
          "which",
          "year",
          "one",
          "about",
          "out",
          "if",
          "also",
          "more",
          "when",
          "its",
          "into",
          "would",
          "first",
          "last",
          "against",
          "israeli",
          "minister",
          "arafat",
          "over",
          "all",
          "three",
          "afghanistan",
          "united",
          "world",
          "no",
          "or",
          "police",
          "than",
          "attacks",
          "fire",
          "before",
          "some",
          "security",
          "day",
          "you",
          "states",
          "could",
          "them",
          "say",
          "today",
          "now",
          "told",
          "time",
          "any",
          "laden",
          "very",
          "bin",
          "just",
          "can",
          "sydney",
          "what",
          "still",
          "company",
          "president",
          "man",
          "four",
          "taliban",
          "killed",
          "our",
          "forces",
          "al",
          "around",
          "being",
          "days",
          "west",
          "old",
          "other",
          "officials",
          "where",
          "so",
          "test",
          "qaeda",
          "israel",
          "think",
          "per",
          "general",
          "next",
          "federal",
          "force",
          "cent",
          "she",
          "leader",
          "yesterday",
          "workers",
          "take",
          "him",
          "hamas",
          "under",
          "state",
          "those",
          "years",
          "meeting",
          "bank",
          "suicide",
          "back",
          "action",
          "commission",
          "made",
          "down",
          "morning",
          "re",
          "pakistan",
          "international",
          "city",
          "attack",
          "centre",
          "group",
          "afghan",
          "members",
          "while",
          "military",
          "well",
          "number",
          "through",
          "qantas",
          "five",
          "local",
          "called",
          "area",
          "union",
          "gaza",
          "week",
          "national",
          "since",
          "wales",
          "including",
          "hours",
          "september",
          "another",
          "east",
          "night",
          "report",
          "off",
          "north",
          "should",
          "get",
          "second",
          "go",
          "earlier",
          "war",
          "staff",
          "six",
          "these",
          "between",
          "islamic",
          "months",
          "further",
          "end",
          "defence",
          "do",
          "sharon",
          "near",
          "team",
          "foreign",
          "power",
          "areas",
          "work",
          "going",
          "authority",
          "because",
          "way",
          "eight",
          "india",
          "only",
          "know",
          "month",
          "during",
          "died",
          "many",
          "match",
          "make",
          "air",
          "metres",
          "left",
          "claims",
          "spokesman",
          "ve",
          "former",
          "melbourne",
          "northern",
          "good",
          "authorities",
          "most",
          "osama",
          "support",
          "prime",
          "peace",
          "like",
          "set",
          "ago",
          "expected",
          "saying",
          "given",
          "am",
          "come",
          "looking",
          "militants",
          "bora",
          "tora",
          "put",
          "place",
          "several",
          "fighters",
          "children",
          "arrested",
          "injured",
          "found",
          "river",
          "royal",
          "groups",
          "africa",
          "unions",
          "christmas",
          "troops",
          "meanwhile",
          "indian",
          "child",
          "hospital",
          "terrorist",
          "interim",
          "part",
          "reports",
          "talks",
          "official",
          "whether",
          "then",
          "yasser",
          "statement",
          "leaders",
          "economy",
          "mountains",
          "how",
          "industrial",
          "third",
          "terrorism",
          "senior",
          "start",
          "don",
          "early",
          "radio",
          "john",
          "hit",
          "trying",
          "weather",
          "public",
          "both",
          "believe",
          "family",
          "pay",
          "million",
          "army",
          "court",
          "dr",
          "long",
          "best",
          "control",
          "help",
          "however",
          "lead",
          "adelaide",
          "asked",
          "following",
          "chief",
          "pressure",
          "agreement",
          "does",
          "service",
          "firefighters",
          "close",
          "few",
          "services",
          "labor",
          "play",
          "better",
          "community",
          "taken",
          "want",
          "arrest",
          "queensland",
          "house",
          "need",
          "overnight",
          "australians",
          "high",
          "confirmed",
          "process",
          "information",
          "came",
          "believed",
          "williams",
          "must",
          "opposition",
          "detainees",
          "won",
          "secretary",
          "did",
          "peter",
          "party",
          "held",
          "damage",
          "governor",
          "maintenance",
          "released",
          "win",
          "pentagon",
          "possible",
          "her",
          "brought",
          "hicks",
          "much",
          "shot",
          "took",
          "accused",
          "nations",
          "british",
          "weekend",
          "lot",
          "violence",
          "building",
          "despite",
          "council",
          "return",
          "got",
          "airline",
          "asylum",
          "york",
          "dead",
          "kandahar",
          "conditions",
          "across",
          "hill",
          "winds",
          "safety",
          "even",
          "such",
          "change",
          "cut",
          "eastern",
          "without",
          "director",
          "armed",
          "working",
          "aircraft",
          "call",
          "here",
          "see",
          "palestinians",
          "december",
          "economic",
          "news",
          "american",
          "too",
          "home",
          "men",
          "seekers",
          "strip",
          "lee",
          "waugh",
          "role",
          "country",
          "region",
          "trade",
          "emergency",
          "crew",
          "strong",
          "race",
          "captured",
          "david",
          "southern",
          "fighting",
          "continuing",
          "fires",
          "monday",
          "far",
          "anti",
          "board",
          "cricket",
          "training",
          "key",
          "plans",
          "bush",
          "bureau",
          "act",
          "industry",
          "george",
          "head",
          "past",
          "water",
          "charged",
          "used",
          "administration",
          "received",
          "offer",
          "alliance",
          "rate",
          "zinni",
          "health",
          "least",
          "leading",
          "person",
          "captain",
          "your",
          "town",
          "boat",
          "large",
          "decision",
          "stop",
          "known",
          "airport",
          "operations",
          "may",
          "line",
          "within",
          "risk",
          "use",
          "downer",
          "israelis",
          "soldiers",
          "major",
          "britain",
          "final",
          "parliament",
          "department",
          "zealand",
          "hundreds",
          "issue",
          "strikes",
          "hih",
          "station",
          "legal",
          "shane",
          "plane",
          "might",
          "series",
          "interest",
          "un",
          "laws",
          "policy",
          "right",
          "ahead",
          "hollingworth",
          "tomorrow",
          "network",
          "pm",
          "able",
          "due",
          "kabul",
          "latest",
          "death",
          "homes",
          "weapons",
          "behind",
          "great",
          "coast",
          "western",
          "position",
          "give",
          "later",
          "late",
          "half",
          "officers",
          "my",
          "taking",
          "every",
          "remain",
          "campaign",
          "seen",
          "thought",
          "bill",
          "timor",
          "special",
          "side",
          "failed",
          "same",
          "flight",
          "along",
          "jobs",
          "storm",
          "me",
          "forced",
          "life",
          "others",
          "continue",
          "hard",
          "event",
          "abuse",
          "cup",
          "victory",
          "jihad",
          "guilty",
          "point",
          "towards",
          "really",
          "concerned",
          "heard",
          "already",
          "territory",
          "washington",
          "deaths",
          "mcgrath",
          "helicopters",
          "envoy",
          "canyoning",
          "capital",
          "bus",
          "bichel",
          "november",
          "likely",
          "details",
          "case",
          "member",
          "launched",
          "innings",
          "according",
          "enough",
          "bombings",
          "weeks",
          "countries",
          "again",
          "detention",
          "move",
          "woomera",
          "seven",
          "cabinet",
          "bowler",
          "buildings",
          "hour",
          "mark",
          "matter",
          "middle",
          "bombing",
          "th",
          "sunday",
          "situation",
          "rates",
          "space",
          "important",
          "warne",
          "dispute",
          "caught",
          "jail",
          "claimed",
          "wants",
          "perth",
          "adventure",
          "targets",
          "run",
          "swiss",
          "asio",
          "added",
          "commonwealth",
          "raids",
          "office",
          "evidence",
          "deal",
          "guides",
          "disease",
          "show",
          "boy",
          "women",
          "own",
          "freeze",
          "opened",
          "human",
          "forward",
          "carried",
          "african",
          "mission",
          "movement",
          "based",
          "sure",
          "reported",
          "immediately",
          "political",
          "warplanes",
          "young",
          "rule",
          "ms",
          "blue",
          "top",
          "justice",
          "money",
          "aedt",
          "cancer",
          "crash",
          "march",
          "banks",
          "border",
          "using",
          "although",
          "access",
          "financial",
          "allegations",
          "certainly",
          "planning",
          "probably",
          "break",
          "find",
          "wicket",
          "ground",
          "beat",
          "prepared",
          "burning",
          "become",
          "always",
          "job",
          "proposed",
          "each",
          "full",
          "reached",
          "collapse",
          "growth",
          "order",
          "island",
          "sector",
          "flying",
          "carrying",
          "result",
          "face",
          "investigation",
          "times",
          "relations",
          "militant",
          "road",
          "sex",
          "needs",
          "organisation",
          "until",
          "serious",
          "program",
          "fight",
          "calls",
          "stage",
          "getting",
          "lives",
          "responsibility",
          "reserve",
          "thursday",
          "comes",
          "management",
          "sent",
          "drop",
          "surrender",
          "allow",
          "soon",
          "afp",
          "tried",
          "post",
          "killing",
          "radical",
          "hewitt",
          "himself",
          "senator",
          "executive",
          "outside",
          "believes",
          "inquiry",
          "short",
          "caves",
          "different",
          "flights",
          "immigration",
          "tourists",
          "future",
          "inside",
          "bid",
          "energy",
          "clear",
          "trees",
          "thousands",
          "argentina",
          "militia",
          "suspected",
          "making",
          "bowling",
          "ariel",
          "went",
          "alleged",
          "rejected",
          "howard",
          "quickly",
          "wave",
          "harrison",
          "travel",
          "opening",
          "ansett",
          "kilometres",
          "declared",
          "running",
          "measures",
          "biggest",
          "list",
          "figures",
          "rise",
          "residents",
          "sea",
          "form",
          "annual",
          "anything",
          "attempt",
          "open",
          "parties",
          "available",
          "announced",
          "shortly",
          "among",
          "currently",
          "bombers",
          "circumstances",
          "accident",
          "donald",
          "ministers",
          "look",
          "brisbane",
          "decided",
          "ruddock",
          "changes",
          "yet",
          "issues",
          "address",
          "destroyed",
          "actually",
          "rights",
          "increase",
          "terms",
          "school",
          "rural",
          "fighter",
          "quite",
          "happened",
          "wounded",
          "victoria",
          "television",
          "nine",
          "something",
          "try",
          "parts",
          "white",
          "response",
          "done",
          "wickets",
          "witnesses",
          "refused",
          "karzai",
          "sentence",
          "ended",
          "tanks",
          "gunmen",
          "sources",
          "kallis",
          "agency",
          "july",
          "jewish",
          "warned",
          "directors",
          "understand",
          "meet",
          "means",
          "returned",
          "offices",
          "yacht",
          "source",
          "alexander",
          "ll",
          "fact",
          "difficult",
          "though",
          "period",
          "confidence",
          "wage",
          "airlines",
          "virus",
          "advice",
          "caused",
          "musharraf",
          "allan",
          "recession",
          "less",
          "ensure",
          "strike",
          "appeared",
          "islands",
          "crowd",
          "suharto",
          "highway",
          "afternoon",
          "step",
          "commanders",
          "began",
          "gave",
          "worst",
          "glenn",
          "bomb",
          "commissioner",
          "powell",
          "having",
          "beginning",
          "intelligence",
          "rafter",
          "prevent",
          "gives",
          "expressed",
          "huge",
          "ever",
          "big",
          "business",
          "ses",
          "media",
          "friday",
          "pacific",
          "robert",
          "expect",
          "blake",
          "runs",
          "involved",
          "followed",
          "deputy",
          "hobart",
          "whose",
          "market",
          "tour",
          "rather",
          "attorney",
          "elected",
          "beyond",
          "arrived",
          "away",
          "facility",
          "commander",
          "total",
          "law",
          "field",
          "supporters",
          "struck",
          "car",
          "cost",
          "sir",
          "negotiations",
          "nauru",
          "tennis",
          "massive",
          "entered",
          "threat",
          "plan",
          "explosives",
          "debt",
          "entitlements",
          "criticism",
          "decide",
          "quarter",
          "saturday",
          "assistance",
          "labour",
          "geoff",
          "together",
          "finished",
          "chance",
          "endeavour",
          "chairman",
          "main",
          "heavy",
          "base",
          "places",
          "tragedy",
          "sort",
          "vote",
          "giving",
          "jenin",
          "front",
          "powers",
          "anglican",
          "son",
          "zimbabwe",
          "themselves",
          "conflict",
          "yes",
          "muslim",
          "lockett",
          "daryl",
          "helicopter",
          "current",
          "fast",
          "complex",
          "terror",
          "smoke",
          "france",
          "anthony",
          "calling",
          "hearings",
          "population",
          "tasmania",
          "game",
          "jacques",
          "placed",
          "denied",
          "reid",
          "pakistani",
          "indonesia",
          "bring",
          "ballot",
          "played",
          "protect",
          "level",
          "conference",
          "organisations",
          "martin",
          "employees",
          "feel",
          "costs",
          "changed",
          "study",
          "survey",
          "brett",
          "potential",
          "macgill",
          "cannot",
          "crean",
          "lost",
          "storms",
          "round",
          "russian",
          "trip",
          "crisis",
          "nearly",
          "americans",
          "speaking",
          "ambush",
          "never",
          "significant",
          "boxing",
          "longer",
          "low",
          "tribal",
          "deadly",
          "record",
          "problem",
          "professor",
          "hayden",
          "fleeing",
          "absolutely",
          "continues",
          "fired",
          "rumsfeld",
          "claim",
          "ramallah",
          "hold",
          "anyone",
          "election",
          "construction",
          "technology",
          "doubles",
          "cities",
          "companies",
          "research",
          "whole",
          "efforts",
          "needed",
          "small",
          "moved",
          "confident",
          "land",
          "proposals",
          "sign",
          "little",
          "affected",
          "tape",
          "ruled",
          "environment",
          "everything",
          "severe",
          "led",
          "closed",
          "forecast",
          "pilot",
          "overall",
          "gillespie",
          "signed",
          "coming",
          "receive",
          "rival",
          "provide",
          "representation",
          "simon",
          "accept",
          "sides",
          "mountain",
          "receiving",
          "mean",
          "secret",
          "injuries",
          "dozens",
          "steve",
          "payment",
          "hope",
          "battle",
          "shuttle",
          "gun",
          "central",
          "bomber",
          "starting",
          "activity",
          "damaged",
          "bonn",
          "disaster",
          "problems",
          "verdict",
          "flames",
          "condition",
          "french",
          "tony",
          "resolution",
          "rest",
          "coalition",
          "richard",
          "treatment",
          "recorded",
          "grant",
          "stopped",
          "hotel",
          "insurance",
          "carry",
          "rain",
          "almost",
          "ice",
          "continued",
          "greater",
          "global",
          "share",
          "direct",
          "nation",
          "paid",
          "vaughan",
          "statistics",
          "fellow",
          "winner",
          "civil",
          "review",
          "private",
          "gas",
          "twice",
          "interlaken",
          "concern",
          "cars",
          "started",
          "red",
          "fell",
          "disappointed",
          "debate",
          "determined",
          "michael",
          "seles",
          "begin",
          "krishna",
          "didn",
          "refugees",
          "remaining",
          "tough",
          "ceremony",
          "property",
          "january",
          "qc",
          "stand",
          "operation",
          "territories",
          "above",
          "lower",
          "respond",
          "reduce",
          "resolve",
          "victims",
          "strategic",
          "asic",
          "alongside",
          "include",
          "revealed",
          "august",
          "season",
          "charge",
          "completed",
          "seeking",
          "bit",
          "park",
          "lines",
          "heritage",
          "traditional",
          "enter",
          "tuesday",
          "guard",
          "ray",
          "avoid",
          "markets",
          "visit",
          "europe",
          "winning",
          "playing",
          "self",
          "yachts",
          "met",
          "charges",
          "vice",
          "cease",
          "roads",
          "factory",
          "america",
          "itself",
          "created",
          "wake",
          "levels",
          "fall",
          "related",
          "outlook",
          "ministry",
          "lung",
          "hearing",
          "non",
          "volunteers",
          "civilians",
          "voted",
          "liquidation",
          "search",
          "provisional",
          "rescue",
          "victorian",
          "table",
          "successful",
          "track",
          "conducted",
          "heading",
          "spread",
          "accompanied",
          "delhi",
          "operating",
          "wanted",
          "expects",
          "leg",
          "ponting",
          "pulled",
          "knew",
          "heart",
          "coach",
          "confirm",
          "ball",
          "virgin",
          "press",
          "suffered",
          "illawarra",
          "approach",
          "manslaughter",
          "costello",
          "showed",
          "threatened",
          "warning",
          "helped",
          "resume",
          "japan",
          "individuals",
          "mayor",
          "giuliani",
          "friedli",
          "wind",
          "served",
          "andy",
          "range",
          "responsible",
          "unemployment",
          "mckenzie",
          "initial",
          "keep",
          "families",
          "lord",
          "incident",
          "october",
          "finance",
          "treated",
          "ian",
          "why",
          "solution",
          "apparently",
          "body",
          "club",
          "crackdown",
          "reach",
          "officer",
          "institute",
          "shaun",
          "pollock",
          "hopes",
          "structure",
          "data",
          "nice",
          "food",
          "seriously",
          "suspended",
          "attacked",
          "jason",
          "elections",
          "edge",
          "affairs",
          "nothing",
          "questions",
          "mid",
          "built",
          "negotiating",
          "peacekeepers",
          "saw",
          "issued",
          "spokeswoman",
          "assisting",
          "remains",
          "finding",
          "recovery",
          "woman",
          "gang",
          "kashmir",
          "farmers",
          "oil",
          "networks",
          "sheikh",
          "adequate",
          "doubt",
          "products",
          "secure",
          "beatle",
          "single",
          "options",
          "clearly",
          "blaze",
          "present",
          "ford",
          "cfmeu",
          "tailenders",
          "fatah",
          "scene",
          "co",
          "lording",
          "factions",
          "st",
          "raid",
          "career",
          "streets",
          "butterfly",
          "amin",
          "outcome",
          "traveland",
          "peres",
          "inappropriate",
          "austar",
          "scored",
          "champion",
          "races",
          "cave",
          "scheduled",
          "clean",
          "nearby",
          "philip",
          "shows",
          "invasion",
          "aboard",
          "coup",
          "senate",
          "doug",
          "solomon",
          "eve",
          "sarah",
          "holiday",
          "mohammad",
          "university",
          "murder",
          "whiting",
          "gorge",
          "tensions",
          "manufacturing",
          "wayne",
          "yallourn",
          "diplomatic",
          "drug",
          "promised",
          "cause",
          "natural",
          "afroz",
          "ethnic",
          "singles",
          "crews",
          "meetings",
          "toll",
          "apra",
          "administrators",
          "corporation",
          "leadership",
          "canberra",
          "exchange",
          "nuclear",
          "germany",
          "numbers",
          "attacking",
          "largest",
          "petrol",
          "customers",
          "prior",
          "internet",
          "awards",
          "extremists",
          "attempting",
          "personnel",
          "hand",
          "criminal",
          "mandate",
          "things",
          "deployed",
          "follows",
          "unrest",
          "dropped",
          "manager",
          "injury",
          "settlement",
          "roof",
          "honours",
          "appears",
          "metre",
          "boats",
          "often",
          "speech",
          "squad",
          "fair",
          "budget",
          "ready",
          "ask",
          "band",
          "proteas",
          "king",
          "grand",
          "recent",
          "happens",
          "classic",
          "suburbs",
          "resign",
          "swept",
          "collapsed",
          "true",
          "agreed",
          "batsmen",
          "presence",
          "felt",
          "billion",
          "resistance",
          "giant",
          "increased",
          "described",
          "unit",
          "create",
          "concerns",
          "protection",
          "targeted",
          "boys",
          "saudi",
          "leave",
          "unity",
          "planes",
          "halt",
          "read",
          "marine",
          "neil",
          "walk",
          "crossed",
          "fleet",
          "knowledge",
          "minute",
          "greatest",
          "extensive",
          "backed",
          "ocean",
          "assa",
          "ricky",
          "abloy",
          "light",
          "premier",
          "names",
          "explanation",
          "wall",
          "possibility",
          "real",
          "live",
          "switzerland",
          "japanese",
          "shopping",
          "reveal",
          "fierce",
          "tree",
          "elders",
          "blame",
          "tension",
          "employment",
          "detain",
          "positive",
          "income",
          "haifa",
          "jerusalem",
          "pre",
          "programs",
          "jets",
          "transport",
          "regional",
          "save",
          "hunt",
          "advance",
          "gone",
          "battling",
          "suspect",
          "representing",
          "investigating",
          "reduced",
          "acting",
          "projects",
          "investment",
          "spencer",
          "findings",
          "students",
          "nablus",
          "actions",
          "trial",
          "declaration",
          "handed",
          "custody",
          "growing",
          "system",
          "prisoners",
          "domestic",
          "education",
          "society",
          "summit",
          "assault",
          "langer",
          "matthew",
          "requested",
          "westpac",
          "doctor",
          "wing",
          "republic",
          "searching",
          "eliminated",
          "approval",
          "anz",
          "term",
          "bargaining",
          "various",
          "balls",
          "klusener",
          "boucher",
          "humanity",
          "suggested",
          "adding",
          "history",
          "normal",
          "cuts",
          "signs",
          "gunships",
          "blasted",
          "turn",
          "hare",
          "smaller",
          "guess",
          "benares",
          "ashes",
          "path",
          "terrorists",
          "blazes",
          "hijacked",
          "adam",
          "follow",
          "comment",
          "aware",
          "connection",
          "underway",
          "kieren",
          "rabbani",
          "completely",
          "tonight",
          "understanding",
          "infected",
          "masood",
          "treasurer",
          "crime",
          "gambier",
          "henderson",
          "returning",
          "results",
          "kingham",
          "question",
          "kissinger",
          "gerber",
          "stuart",
          "launceston",
          "sergeant",
          "flood",
          "committee",
          "hundred",
          "goshen",
          "handling",
          "church",
          "thing",
          "escaped",
          "injuring",
          "slightly",
          "francs",
          "hunter",
          "ahmed",
          "actor",
          "wednesday",
          "aged",
          "centrelink",
          "threatening",
          "sultan",
          "improve",
          "passed",
          "stability",
          "project",
          "dollars",
          "decades",
          "course",
          "ill",
          "faces",
          "chosen",
          "bob",
          "hamid",
          "passengers",
          "davis",
          "neville",
          "ways",
          "pace",
          "whatever",
          "headed",
          "launch",
          "replied",
          "hopefully",
          "determine",
          "archbishop",
          "unable",
          "throughout",
          "average",
          "unidentified",
          "survived",
          "approached",
          "convicted",
          "cooperation",
          "redundancy",
          "waiting",
          "request",
          "paying",
          "observers",
          "aboriginal",
          "procedures",
          "reject",
          "document",
          "improved",
          "holding",
          "mass",
          "unfortunately",
          "welcomed",
          "whereabouts",
          "appropriate",
          "lack",
          "delay",
          "trapped",
          "facilities",
          "decisions",
          "prepare",
          "medical",
          "necessary",
          "spinner",
          "examination",
          "losing",
          "channel",
          "occupation",
          "title",
          "consumers",
          "firm",
          "creditors",
          "fine",
          "vehicle",
          "staying",
          "relationship",
          "delivered",
          "begun",
          "hot",
          "coroner",
          "temperatures",
          "containment",
          "cross",
          "contested",
          "strongly",
          "experts",
          "celebrations",
          "focus",
          "named",
          "sometimes",
          "marines",
          "player",
          "jalalabad",
          "games",
          "breaking",
          "contained",
          "counts",
          "stay",
          "allowed",
          "temporary",
          "assembly",
          "draft",
          "understood",
          "toowoomba",
          "voice",
          "twenty",
          "strachan",
          "harris",
          "discussions",
          "hopman",
          "crashed",
          "farm",
          "violent",
          "communities",
          "kilometre",
          "doctors",
          "hoping",
          "ban",
          "colin",
          "effective",
          "success",
          "offered",
          "positions",
          "abu",
          "worked",
          "documents",
          "tell",
          "phillips",
          "retired",
          "choosing",
          "responding",
          "allegedly",
          "indonesian",
          "detail",
          "free",
          "bringing",
          "hiv",
          "proposal",
          "doesn",
          "mining",
          "embassy",
          "heights",
          "mt",
          "trading",
          "room",
          "fund",
          "impact",
          "male",
          "mohammed",
          "interests",
          "effort",
          "antarctic",
          "previous",
          "target",
          "words",
          "publicly",
          "walked",
          "credit",
          "provided",
          "investigate",
          "telephone",
          "eventually",
          "leaving",
          "banking",
          "interview",
          "headquarters",
          "clashes",
          "doing",
          "fear",
          "predicted",
          "picked",
          "happy",
          "visa",
          "tie",
          "putting",
          "escalating",
          "hoped",
          "landed",
          "sharing",
          "mind",
          "skipper",
          "gary",
          "soft",
          "became",
          "sending",
          "shoes",
          "paris",
          "required",
          "seemed",
          "cameron",
          "ability",
          "locked",
          "travelled",
          "finally",
          "separate",
          "owen"
         ],
         "type": "scatter",
         "x": [
          55.62959671020508,
          58.25174331665039,
          57.287445068359375,
          57.23680114746094,
          56.940879821777344,
          49.072601318359375,
          56.6842155456543,
          56.5872917175293,
          57.703983306884766,
          52.76639938354492,
          54.781131744384766,
          57.70323944091797,
          56.77732849121094,
          53.83364486694336,
          56.58464813232422,
          51.29952621459961,
          50.856178283691406,
          58.08560562133789,
          58.616172790527344,
          55.55207061767578,
          57.93626022338867,
          54.87437057495117,
          58.30657958984375,
          58.12884521484375,
          54.19414138793945,
          49.07210922241211,
          57.447845458984375,
          55.76576232910156,
          51.925724029541016,
          56.973724365234375,
          56.482994079589844,
          54.33002471923828,
          58.73465347290039,
          58.11374282836914,
          55.20647048950195,
          49.614662170410156,
          55.65520477294922,
          53.19033432006836,
          50.181640625,
          52.750770568847656,
          54.889442443847656,
          54.92460250854492,
          47.44418716430664,
          55.14533996582031,
          48.334510803222656,
          57.4003791809082,
          51.64601135253906,
          52.04490661621094,
          52.45989227294922,
          55.53887176513672,
          52.488380432128906,
          46.480194091796875,
          52.278018951416016,
          52.84587097167969,
          51.67063903808594,
          51.83039474487305,
          51.092018127441406,
          56.00668716430664,
          52.56639862060547,
          54.64967346191406,
          49.761016845703125,
          50.17380905151367,
          52.69435119628906,
          50.645668029785156,
          51.539005279541016,
          56.08518600463867,
          48.33510208129883,
          51.871158599853516,
          45.3217658996582,
          49.042274475097656,
          44.5504264831543,
          45.137794494628906,
          48.98528289794922,
          44.977867126464844,
          49.24569320678711,
          46.28532028198242,
          49.774295806884766,
          43.77195739746094,
          46.997989654541016,
          50.71452331542969,
          45.205753326416016,
          45.92426300048828,
          43.60847091674805,
          48.6707878112793,
          43.232582092285156,
          47.45182800292969,
          43.816532135009766,
          45.612483978271484,
          49.8828125,
          45.54007339477539,
          49.54442596435547,
          43.85606384277344,
          45.64667892456055,
          44.26789855957031,
          -1.1209492683410645,
          44.931156158447266,
          43.50965118408203,
          44.78970718383789,
          44.32978439331055,
          -0.8195958733558655,
          -1.2143555879592896,
          44.579952239990234,
          45.96660232543945,
          -1.9100197553634644,
          46.85956573486328,
          -0.8069230318069458,
          -2.9415199756622314,
          -1.2498385906219482,
          -2.0921292304992676,
          42.88644790649414,
          44.18465042114258,
          -0.8294044733047485,
          -2.4254937171936035,
          -3.185133695602417,
          -1.6112090349197388,
          -2.8297178745269775,
          -2.368699789047241,
          44.35597229003906,
          -2.6124231815338135,
          -2.327694892883301,
          -3.928333044052124,
          -3.1175405979156494,
          -2.5814127922058105,
          -1.7755143642425537,
          44.739234924316406,
          -2.1652767658233643,
          -2.7121477127075195,
          -2.684575080871582,
          -3.238539934158325,
          -2.507265090942383,
          -3.0327541828155518,
          -1.4790669679641724,
          -0.7237892746925354,
          -1.1563968658447266,
          -2.6198606491088867,
          -1.588295340538025,
          -2.41302227973938,
          -1.8258376121520996,
          -2.3341331481933594,
          0.001788176828995347,
          -1.6757028102874756,
          -3.2748939990997314,
          -2.493225336074829,
          -0.9801574945449829,
          -2.002220630645752,
          -1.4063514471054077,
          -2.7667860984802246,
          -1.5274983644485474,
          -2.315856456756592,
          -2.4085960388183594,
          -2.674729824066162,
          -1.0105609893798828,
          -3.0684010982513428,
          -1.0146582126617432,
          -1.8946055173873901,
          -1.9585070610046387,
          -2.517274856567383,
          -2.9147047996520996,
          -1.76229727268219,
          -2.1109883785247803,
          -0.5530831813812256,
          -2.656510591506958,
          -2.5414676666259766,
          -2.6041276454925537,
          -2.6034300327301025,
          43.665714263916016,
          0.4846896529197693,
          2.282595634460449,
          -1.7911313772201538,
          -3.213859796524048,
          -0.9108051061630249,
          -2.7427737712860107,
          -2.242649793624878,
          3.1579601764678955,
          -2.7273998260498047,
          -1.5103628635406494,
          15.064780235290527,
          -2.4526901245117188,
          -2.8713598251342773,
          -2.2349319458007812,
          -1.2477976083755493,
          -2.683516502380371,
          -2.0789177417755127,
          -0.07839041203260422,
          -2.5567522048950195,
          -2.5885097980499268,
          -2.241626501083374,
          -2.5550599098205566,
          13.038472175598145,
          -1.898974061012268,
          -2.800168752670288,
          -1.9348371028900146,
          -1.7882661819458008,
          -2.068464756011963,
          -0.38067352771759033,
          0.7627512812614441,
          5.726933002471924,
          -2.059047222137451,
          5.41478967666626,
          4.222344398498535,
          -2.7982120513916016,
          1.9962525367736816,
          -2.668811321258545,
          -1.7973449230194092,
          -2.202721118927002,
          14.781126022338867,
          9.040486335754395,
          11.995142936706543,
          -1.9307165145874023,
          20.364662170410156,
          -1.5972422361373901,
          1.5767228603363037,
          3.780710220336914,
          1.7374285459518433,
          -2.4644455909729004,
          -2.5954935550689697,
          -1.5812891721725464,
          5.181344032287598,
          5.253445148468018,
          -1.6153351068496704,
          -1.2180345058441162,
          -2.51794695854187,
          2.206063985824585,
          5.731832027435303,
          3.1404106616973877,
          8.031319618225098,
          0.8082072734832764,
          -1.3295308351516724,
          3.5396320819854736,
          12.471369743347168,
          15.572917938232422,
          1.7825706005096436,
          -0.7100955843925476,
          18.07757568359375,
          2.337677240371704,
          15.742916107177734,
          3.890263795852661,
          -1.5356013774871826,
          1.8733580112457275,
          16.808015823364258,
          13.551128387451172,
          8.58609390258789,
          8.649884223937988,
          13.395962715148926,
          11.630277633666992,
          6.529665470123291,
          0.9065268635749817,
          3.5487589836120605,
          3.042285680770874,
          4.828672409057617,
          -1.6954689025878906,
          14.807618141174316,
          3.118734836578369,
          29.822193145751953,
          26.235443115234375,
          2.8430416584014893,
          7.041579723358154,
          8.445109367370605,
          7.710870742797852,
          29.898242950439453,
          12.901951789855957,
          9.247934341430664,
          9.187820434570312,
          1.8023629188537598,
          5.822205066680908,
          -1.0129863023757935,
          20.8071346282959,
          28.93654441833496,
          31.208314895629883,
          25.454477310180664,
          26.008455276489258,
          -0.628958523273468,
          12.632048606872559,
          5.811607360839844,
          1.5458431243896484,
          18.872215270996094,
          7.247864246368408,
          26.85730743408203,
          30.04733657836914,
          12.114266395568848,
          9.66202163696289,
          2.63598370552063,
          5.976791858673096,
          26.57123565673828,
          9.332062721252441,
          8.698257446289062,
          14.581055641174316,
          26.109277725219727,
          11.334860801696777,
          4.980712413787842,
          1.2084754705429077,
          21.1138858795166,
          13.032801628112793,
          4.6378984451293945,
          2.9371116161346436,
          30.829193115234375,
          12.999438285827637,
          12.587446212768555,
          30.981006622314453,
          20.105003356933594,
          4.871184825897217,
          6.418717861175537,
          1.3780826330184937,
          19.23470115661621,
          29.975719451904297,
          17.648000717163086,
          15.972381591796875,
          27.6395263671875,
          13.360753059387207,
          20.998228073120117,
          -0.007735404185950756,
          2.1332590579986572,
          20.496349334716797,
          21.084333419799805,
          27.256502151489258,
          15.656559944152832,
          30.446426391601562,
          12.450937271118164,
          30.853275299072266,
          18.991073608398438,
          16.096731185913086,
          19.40508460998535,
          20.21185874938965,
          29.49405860900879,
          27.784690856933594,
          18.003311157226562,
          29.0501708984375,
          -0.48527416586875916,
          28.894683837890625,
          30.165813446044922,
          17.272174835205078,
          31.042741775512695,
          20.029382705688477,
          29.611675262451172,
          27.237743377685547,
          30.602689743041992,
          30.714982986450195,
          23.331331253051758,
          31.264148712158203,
          16.669214248657227,
          26.580759048461914,
          30.32659149169922,
          8.231629371643066,
          3.1717941761016846,
          28.979276657104492,
          7.143673419952393,
          30.227853775024414,
          25.907115936279297,
          17.121740341186523,
          30.27646827697754,
          23.96994972229004,
          27.220354080200195,
          16.904327392578125,
          13.964105606079102,
          28.46312713623047,
          19.34065818786621,
          31.373991012573242,
          30.718761444091797,
          28.8741397857666,
          29.460268020629883,
          21.81553077697754,
          29.034687042236328,
          31.94339370727539,
          28.115047454833984,
          31.414587020874023,
          20.64720344543457,
          31.880542755126953,
          13.721745491027832,
          28.526845932006836,
          19.358797073364258,
          30.480270385742188,
          28.983768463134766,
          17.217748641967773,
          9.078679084777832,
          17.499916076660156,
          30.92426300048828,
          29.811031341552734,
          28.076093673706055,
          25.504240036010742,
          32.018856048583984,
          30.2730655670166,
          29.582069396972656,
          30.369253158569336,
          30.960599899291992,
          18.950523376464844,
          31.37864875793457,
          26.99855613708496,
          19.145631790161133,
          11.916115760803223,
          27.70595359802246,
          28.305150985717773,
          17.939407348632812,
          29.475244522094727,
          16.056238174438477,
          24.946805953979492,
          30.361438751220703,
          30.40264129638672,
          27.48917007446289,
          19.964445114135742,
          16.728078842163086,
          19.688337326049805,
          31.406570434570312,
          31.178022384643555,
          17.337066650390625,
          15.7081298828125,
          25.083946228027344,
          6.475296974182129,
          22.265710830688477,
          26.39765739440918,
          23.816871643066406,
          14.252201080322266,
          29.87782859802246,
          25.827136993408203,
          31.383676528930664,
          20.438343048095703,
          29.422203063964844,
          27.686017990112305,
          14.323344230651855,
          25.08845329284668,
          26.491296768188477,
          30.57578468322754,
          20.473739624023438,
          13.922996520996094,
          31.108678817749023,
          17.06090545654297,
          29.67152214050293,
          29.659645080566406,
          19.348243713378906,
          21.766265869140625,
          25.535621643066406,
          25.696123123168945,
          26.785009384155273,
          27.007261276245117,
          26.98248291015625,
          30.875320434570312,
          19.939653396606445,
          14.515880584716797,
          24.964584350585938,
          27.35881996154785,
          28.342397689819336,
          29.772571563720703,
          31.739601135253906,
          28.945375442504883,
          13.559073448181152,
          30.383853912353516,
          25.44859504699707,
          15.320223808288574,
          30.865570068359375,
          28.0589542388916,
          9.544511795043945,
          12.569992065429688,
          22.827791213989258,
          21.065114974975586,
          30.77783203125,
          31.160860061645508,
          23.76905059814453,
          17.695796966552734,
          25.92347526550293,
          11.829035758972168,
          28.777341842651367,
          27.528772354125977,
          18.81589126586914,
          17.856534957885742,
          30.5435848236084,
          29.340587615966797,
          31.123233795166016,
          13.860021591186523,
          20.515125274658203,
          25.88664436340332,
          18.2695369720459,
          28.15155601501465,
          29.647768020629883,
          13.660282135009766,
          13.621223449707031,
          26.837623596191406,
          29.556310653686523,
          30.757238388061523,
          27.81635284423828,
          30.436155319213867,
          29.262887954711914,
          30.821603775024414,
          27.211788177490234,
          13.7709321975708,
          25.22516441345215,
          28.463661193847656,
          17.532695770263672,
          30.743122100830078,
          17.159976959228516,
          27.71466636657715,
          29.03765106201172,
          31.34149742126465,
          19.312034606933594,
          20.582643508911133,
          13.324617385864258,
          27.954364776611328,
          12.78392219543457,
          17.26319122314453,
          19.69967269897461,
          12.960994720458984,
          16.586034774780273,
          30.366226196289062,
          27.93490219116211,
          23.259252548217773,
          28.356348037719727,
          21.93136215209961,
          31.423397064208984,
          20.832103729248047,
          31.528249740600586,
          28.71299171447754,
          14.897936820983887,
          18.44479751586914,
          22.497093200683594,
          31.416677474975586,
          27.332590103149414,
          23.168794631958008,
          16.295791625976562,
          -3.9588897228240967,
          25.027023315429688,
          18.537607192993164,
          15.16908073425293,
          18.1568660736084,
          29.933273315429688,
          17.932273864746094,
          24.00623321533203,
          29.314617156982422,
          13.800902366638184,
          26.191186904907227,
          12.38934326171875,
          12.721061706542969,
          26.347179412841797,
          16.99265480041504,
          14.486223220825195,
          30.26120376586914,
          30.300926208496094,
          28.663837432861328,
          19.1336727142334,
          28.6845760345459,
          30.452817916870117,
          31.600996017456055,
          21.83108901977539,
          30.06262969970703,
          15.376973152160645,
          15.88620376586914,
          26.640106201171875,
          20.476863861083984,
          17.066343307495117,
          13.254066467285156,
          13.81985092163086,
          30.917842864990234,
          28.073638916015625,
          15.124059677124023,
          27.892934799194336,
          12.525727272033691,
          25.62285804748535,
          28.124189376831055,
          11.622467994689941,
          15.993433952331543,
          20.31975555419922,
          18.04582977294922,
          30.589881896972656,
          15.984814643859863,
          25.723413467407227,
          14.998213768005371,
          14.14594841003418,
          11.774127960205078,
          14.440616607666016,
          21.314315795898438,
          31.95587730407715,
          16.334352493286133,
          17.687484741210938,
          19.09137535095215,
          12.711405754089355,
          12.254070281982422,
          19.241260528564453,
          14.728588104248047,
          16.567211151123047,
          28.747482299804688,
          17.88585090637207,
          24.70015525817871,
          16.143306732177734,
          29.294218063354492,
          14.390213012695312,
          11.943886756896973,
          18.953519821166992,
          29.08246612548828,
          9.891669273376465,
          21.306793212890625,
          13.435516357421875,
          15.548649787902832,
          15.71707820892334,
          20.56474494934082,
          17.255294799804688,
          20.0662784576416,
          14.303845405578613,
          25.787572860717773,
          13.05938720703125,
          13.055997848510742,
          20.044864654541016,
          16.27194595336914,
          12.835847854614258,
          14.934893608093262,
          13.897072792053223,
          12.077815055847168,
          12.500072479248047,
          16.85354995727539,
          22.088659286499023,
          18.148496627807617,
          15.927809715270996,
          11.860359191894531,
          11.791975021362305,
          28.857391357421875,
          12.554155349731445,
          13.978464126586914,
          15.953495025634766,
          21.801353454589844,
          31.54692268371582,
          20.782772064208984,
          20.43389892578125,
          19.137582778930664,
          -5.3364105224609375,
          15.068244934082031,
          13.57296085357666,
          29.402938842773438,
          12.421014785766602,
          19.043893814086914,
          22.600622177124023,
          20.55112075805664,
          30.499256134033203,
          13.026572227478027,
          20.32019805908203,
          24.985132217407227,
          13.873624801635742,
          25.0418701171875,
          18.807331085205078,
          31.261886596679688,
          14.904316902160645,
          12.50338077545166,
          14.39312744140625,
          16.23789405822754,
          14.437299728393555,
          26.69397735595703,
          17.05126953125,
          12.198063850402832,
          17.52529525756836,
          12.04548168182373,
          18.541593551635742,
          17.902645111083984,
          12.879308700561523,
          16.87038230895996,
          16.8077449798584,
          4.197262287139893,
          18.057708740234375,
          16.363649368286133,
          14.783885955810547,
          30.602231979370117,
          15.35781478881836,
          23.567691802978516,
          15.446786880493164,
          15.984638214111328,
          14.94379711151123,
          16.232606887817383,
          11.98465347290039,
          11.166680335998535,
          19.141216278076172,
          11.660194396972656,
          16.88774871826172,
          14.159510612487793,
          24.969493865966797,
          14.064404487609863,
          15.04787540435791,
          13.552556991577148,
          13.539947509765625,
          12.722043991088867,
          11.395232200622559,
          12.9241361618042,
          5.691736698150635,
          12.934807777404785,
          17.376646041870117,
          12.639498710632324,
          13.200181007385254,
          18.559627532958984,
          12.49632453918457,
          11.308845520019531,
          -12.818475723266602,
          13.870956420898438,
          5.048379421234131,
          15.320544242858887,
          14.630876541137695,
          13.344326972961426,
          17.660385131835938,
          18.67965316772461,
          17.788721084594727,
          14.012785911560059,
          -9.142021179199219,
          16.931766510009766,
          17.546398162841797,
          16.129074096679688,
          14.292671203613281,
          19.560096740722656,
          18.186378479003906,
          16.81202507019043,
          11.494170188903809,
          19.767414093017578,
          12.981748580932617,
          17.143896102905273,
          19.24823760986328,
          24.406278610229492,
          8.741292953491211,
          15.290863037109375,
          16.37706756591797,
          11.508367538452148,
          17.8150577545166,
          -32.33406066894531,
          13.404064178466797,
          13.235380172729492,
          26.932104110717773,
          4.715134620666504,
          17.976797103881836,
          -0.4063328504562378,
          7.356654167175293,
          14.31165599822998,
          16.42043685913086,
          11.25585651397705,
          13.342555046081543,
          16.585508346557617,
          -22.474428176879883,
          19.433366775512695,
          17.09172821044922,
          15.038843154907227,
          11.015339851379395,
          18.91008758544922,
          13.539173126220703,
          18.1174259185791,
          14.57480239868164,
          7.481387138366699,
          17.79888916015625,
          19.58182144165039,
          -2.6101748943328857,
          17.275802612304688,
          14.07254409790039,
          18.287118911743164,
          12.028990745544434,
          11.350973129272461,
          17.388612747192383,
          14.792717933654785,
          -22.757442474365234,
          19.862401962280273,
          15.980634689331055,
          16.14280891418457,
          21.659751892089844,
          -10.871376991271973,
          17.496158599853516,
          -0.7969439029693604,
          16.978151321411133,
          14.64913272857666,
          13.767081260681152,
          16.69391632080078,
          1.26152765750885,
          14.156943321228027,
          11.18607234954834,
          18.668609619140625,
          -23.475343704223633,
          15.44373893737793,
          15.772281646728516,
          19.252769470214844,
          8.984917640686035,
          -17.468809127807617,
          13.643280982971191,
          15.25366497039795,
          -28.580352783203125,
          15.729134559631348,
          13.05786418914795,
          -0.3177850544452667,
          13.763980865478516,
          22.76610565185547,
          10.1514892578125,
          16.08761978149414,
          17.892061233520508,
          -16.704456329345703,
          0.7340424656867981,
          16.26519775390625,
          14.327207565307617,
          6.259427547454834,
          18.67825698852539,
          11.522992134094238,
          -8.147098541259766,
          11.722865104675293,
          11.866677284240723,
          15.256355285644531,
          16.324369430541992,
          16.8829345703125,
          -11.903935432434082,
          13.065629005432129,
          15.60111141204834,
          3.6068718433380127,
          -3.049281358718872,
          -28.104167938232422,
          18.13735008239746,
          25.73219108581543,
          14.149129867553711,
          14.6864652633667,
          18.186166763305664,
          13.817790985107422,
          14.902436256408691,
          -0.5903499722480774,
          -4.421199321746826,
          15.896121978759766,
          5.219436168670654,
          15.5505952835083,
          18.674854278564453,
          12.965517044067383,
          15.821354866027832,
          -1.5398554801940918,
          -27.167560577392578,
          -30.47045135498047,
          16.722755432128906,
          15.767909049987793,
          1.3950406312942505,
          17.786855697631836,
          7.478358268737793,
          18.617733001708984,
          8.8328857421875,
          10.616204261779785,
          -23.086788177490234,
          11.610026359558105,
          -15.537113189697266,
          18.888671875,
          8.248224258422852,
          -9.49953556060791,
          -4.250049591064453,
          15.171903610229492,
          16.377885818481445,
          16.7831974029541,
          7.955918788909912,
          2.8314239978790283,
          17.360307693481445,
          7.808535575866699,
          15.676630973815918,
          19.378786087036133,
          -24.209400177001953,
          11.584677696228027,
          4.569023609161377,
          19.738924026489258,
          -34.38258361816406,
          17.57550621032715,
          -17.90455436706543,
          12.886530876159668,
          12.799042701721191,
          15.072419166564941,
          16.09404945373535,
          17.44202995300293,
          16.991411209106445,
          -0.1221981793642044,
          18.34247398376465,
          6.955749034881592,
          13.288137435913086,
          17.290203094482422,
          19.77129554748535,
          12.34115219116211,
          1.3311537504196167,
          8.723352432250977,
          -4.1075968742370605,
          -33.13786697387695,
          7.233434200286865,
          11.93050479888916,
          16.097362518310547,
          18.284255981445312,
          27.039859771728516,
          4.600111484527588,
          -1.9574923515319824,
          13.822853088378906,
          19.031158447265625,
          -0.8932023048400879,
          17.23678207397461,
          4.894928455352783,
          13.353523254394531,
          18.828784942626953,
          19.35894012451172,
          -16.101337432861328,
          12.131532669067383,
          -5.748185634613037,
          -22.402626037597656,
          12.836423873901367,
          18.251426696777344,
          16.995262145996094,
          16.33694076538086,
          16.197973251342773,
          17.677268981933594,
          12.992108345031738,
          17.068485260009766,
          -33.46160125732422,
          16.965118408203125,
          -22.90386962890625,
          12.41738224029541,
          -29.368791580200195,
          11.540061950683594,
          5.031525611877441,
          17.45023536682129,
          11.525507926940918,
          10.586817741394043,
          9.13771915435791,
          3.671236753463745,
          18.847780227661133,
          19.407981872558594,
          -30.311080932617188,
          -18.50452423095703,
          5.968214988708496,
          9.113478660583496,
          16.78700828552246,
          -3.1586720943450928,
          11.112850189208984,
          -15.684852600097656,
          16.314714431762695,
          -31.863561630249023,
          -6.64375638961792,
          16.322628021240234,
          17.66949462890625,
          0.7277677655220032,
          15.489200592041016,
          15.025155067443848,
          18.082111358642578,
          9.602293014526367,
          -7.804964065551758,
          10.930183410644531,
          5.441766262054443,
          -5.267032146453857,
          16.798782348632812,
          14.315098762512207,
          -15.576130867004395,
          -3.4748153686523438,
          20.594491958618164,
          2.2133119106292725,
          -9.240655899047852,
          0.4969451129436493,
          -5.489630699157715,
          16.097261428833008,
          -29.299659729003906,
          14.520236015319824,
          13.788626670837402,
          -13.063963890075684,
          6.780779838562012,
          14.431600570678711,
          12.826601028442383,
          4.080182075500488,
          -27.381437301635742,
          10.151558876037598,
          16.365846633911133,
          -7.591949462890625,
          17.994508743286133,
          -11.629199981689453,
          16.589515686035156,
          18.20642852783203,
          1.5294276475906372,
          5.435586929321289,
          11.269118309020996,
          16.327320098876953,
          -29.123281478881836,
          17.87425422668457,
          10.689189910888672,
          -10.01357650756836,
          19.092817306518555,
          13.921160697937012,
          13.510831832885742,
          12.851699829101562,
          14.884102821350098,
          16.31803321838379,
          -12.178682327270508,
          17.106830596923828,
          1.6544088125228882,
          -8.923954963684082,
          -6.829300880432129,
          -14.818559646606445,
          5.9046502113342285,
          -30.817333221435547,
          14.450815200805664,
          13.930192947387695,
          -17.25067710876465,
          15.989990234375,
          -0.17671874165534973,
          -1.6129298210144043,
          -15.557591438293457,
          -16.108137130737305,
          7.055041790008545,
          -24.323150634765625,
          7.523252964019775,
          -3.686375617980957,
          17.311573028564453,
          -19.728410720825195,
          -25.90094757080078,
          -17.813627243041992,
          -15.06546401977539,
          -2.4010818004608154,
          -28.613056182861328,
          -12.798819541931152,
          -23.620983123779297,
          -25.16852378845215,
          -30.286588668823242,
          16.47834587097168,
          -15.368165016174316,
          3.4303719997406006,
          -25.013036727905273,
          -8.943653106689453,
          -10.111652374267578,
          -31.889822006225586,
          -11.207876205444336,
          -18.809852600097656,
          -27.434558868408203,
          -31.257457733154297,
          -32.60662078857422,
          -31.44466209411621,
          -21.1835880279541,
          -22.145477294921875,
          -13.660806655883789,
          9.677435874938965,
          4.9618239402771,
          -29.7550048828125,
          -23.437088012695312,
          6.479732990264893,
          16.214492797851562,
          -34.878028869628906,
          -30.71358871459961,
          9.181174278259277,
          -17.3967227935791,
          13.313405990600586,
          13.465574264526367,
          -21.88306999206543,
          -28.951658248901367,
          -20.473434448242188,
          11.684379577636719,
          -11.700606346130371,
          3.544398784637451,
          14.745113372802734,
          -5.737241268157959,
          -33.409366607666016,
          -8.328228950500488,
          -7.137378692626953,
          8.44044017791748,
          -4.380893707275391,
          -33.417388916015625,
          -31.408828735351562,
          18.49468231201172,
          -35.34012222290039,
          -16.48025894165039,
          -20.483232498168945,
          -0.44485145807266235,
          -30.989673614501953,
          -1.8362617492675781,
          18.36737060546875,
          -14.278438568115234,
          19.767194747924805,
          -30.694326400756836,
          -32.90785598754883,
          18.425947189331055,
          -18.38192367553711,
          -19.973926544189453,
          10.097620964050293,
          -16.9296817779541,
          3.6128993034362793,
          -21.499862670898438,
          -17.7208194732666,
          -32.588348388671875,
          -30.02313995361328,
          -33.94881820678711,
          -17.707847595214844,
          8.33209228515625,
          -21.645139694213867,
          -4.570428848266602,
          -2.887697458267212,
          16.356531143188477,
          -24.595211029052734,
          -20.001893997192383,
          -2.645878791809082,
          7.36796236038208,
          16.518789291381836,
          -7.907484531402588,
          11.863319396972656,
          -11.07480239868164,
          -2.4167428016662598,
          -18.684009552001953,
          -23.966447830200195,
          -28.764122009277344,
          13.404261589050293,
          14.676966667175293,
          18.371963500976562,
          16.909114837646484,
          -24.025104522705078,
          -13.61558723449707,
          -21.3689022064209,
          9.859331130981445,
          12.67223072052002,
          8.84974479675293,
          -12.792494773864746,
          -32.4720344543457,
          -14.175568580627441,
          -33.23604202270508,
          -29.907848358154297,
          -5.788999080657959,
          -28.92559242248535,
          0.6586169004440308,
          -1.6085580587387085,
          -31.70748519897461,
          10.414246559143066,
          6.190606594085693,
          -20.332792282104492,
          -32.08299255371094,
          -29.278099060058594,
          -29.88584327697754,
          -6.9524712562561035,
          -28.28982925415039,
          16.70951271057129,
          -34.30622863769531,
          -31.69029426574707,
          -28.444793701171875,
          -0.6884005665779114,
          -1.5447019338607788,
          -21.27729606628418,
          -24.87506103515625,
          -5.5493268966674805,
          -4.573999881744385,
          3.4539055824279785,
          -18.108606338500977,
          -18.951271057128906,
          -22.508560180664062,
          -17.85698890686035,
          -7.076883792877197,
          14.468528747558594,
          -31.90167999267578,
          -33.920413970947266,
          -11.832983016967773,
          -33.35187911987305,
          -9.987451553344727,
          -10.6294584274292,
          -32.107688903808594,
          -34.61046600341797,
          -31.50000762939453,
          -12.835225105285645,
          -28.81119155883789,
          14.939024925231934,
          -28.027402877807617,
          -10.9857759475708,
          -28.07142448425293,
          -20.23004913330078,
          -25.111434936523438,
          -13.80938720703125,
          -9.838163375854492,
          -32.668861389160156,
          -27.59136199951172,
          -28.699832916259766,
          -2.135024309158325,
          -8.61827278137207,
          -33.10991287231445,
          -5.111069202423096,
          -29.303298950195312,
          1.0649728775024414,
          -29.7393856048584,
          -4.620283603668213,
          2.080828905105591,
          2.727023124694824,
          -22.964649200439453,
          -26.136098861694336,
          -24.412303924560547,
          -32.129615783691406,
          -11.447710990905762,
          13.450554847717285,
          -20.82510757446289,
          12.289604187011719,
          -11.362724304199219,
          15.210970878601074,
          -17.31284523010254,
          17.514307022094727,
          -27.981624603271484,
          -12.494614601135254,
          -33.356468200683594,
          5.863317966461182,
          -7.637777805328369,
          -29.622135162353516,
          0.8905207514762878,
          4.719330787658691,
          -28.57453155517578,
          -26.693586349487305,
          -31.55157470703125,
          -7.724585056304932,
          -11.813648223876953,
          13.482329368591309,
          -4.6240057945251465,
          -34.81382369995117,
          -33.11952209472656,
          -22.169763565063477,
          8.144613265991211,
          -23.15900230407715,
          6.432703971862793,
          -21.725236892700195,
          -19.474254608154297,
          -24.871305465698242,
          -32.46451187133789,
          -27.102428436279297,
          -1.941635251045227,
          -25.41986083984375,
          -4.9713616371154785,
          -9.025236129760742,
          -23.627758026123047,
          -12.9104642868042,
          -35.260093688964844,
          -7.955969333648682,
          -14.532102584838867,
          -18.996719360351562,
          -33.67641067504883,
          -28.71811866760254,
          -22.051136016845703,
          -31.5103816986084,
          13.870174407958984,
          -4.216862678527832,
          -27.160749435424805,
          18.46084213256836,
          15.896502494812012,
          -29.621109008789062,
          -29.246145248413086,
          -30.891592025756836,
          0.02673014998435974,
          -4.586559295654297,
          -19.893718719482422,
          -25.966354370117188,
          -35.444820404052734,
          -23.086217880249023,
          -30.557973861694336,
          -8.975478172302246,
          -29.91909408569336,
          -0.2536715269088745,
          -24.123483657836914,
          -21.959224700927734,
          -6.50009822845459,
          18.248197555541992,
          -11.66001033782959,
          18.228281021118164,
          18.25043296813965,
          8.076248168945312,
          -16.23440933227539,
          -30.689504623413086,
          -29.342172622680664,
          -29.326244354248047,
          -30.24884796142578,
          -25.737730026245117,
          -29.961523056030273,
          16.047664642333984,
          -20.84590721130371,
          -9.222332954406738,
          -15.421037673950195,
          -30.053455352783203,
          -34.27580642700195,
          15.638002395629883,
          -34.8878059387207,
          -6.772500514984131,
          -31.537965774536133,
          -31.55205726623535,
          -31.041906356811523,
          5.616063594818115,
          1.5373109579086304,
          18.469985961914062,
          -30.60041618347168,
          -14.170853614807129,
          -2.9365947246551514,
          -19.7757625579834,
          -30.925765991210938,
          -26.56563949584961,
          -26.811494827270508,
          -23.52936363220215,
          -22.27605628967285,
          -23.28580665588379,
          -31.40090560913086,
          -29.17062759399414,
          -31.146883010864258,
          -25.999141693115234,
          -33.703369140625,
          -26.312288284301758,
          -32.318504333496094,
          -31.85651206970215,
          -13.175342559814453,
          -29.71141815185547,
          19.110431671142578,
          -34.25397491455078,
          -23.83818817138672,
          -29.942962646484375,
          -29.896324157714844,
          -29.917217254638672,
          -31.541730880737305,
          -29.978933334350586,
          -24.85822868347168,
          -7.4312639236450195,
          -29.459699630737305,
          -14.106328010559082,
          -21.31732749938965,
          -32.70002365112305,
          -29.67205047607422,
          -32.688106536865234,
          -30.792322158813477,
          -14.484172821044922,
          -19.648155212402344,
          -19.908302307128906,
          2.2558014392852783,
          -34.96668243408203,
          -15.634814262390137,
          -32.78310012817383,
          -25.17418098449707,
          -23.856182098388672,
          -31.42673683166504,
          -3.3136987686157227,
          -30.476003646850586,
          -28.841285705566406,
          -35.1773681640625,
          16.381486892700195,
          -27.154211044311523,
          -30.462345123291016,
          -3.084444284439087,
          -31.47987174987793,
          -21.0040225982666,
          -31.224559783935547,
          -19.861194610595703,
          -27.709320068359375,
          -30.159732818603516,
          -35.47177505493164,
          -17.122888565063477,
          -10.771171569824219,
          3.3136463165283203,
          -21.81528663635254,
          0.6783732175827026,
          -6.688207626342773,
          -26.624515533447266,
          -11.863462448120117,
          -9.304072380065918,
          -23.552207946777344,
          -31.624502182006836,
          -34.51225662231445,
          -34.90410232543945,
          -32.594886779785156,
          -32.34375762939453,
          -28.11399269104004,
          -20.63911247253418,
          -31.717939376831055,
          -19.197908401489258,
          -33.428619384765625,
          -33.18241500854492,
          -22.6614990234375,
          -31.510269165039062,
          -29.379117965698242,
          -31.824512481689453,
          -35.19915771484375,
          -29.294710159301758,
          -23.64187240600586,
          5.371075630187988,
          -30.046245574951172,
          -24.67861557006836,
          -34.681304931640625,
          -29.213382720947266,
          -28.08407211303711,
          -34.16594314575195,
          -35.03022384643555,
          -32.60700988769531,
          -29.014142990112305,
          -24.330167770385742,
          -31.46601104736328,
          -18.50746726989746,
          17.38531494140625,
          -20.138303756713867,
          -30.65497589111328,
          -31.937700271606445,
          -18.997394561767578,
          -17.91199493408203,
          -28.009544372558594,
          -24.48651695251465,
          -32.987735748291016,
          -26.871347427368164,
          -18.902414321899414,
          -33.393253326416016,
          -19.687368392944336,
          -28.42325782775879,
          -27.148481369018555,
          -33.62034225463867,
          -34.895137786865234,
          -29.731836318969727,
          -27.122257232666016,
          -31.015613555908203,
          -24.357370376586914,
          -26.067001342773438,
          -19.927831649780273,
          -26.90550994873047,
          -30.541183471679688,
          -31.839693069458008,
          -16.933799743652344,
          -20.77150535583496,
          -31.118602752685547,
          -30.156530380249023,
          -24.035242080688477,
          -22.524446487426758,
          -25.9499568939209,
          17.73192596435547,
          -31.886354446411133,
          -24.874305725097656,
          -1.3429656028747559,
          -30.300209045410156,
          -28.567550659179688,
          -33.41278076171875,
          -32.61056137084961,
          -26.32697296142578,
          -34.67296600341797,
          -13.860450744628906,
          -27.605493545532227,
          -27.210296630859375,
          -28.580638885498047,
          -18.415828704833984,
          -23.404666900634766,
          9.208093643188477,
          -17.68037223815918,
          -29.160831451416016,
          -23.653867721557617,
          -31.676509857177734,
          -28.942806243896484,
          -29.429676055908203,
          -16.780698776245117,
          -30.552156448364258,
          -8.889928817749023,
          13.74736213684082,
          -13.084389686584473,
          10.652175903320312,
          -17.376686096191406,
          -28.712997436523438,
          -27.72955322265625,
          -30.884971618652344,
          -18.926742553710938,
          -28.602357864379883,
          -34.30825424194336,
          -26.527921676635742,
          -20.71649169921875,
          -33.10747528076172,
          -33.1890983581543,
          -33.273529052734375,
          -27.862314224243164,
          -13.221029281616211,
          -32.607177734375,
          -29.760622024536133,
          -34.457801818847656,
          14.218025207519531,
          -30.57169532775879,
          -26.781028747558594,
          -27.62183380126953,
          -24.032310485839844,
          -27.10990333557129,
          -5.714084148406982,
          -23.93501091003418,
          -13.248218536376953,
          -31.562559127807617,
          -23.288040161132812,
          -25.897987365722656,
          -34.020938873291016,
          -29.849016189575195,
          -33.54602813720703,
          -16.176786422729492,
          -16.043209075927734,
          -27.342365264892578,
          -29.342788696289062,
          -32.88066864013672,
          -32.88155746459961,
          -27.83652687072754,
          -31.7696533203125,
          -28.227949142456055,
          -29.858858108520508,
          -13.626096725463867,
          -33.257564544677734,
          -32.16923522949219,
          -30.923011779785156,
          -33.13256072998047,
          -26.81622314453125,
          -27.067941665649414,
          -32.91187286376953,
          -30.330339431762695,
          -33.218406677246094,
          -36.409828186035156,
          -14.396818161010742,
          -32.90968704223633,
          -35.702392578125,
          -20.625720977783203,
          -25.524383544921875,
          -27.05634307861328,
          -28.881324768066406,
          -31.424793243408203,
          -15.150959014892578,
          -25.516389846801758,
          -28.791244506835938,
          -31.310012817382812,
          -34.8974609375,
          -34.101043701171875,
          -31.901546478271484,
          -31.85472297668457,
          -32.280086517333984,
          -31.86369514465332,
          -33.7266960144043,
          -17.37847137451172,
          -10.855664253234863,
          -32.6656379699707,
          -31.46525001525879,
          -33.7158203125,
          -30.77324104309082,
          -30.85201072692871,
          -28.04459571838379,
          -29.141578674316406,
          -27.825876235961914,
          -21.154680252075195,
          -31.43581771850586,
          -34.67069625854492,
          -32.71818161010742,
          -32.375614166259766,
          -30.15286636352539,
          -25.991527557373047,
          -18.67820930480957,
          -26.145526885986328,
          -29.691997528076172,
          -26.869762420654297,
          -15.79371166229248,
          -28.498693466186523,
          -27.791545867919922,
          -31.444461822509766,
          -29.58312225341797,
          -22.407073974609375,
          -33.41269302368164,
          -27.133243560791016,
          -31.448331832885742,
          -32.29397201538086,
          -35.626094818115234,
          -20.06760025024414,
          -29.403770446777344,
          -32.50022506713867,
          -31.28073501586914,
          -16.732458114624023,
          -25.872896194458008,
          -27.858821868896484,
          -30.264118194580078,
          -4.385774612426758,
          -26.455883026123047,
          -28.63071632385254,
          -34.87605667114258,
          -0.3274634778499603,
          -32.60778045654297,
          -30.236583709716797,
          -31.5858154296875,
          -33.29302978515625,
          -28.37165069580078,
          -16.473133087158203,
          -31.792095184326172,
          -30.4201717376709,
          -24.60772132873535,
          -26.666460037231445,
          -30.921476364135742,
          -30.981754302978516,
          3.3406410217285156,
          -35.33982849121094,
          -23.682344436645508,
          -28.94797706604004,
          -26.045969009399414,
          -31.884300231933594,
          -29.662811279296875,
          -32.664146423339844,
          -32.05192565917969,
          -26.349075317382812,
          -30.70130729675293,
          -30.401222229003906,
          -34.249839782714844,
          -30.514461517333984,
          -28.131275177001953,
          -27.955575942993164,
          -33.45735549926758,
          2.739006996154785,
          -14.074922561645508,
          -32.94305419921875,
          -26.151033401489258,
          -32.217411041259766,
          -6.099054336547852,
          18.29738998413086,
          -32.65118408203125,
          -21.834854125976562,
          -31.83256721496582,
          -25.58539390563965,
          -34.28262710571289,
          -30.390588760375977,
          -31.489696502685547,
          -28.994216918945312,
          -31.055191040039062,
          -34.408538818359375,
          -22.022676467895508,
          -32.07353210449219,
          -22.310171127319336,
          -25.80156898498535,
          -32.945640563964844,
          -34.58321762084961,
          -26.79009246826172,
          -29.67930030822754,
          -29.339601516723633,
          -33.163963317871094,
          -36.14051055908203,
          -33.81028366088867,
          -15.705370903015137,
          -32.649208068847656,
          -29.070531845092773,
          -30.997541427612305,
          -19.904993057250977,
          -32.887210845947266,
          -29.747833251953125,
          -27.39400863647461,
          -32.262962341308594,
          -30.025157928466797,
          -32.048797607421875,
          -31.51446533203125,
          -35.247711181640625,
          -30.66423988342285,
          -26.30963897705078,
          -30.32463836669922,
          -34.77616500854492,
          -30.13810920715332,
          -31.244884490966797,
          -11.960482597351074,
          -30.479938507080078,
          -30.571308135986328,
          -30.842891693115234,
          -27.014379501342773,
          -30.596904754638672,
          -32.17981719970703,
          -28.4558162689209,
          -28.35002899169922,
          -31.732938766479492,
          -35.33066177368164,
          -32.077178955078125,
          -31.661588668823242,
          -26.795167922973633,
          -27.681766510009766,
          -28.76331901550293,
          -26.23796844482422,
          -32.00313949584961,
          -25.14043426513672,
          -20.14621353149414,
          -30.86736297607422,
          -28.639253616333008,
          -30.85781478881836,
          -30.347393035888672,
          -26.869285583496094,
          -35.05887985229492,
          -33.072967529296875,
          -29.829669952392578,
          -35.19538116455078,
          -31.442678451538086,
          -31.189056396484375,
          -33.36214065551758,
          -28.9594669342041,
          -32.730621337890625,
          -20.97235679626465,
          -32.359066009521484,
          -26.08793067932129,
          -21.299108505249023,
          -24.128231048583984,
          -33.80507278442383,
          -33.531219482421875,
          -28.955734252929688,
          -33.345458984375,
          -31.472305297851562,
          -24.771621704101562,
          -22.534326553344727,
          -28.161928176879883,
          -27.113147735595703,
          -31.054391860961914,
          -29.58904457092285,
          -28.14917755126953,
          -33.36284255981445,
          -30.86042594909668,
          -29.387990951538086,
          -26.680505752563477,
          -30.772579193115234,
          -28.287071228027344,
          -24.995742797851562,
          -34.72348403930664,
          -34.179264068603516,
          -35.72634506225586,
          -26.361188888549805,
          -32.82211685180664,
          -29.120649337768555,
          -28.655540466308594,
          -33.05246353149414,
          -3.255335807800293,
          -27.318178176879883,
          -21.67326545715332,
          -32.756919860839844,
          -30.87982177734375,
          -31.365312576293945,
          -33.821083068847656,
          -32.55697250366211,
          -34.31511306762695,
          -36.22047424316406,
          -6.633201599121094,
          -29.881528854370117,
          -31.524446487426758,
          -24.66391372680664,
          -25.469148635864258,
          -31.302978515625,
          -27.07049560546875,
          -25.886701583862305,
          -35.17860794067383,
          -33.29360580444336,
          -27.598419189453125,
          -26.070531845092773,
          -17.61162757873535,
          -30.633323669433594,
          -30.11627197265625,
          -33.833614349365234,
          -29.348861694335938,
          -24.56534767150879,
          -30.32691192626953,
          -27.202611923217773,
          -27.265287399291992,
          -29.35553550720215,
          -30.342147827148438,
          -32.39470291137695,
          -33.15397262573242,
          -27.29109001159668,
          -32.25031280517578,
          -29.77702522277832,
          -27.855398178100586,
          -33.5924186706543,
          -13.887687683105469,
          -32.91410827636719,
          -26.366268157958984,
          -28.511476516723633,
          -35.33031463623047,
          -29.205129623413086,
          -26.425445556640625,
          -27.44217300415039,
          -25.04501724243164,
          -35.23867416381836,
          -26.99949836730957,
          -27.415943145751953,
          -32.29316711425781,
          -25.568153381347656,
          -23.1085205078125,
          -35.516639709472656,
          -31.76518440246582,
          -31.605737686157227,
          -26.014209747314453,
          -29.6401309967041,
          -12.114228248596191,
          -26.521177291870117,
          -30.85478973388672,
          -33.48488235473633,
          -30.958486557006836,
          -32.699974060058594,
          -11.064621925354004
         ],
         "y": [
          8.574629783630371,
          10.272871971130371,
          9.500164985656738,
          10.092294692993164,
          9.355950355529785,
          4.637571334838867,
          9.476975440979004,
          9.500449180603027,
          10.445895195007324,
          7.08310604095459,
          8.42678451538086,
          10.45269775390625,
          9.190958976745605,
          7.4949140548706055,
          9.819746971130371,
          6.037291526794434,
          5.643877983093262,
          9.965691566467285,
          10.710164070129395,
          9.051444053649902,
          10.146769523620605,
          7.915126323699951,
          10.603866577148438,
          10.649893760681152,
          8.032660484313965,
          4.091607570648193,
          9.788108825683594,
          8.782576560974121,
          6.542656421661377,
          9.672595024108887,
          9.439826011657715,
          8.068989753723145,
          10.794023513793945,
          10.057008743286133,
          8.683547973632812,
          4.798459529876709,
          8.239609718322754,
          7.043629169464111,
          4.90942907333374,
          6.6996846199035645,
          8.31154727935791,
          7.714805603027344,
          3.155330181121826,
          8.570414543151855,
          3.770610809326172,
          10.132532119750977,
          5.896604061126709,
          5.464407444000244,
          6.6313886642456055,
          8.75312328338623,
          5.87841272354126,
          2.5088000297546387,
          6.433380603790283,
          6.808150291442871,
          6.308969974517822,
          6.100968360900879,
          6.053338527679443,
          9.119235038757324,
          6.516052722930908,
          8.076611518859863,
          4.923530101776123,
          4.932368278503418,
          6.424412727355957,
          5.161946773529053,
          5.631498336791992,
          8.570242881774902,
          3.7515358924865723,
          6.013418197631836,
          1.8744134902954102,
          4.180589199066162,
          1.0606435537338257,
          0.5657971501350403,
          4.2123589515686035,
          1.3241301774978638,
          4.36327600479126,
          2.3847362995147705,
          4.2462263107299805,
          0.7746409177780151,
          2.8566935062408447,
          5.3249711990356445,
          1.6826097965240479,
          2.11360502243042,
          0.8911349177360535,
          4.030747890472412,
          1.3731106519699097,
          3.161267042160034,
          0.860297679901123,
          1.7571049928665161,
          4.721892356872559,
          1.654163122177124,
          4.5388665199279785,
          0.9811684489250183,
          2.0350377559661865,
          0.28213387727737427,
          -20.292659759521484,
          0.6223909854888916,
          0.6856060028076172,
          1.6420974731445312,
          1.4472596645355225,
          -19.7694034576416,
          -20.48760414123535,
          1.4959626197814941,
          2.204069137573242,
          -35.581241607666016,
          2.7640607357025146,
          -19.769454956054688,
          -29.00425910949707,
          -20.496824264526367,
          -23.620208740234375,
          0.4196929335594177,
          1.2409210205078125,
          -19.80928611755371,
          -23.71021842956543,
          -25.6669979095459,
          -25.488731384277344,
          -27.783592224121094,
          -24.51732635498047,
          1.0026566982269287,
          -27.76382064819336,
          -22.127397537231445,
          -25.98760223388672,
          -28.600297927856445,
          -22.88784408569336,
          -26.09601593017578,
          1.5748506784439087,
          -22.254291534423828,
          -29.57825469970703,
          -30.263538360595703,
          -24.316965103149414,
          -28.57391357421875,
          -29.511615753173828,
          -20.94269371032715,
          -19.65596580505371,
          -35.720733642578125,
          -24.67058753967285,
          -21.64602279663086,
          -24.944589614868164,
          -22.24126434326172,
          -23.674806594848633,
          -38.36140441894531,
          -22.577085494995117,
          -26.589628219604492,
          -24.817087173461914,
          -36.42941665649414,
          -21.935630798339844,
          -21.081233978271484,
          -25.928417205810547,
          -21.17901039123535,
          -33.308048248291016,
          -32.15425491333008,
          -25.862571716308594,
          -20.152042388916016,
          -28.216299057006836,
          -36.309730529785156,
          -33.54946517944336,
          -22.932153701782227,
          -26.444326400756836,
          -27.86650276184082,
          -21.39191246032715,
          -23.05916976928711,
          -37.350791931152344,
          -30.565555572509766,
          -25.036455154418945,
          -24.827823638916016,
          -25.330028533935547,
          0.8550342321395874,
          -39.13967514038086,
          -41.22145080566406,
          -22.410686492919922,
          -29.41424560546875,
          -36.9384880065918,
          -27.16061019897461,
          -23.2427921295166,
          -43.76711654663086,
          -26.759397506713867,
          -36.24002456665039,
          -45.56025695800781,
          -31.918119430541992,
          -26.062664031982422,
          -33.58485412597656,
          -35.04889678955078,
          -29.782390594482422,
          -34.57994842529297,
          -38.257381439208984,
          -29.438495635986328,
          -26.350635528564453,
          -34.03168487548828,
          -31.415658950805664,
          -45.108177185058594,
          -34.126792907714844,
          -28.007966995239258,
          -34.104942321777344,
          -21.99277114868164,
          -22.66432762145996,
          -37.69607925415039,
          -39.490604400634766,
          -44.209197998046875,
          -35.057193756103516,
          -43.30933380126953,
          -43.891143798828125,
          -27.012361526489258,
          -41.347137451171875,
          -28.226062774658203,
          -35.118343353271484,
          -33.04158020019531,
          -44.88394546508789,
          -45.388328552246094,
          -45.65620422363281,
          -33.87221145629883,
          -42.980140686035156,
          -34.626224517822266,
          -41.416282653808594,
          -42.50090026855469,
          -41.55413818359375,
          -31.94048309326172,
          -31.1610107421875,
          -35.228050231933594,
          -43.25535583496094,
          -44.14769744873047,
          -35.597938537597656,
          -35.76996994018555,
          -31.5473575592041,
          -41.25700759887695,
          -43.72921371459961,
          -42.01362991333008,
          -44.92661666870117,
          -39.618247985839844,
          -35.34844207763672,
          -42.10128402709961,
          -44.858821868896484,
          -44.78894805908203,
          -41.08826446533203,
          -34.7861328125,
          -44.55583190917969,
          -42.962059020996094,
          -45.08890151977539,
          -42.5880241394043,
          -36.07066345214844,
          -40.706199645996094,
          -44.30899429321289,
          -45.36344528198242,
          -44.56768798828125,
          -45.090091705322266,
          -45.729652404785156,
          -45.15904998779297,
          -43.93210983276367,
          -40.235382080078125,
          -41.59992218017578,
          -42.454994201660156,
          -43.42512893676758,
          -34.35785675048828,
          -45.131465911865234,
          -42.561485290527344,
          -23.593074798583984,
          -38.065494537353516,
          -41.6924934387207,
          -44.582977294921875,
          -45.05137634277344,
          -44.489540100097656,
          -36.476715087890625,
          -44.836761474609375,
          -45.21126937866211,
          -44.498104095458984,
          -40.64068603515625,
          -43.70674514770508,
          -36.33621597290039,
          -42.814910888671875,
          -37.909820556640625,
          -26.87919044494629,
          -39.364967346191406,
          -38.59648895263672,
          -37.28032302856445,
          -45.48713302612305,
          -43.65696716308594,
          -40.95903015136719,
          -45.18778610229492,
          -44.5312385559082,
          -37.06500244140625,
          -24.352338790893555,
          -44.899662017822266,
          -44.91270446777344,
          -42.17486572265625,
          -44.1375617980957,
          -38.58884048461914,
          -44.728824615478516,
          -44.627777099609375,
          -44.60326385498047,
          -38.977294921875,
          -45.09194564819336,
          -43.51591873168945,
          -40.194557189941406,
          -42.919700622558594,
          -44.81172180175781,
          -43.03363037109375,
          -42.1981315612793,
          -29.434532165527344,
          -44.986576080322266,
          -45.604095458984375,
          -29.009897232055664,
          -12.32712459564209,
          -43.56262969970703,
          -44.328250885009766,
          -40.44757843017578,
          -9.538915634155273,
          -30.62936782836914,
          -44.43600082397461,
          -44.9848518371582,
          -38.212337493896484,
          -45.57974624633789,
          -43.337890625,
          -38.32857894897461,
          -40.854312896728516,
          -42.82062530517578,
          -42.973758697509766,
          -39.00816345214844,
          -44.521385192871094,
          -24.85559844970703,
          -45.322330474853516,
          -26.173572540283203,
          -43.60765838623047,
          -44.72538757324219,
          -43.14202880859375,
          -43.12983322143555,
          -33.62580871582031,
          -17.049467086791992,
          -44.19570541381836,
          -34.92049789428711,
          -37.53976058959961,
          -34.223628997802734,
          -33.11007308959961,
          -44.434844970703125,
          -24.86492347717285,
          -43.16251754760742,
          -32.885162353515625,
          -37.485870361328125,
          -33.13738250732422,
          -22.973257064819336,
          -14.2575044631958,
          -27.478784561157227,
          -44.75590133666992,
          -38.97038269042969,
          -29.81182289123535,
          -44.7381706237793,
          -42.311981201171875,
          -35.689029693603516,
          -44.13360595703125,
          -34.1682014465332,
          -14.957115173339844,
          -7.981330394744873,
          -28.89406967163086,
          -40.61979293823242,
          -35.90375900268555,
          -45.035789489746094,
          -4.83840274810791,
          -36.14848327636719,
          -43.19550704956055,
          -25.845937728881836,
          -29.61894989013672,
          -35.752384185791016,
          -21.834117889404297,
          -42.24490737915039,
          -17.67000389099121,
          -27.12844467163086,
          -35.71380615234375,
          -24.46285629272461,
          -11.472228050231934,
          -27.91571807861328,
          -45.01800537109375,
          -35.70618438720703,
          -43.87342071533203,
          -21.78550148010254,
          -34.73483657836914,
          -44.18169021606445,
          -45.167327880859375,
          -9.703246116638184,
          -28.328828811645508,
          -32.23463439941406,
          -37.5943489074707,
          -39.36065673828125,
          -26.272247314453125,
          -34.52400588989258,
          -21.96731948852539,
          -31.935686111450195,
          -23.730968475341797,
          -43.75898742675781,
          -30.758100509643555,
          -18.784360885620117,
          -43.862667083740234,
          -45.18029022216797,
          -35.02239990234375,
          -18.278621673583984,
          -43.90817642211914,
          -19.674129486083984,
          -7.9658989906311035,
          -13.753936767578125,
          -25.735424041748047,
          -23.177223205566406,
          -37.332698822021484,
          -44.260658264160156,
          -8.827471733093262,
          -44.08601760864258,
          -23.648601531982422,
          -30.024267196655273,
          -44.980255126953125,
          -2.7660422325134277,
          -39.895408630371094,
          -44.07052230834961,
          -11.715381622314453,
          -16.788818359375,
          -13.590599060058594,
          8.280402183532715,
          -31.937644958496094,
          -39.0949592590332,
          -30.163381576538086,
          -43.855709075927734,
          -19.339601516723633,
          -36.537715911865234,
          -5.206798553466797,
          -15.827568054199219,
          -14.724151611328125,
          -26.512306213378906,
          -43.74229431152344,
          -2.487067461013794,
          -31.720596313476562,
          19.539657592773438,
          -20.352460861206055,
          -35.653446197509766,
          -10.536920547485352,
          -10.79731559753418,
          -16.40302276611328,
          -38.883697509765625,
          -16.87676429748535,
          -37.46246337890625,
          -37.76881790161133,
          -23.28018569946289,
          -10.732453346252441,
          -5.9878249168396,
          -15.968596458435059,
          -15.889875411987305,
          -36.4415283203125,
          -21.947813034057617,
          -30.057886123657227,
          -33.55486297607422,
          -45.05427932739258,
          -25.301605224609375,
          -39.71748733520508,
          17.68488121032715,
          -30.68324851989746,
          -18.095417022705078,
          -45.16050338745117,
          -45.907554626464844,
          -13.069955825805664,
          -11.664366722106934,
          -32.66934585571289,
          -26.361970901489258,
          -13.776851654052734,
          15.735224723815918,
          -14.497995376586914,
          4.856130599975586,
          -17.80486488342285,
          -37.30863952636719,
          -7.915453910827637,
          -9.236189842224121,
          -30.597618103027344,
          -21.432720184326172,
          -21.804349899291992,
          -1.513877511024475,
          -43.24066925048828,
          -15.40013313293457,
          -7.581984996795654,
          -19.528356552124023,
          -18.759918212890625,
          -3.725360631942749,
          2.43713641166687,
          -16.207914352416992,
          -22.6186466217041,
          -31.44147491455078,
          -37.86753845214844,
          -33.152591705322266,
          -33.6156120300293,
          -28.36846160888672,
          -16.235076904296875,
          0.46757301688194275,
          -39.45839309692383,
          -17.1835994720459,
          -7.317741394042969,
          -27.366880416870117,
          -7.72216796875,
          -36.05339813232422,
          -37.00178909301758,
          -27.87815284729004,
          -11.667247772216797,
          -10.172476768493652,
          -3.490463972091675,
          -18.278995513916016,
          5.626254081726074,
          -6.168140888214111,
          -10.022398948669434,
          2.668581008911133,
          -7.361636638641357,
          -31.686132431030273,
          -18.503089904785156,
          -12.556568145751953,
          -18.7513370513916,
          -11.309160232543945,
          -25.930225372314453,
          -10.380800247192383,
          -25.454391479492188,
          -20.015399932861328,
          -3.493474006652832,
          25.39496421813965,
          -11.002331733703613,
          -23.481212615966797,
          -16.55561065673828,
          -14.175738334655762,
          12.659717559814453,
          35.63993835449219,
          -13.9353609085083,
          -9.679869651794434,
          -4.591545104980469,
          -7.1929240226745605,
          -22.45168113708496,
          -7.319697380065918,
          -14.696593284606934,
          -19.40477752685547,
          5.766711235046387,
          -15.922809600830078,
          5.394127368927002,
          -1.121706485748291,
          -16.42889976501465,
          -8.128063201904297,
          -3.8273422718048096,
          -22.20323944091797,
          -21.3642578125,
          -36.75178146362305,
          -43.636009216308594,
          -19.70298957824707,
          -21.1245059967041,
          -25.73166847229004,
          -12.034936904907227,
          -30.852397918701172,
          10.840404510498047,
          -5.821752548217773,
          -17.319217681884766,
          -11.202323913574219,
          23.722049713134766,
          5.114394664764404,
          -1.4119811058044434,
          -22.215137481689453,
          -37.718505859375,
          13.246133804321289,
          -36.44519805908203,
          3.869276285171509,
          -17.308637619018555,
          -19.740442276000977,
          1.8639800548553467,
          16.183305740356445,
          21.262310028076172,
          31.254430770874023,
          -26.561492919921875,
          -4.471811771392822,
          -16.451343536376953,
          16.618024826049805,
          -2.8290982246398926,
          7.977432727813721,
          -0.007313189096748829,
          -11.122190475463867,
          -30.660850524902344,
          13.499622344970703,
          -8.857129096984863,
          16.86300277709961,
          7.1404128074646,
          0.3431346118450165,
          -44.11223602294922,
          13.636750221252441,
          -5.96608829498291,
          -36.654109954833984,
          32.248348236083984,
          -15.11059856414795,
          -6.233989238739014,
          -33.877437591552734,
          11.771960258483887,
          5.414496421813965,
          -44.209346771240234,
          -35.34839630126953,
          34.44925308227539,
          -42.7163200378418,
          -4.829387187957764,
          -6.609363555908203,
          11.058381080627441,
          -9.573046684265137,
          -9.476951599121094,
          25.885393142700195,
          6.702848434448242,
          -16.20806312561035,
          -1.438814401626587,
          -3.417283535003662,
          -9.163920402526855,
          10.703822135925293,
          3.5235118865966797,
          14.907001495361328,
          30.71670150756836,
          -1.0022581815719604,
          7.272885799407959,
          -5.209935188293457,
          -11.690879821777344,
          -8.748006820678711,
          14.823246955871582,
          -0.700090229511261,
          0.10163289308547974,
          -19.422197341918945,
          -0.575335681438446,
          5.119610786437988,
          -7.254215717315674,
          -12.413403511047363,
          -28.89533233642578,
          -12.40493392944336,
          -10.80331802368164,
          24.62933921813965,
          38.089908599853516,
          14.307059288024902,
          1.0302531719207764,
          -20.583759307861328,
          -0.04072638973593712,
          26.84721565246582,
          -12.264108657836914,
          -12.331547737121582,
          -28.129934310913086,
          10.828572273254395,
          -11.560235023498535,
          -14.009937286376953,
          -3.7261223793029785,
          -15.493749618530273,
          14.76358699798584,
          -31.1004581451416,
          31.91609764099121,
          4.6476593017578125,
          8.064101219177246,
          32.9221076965332,
          -6.162394046783447,
          -15.4171724319458,
          -10.406198501586914,
          3.845520257949829,
          23.215620040893555,
          -1.6317253112792969,
          21.942174911499023,
          16.995769500732422,
          6.430110931396484,
          -6.978700637817383,
          18.180376052856445,
          39.65559387207031,
          14.86062240600586,
          11.994349479675293,
          -5.95509147644043,
          -23.909038543701172,
          -4.056066036224365,
          -12.891042709350586,
          -5.149336814880371,
          -8.146263122558594,
          -3.769965887069702,
          12.195056915283203,
          37.167606353759766,
          5.568997383117676,
          25.338497161865234,
          0.021511590108275414,
          14.558629035949707,
          3.8238909244537354,
          -15.251442909240723,
          10.1013822555542,
          -1.2604389190673828,
          -5.663856029510498,
          7.8488006591796875,
          34.81419372558594,
          5.67287540435791,
          8.433690071105957,
          36.199684143066406,
          1.7383240461349487,
          26.133926391601562,
          0.32600700855255127,
          34.31631851196289,
          29.10181427001953,
          36.0260124206543,
          3.457749128341675,
          32.759849548339844,
          9.842429161071777,
          35.20631408691406,
          28.889074325561523,
          12.36617374420166,
          3.4454197883605957,
          13.001957893371582,
          13.591771125793457,
          17.977397918701172,
          -0.8716705441474915,
          33.792938232421875,
          17.137144088745117,
          30.031736373901367,
          26.9371337890625,
          11.074077606201172,
          22.59956169128418,
          21.24396324157715,
          16.608137130737305,
          5.065004825592041,
          -11.600608825683594,
          7.880521297454834,
          21.157238006591797,
          15.912988662719727,
          -15.426154136657715,
          38.78827667236328,
          14.436089515686035,
          -6.839799880981445,
          7.426136493682861,
          24.150320053100586,
          1.756204605102539,
          -1.5534087419509888,
          7.025052547454834,
          -36.462772369384766,
          39.874595642089844,
          16.09578514099121,
          38.14820861816406,
          36.25474166870117,
          6.812577247619629,
          16.42123794555664,
          36.29288864135742,
          4.596611499786377,
          24.72056770324707,
          22.496461868286133,
          19.901918411254883,
          20.659404754638672,
          32.83430480957031,
          36.76348876953125,
          21.0698184967041,
          -2.3760595321655273,
          -9.740467071533203,
          -4.345455169677734,
          39.758724212646484,
          25.334245681762695,
          19.30828094482422,
          38.5462760925293,
          34.02610397338867,
          -2.3008103370666504,
          26.18291664123535,
          -1.059850811958313,
          3.594578504562378,
          31.082014083862305,
          -5.879230499267578,
          25.305625915527344,
          24.098297119140625,
          11.073482513427734,
          28.879297256469727,
          -12.734034538269043,
          35.094783782958984,
          14.95168399810791,
          36.780433654785156,
          25.359323501586914,
          -3.040628671646118,
          -0.7777708172798157,
          17.05976676940918,
          40.32474899291992,
          10.05036735534668,
          4.175654411315918,
          28.073396682739258,
          25.355876922607422,
          34.26531982421875,
          33.27202606201172,
          21.41895866394043,
          36.793601989746094,
          30.945240020751953,
          -0.3012513518333435,
          -7.100926876068115,
          6.203813076019287,
          10.73547077178955,
          7.468992710113525,
          39.627647399902344,
          32.58608627319336,
          -13.735197067260742,
          37.70819091796875,
          -7.998314380645752,
          17.537939071655273,
          32.194549560546875,
          40.62356948852539,
          23.610660552978516,
          32.87824249267578,
          35.308353424072266,
          30.161230087280273,
          2.0846259593963623,
          38.03890609741211,
          4.721196174621582,
          8.333693504333496,
          11.244544982910156,
          29.791385650634766,
          29.95857048034668,
          34.53710174560547,
          34.54243850708008,
          32.024635314941406,
          36.58912658691406,
          37.71343231201172,
          11.486617088317871,
          26.573741912841797,
          -16.152233123779297,
          6.719520568847656,
          7.45435094833374,
          16.033002853393555,
          12.95871639251709,
          9.664067268371582,
          40.97522735595703,
          36.405067443847656,
          9.404703140258789,
          38.96160888671875,
          35.46160125732422,
          15.673747062683105,
          34.08543014526367,
          20.87383270263672,
          39.782493591308594,
          19.60590171813965,
          13.247385025024414,
          28.67386245727539,
          32.30768585205078,
          39.42241668701172,
          -8.456403732299805,
          37.2249755859375,
          -8.880934715270996,
          35.687278747558594,
          38.76692199707031,
          19.792484283447266,
          6.70623779296875,
          27.066469192504883,
          29.22711944580078,
          35.399925231933594,
          31.290586471557617,
          37.1889762878418,
          30.181171417236328,
          15.215272903442383,
          26.540706634521484,
          36.31616973876953,
          39.896690368652344,
          27.322729110717773,
          38.586639404296875,
          18.138282775878906,
          21.409379959106445,
          24.6717472076416,
          35.06675720214844,
          39.26007843017578,
          -11.095681190490723,
          -19.227359771728516,
          13.98161506652832,
          25.501506805419922,
          5.828378677368164,
          2.974407196044922,
          33.190677642822266,
          31.568744659423828,
          26.480484008789062,
          18.345539093017578,
          36.67032241821289,
          20.29898452758789,
          39.181182861328125,
          36.08190155029297,
          31.270057678222656,
          26.38123893737793,
          6.270257949829102,
          38.78076934814453,
          35.447731018066406,
          38.79734802246094,
          3.051088809967041,
          36.74934768676758,
          37.45152282714844,
          20.5401554107666,
          19.660608291625977,
          -15.830499649047852,
          35.82097625732422,
          38.79975128173828,
          1.5747274160385132,
          27.590120315551758,
          38.07724380493164,
          21.05210304260254,
          37.628658294677734,
          11.201349258422852,
          30.62512969970703,
          18.292476654052734,
          27.588031768798828,
          35.36761474609375,
          34.46810531616211,
          21.157474517822266,
          32.82170104980469,
          27.133499145507812,
          32.796836853027344,
          19.54918670654297,
          13.633402824401855,
          17.279987335205078,
          4.021127700805664,
          29.11309051513672,
          -9.501053810119629,
          30.260334014892578,
          24.4081974029541,
          35.95424270629883,
          10.144519805908203,
          38.253631591796875,
          38.46715545654297,
          28.12282371520996,
          35.01179122924805,
          34.466209411621094,
          39.576194763183594,
          40.594398498535156,
          23.006044387817383,
          21.35888671875,
          11.48178768157959,
          21.902158737182617,
          39.70576095581055,
          38.367610931396484,
          11.866911888122559,
          36.56671142578125,
          35.51045227050781,
          29.129880905151367,
          22.810319900512695,
          -3.6466193199157715,
          36.53143310546875,
          13.818459510803223,
          22.088281631469727,
          39.3947868347168,
          16.395307540893555,
          12.439858436584473,
          23.748258590698242,
          37.84893798828125,
          34.403377532958984,
          35.26967239379883,
          39.98708724975586,
          38.97848892211914,
          16.337364196777344,
          36.1514892578125,
          30.11380386352539,
          41.28556442260742,
          20.580238342285156,
          41.076133728027344,
          32.055912017822266,
          38.505043029785156,
          38.125911712646484,
          28.520824432373047,
          7.082658290863037,
          35.14522933959961,
          14.420459747314453,
          29.86136245727539,
          37.607181549072266,
          12.078457832336426,
          37.584659576416016,
          38.01173782348633,
          -35.26069641113281,
          35.15172576904297,
          30.32480812072754,
          34.514976501464844,
          19.140085220336914,
          32.06404495239258,
          18.704492568969727,
          25.082340240478516,
          37.480979919433594,
          40.151206970214844,
          3.4063947200775146,
          31.452804565429688,
          14.082701683044434,
          28.77914810180664,
          33.54253005981445,
          35.17567443847656,
          27.93110466003418,
          -0.7754507064819336,
          33.46442794799805,
          1.0781753063201904,
          33.70756912231445,
          15.317376136779785,
          34.524940490722656,
          15.74460220336914,
          38.010990142822266,
          31.632593154907227,
          38.30498123168945,
          28.65715980529785,
          37.537742614746094,
          -26.28334617614746,
          32.46931838989258,
          7.025089263916016,
          30.73752212524414,
          29.807449340820312,
          40.69365310668945,
          39.47945022583008,
          29.086341857910156,
          30.034393310546875,
          37.27565383911133,
          18.14565086364746,
          38.03232192993164,
          35.402992248535156,
          33.99307632446289,
          25.770235061645508,
          16.450469970703125,
          24.961376190185547,
          26.20049285888672,
          40.163978576660156,
          3.153325080871582,
          28.11561393737793,
          23.713848114013672,
          17.46057891845703,
          -17.533855438232422,
          21.815811157226562,
          31.02562713623047,
          38.942359924316406,
          21.816186904907227,
          36.64805221557617,
          32.3570442199707,
          1.9346786737442017,
          30.659536361694336,
          21.973745346069336,
          15.449738502502441,
          -1.0195229053497314,
          -4.41714334487915,
          -17.762510299682617,
          25.620038986206055,
          18.541353225708008,
          29.232038497924805,
          37.2996826171875,
          37.43655014038086,
          0.6849755644798279,
          19.037031173706055,
          39.75754928588867,
          27.062828063964844,
          -0.1230444610118866,
          2.5601322650909424,
          35.80084991455078,
          26.503629684448242,
          11.81118392944336,
          12.513497352600098,
          19.73622703552246,
          -28.633291244506836,
          21.325489044189453,
          34.03525924682617,
          28.899707794189453,
          36.972957611083984,
          16.74858283996582,
          35.346763610839844,
          0.4780345857143402,
          35.34906005859375,
          38.385597229003906,
          37.965335845947266,
          36.759132385253906,
          -3.1657636165618896,
          -28.024354934692383,
          17.370004653930664,
          -12.971800804138184,
          26.612468719482422,
          19.931299209594727,
          39.871726989746094,
          -3.8549842834472656,
          37.65224075317383,
          26.842670440673828,
          31.173133850097656,
          23.719249725341797,
          13.471193313598633,
          -11.420659065246582,
          23.784868240356445,
          23.440126419067383,
          20.924549102783203,
          36.18611145019531,
          28.32847023010254,
          40.68014907836914,
          22.993314743041992,
          27.06184196472168,
          -2.795347213745117,
          -21.205068588256836,
          2.3937366008758545,
          27.02332878112793,
          37.75873947143555,
          23.750255584716797,
          39.52994155883789,
          39.22090148925781,
          17.478601455688477,
          20.590444564819336,
          22.233137130737305,
          36.67277908325195,
          36.11781311035156,
          18.56654930114746,
          36.598716735839844,
          36.75761795043945,
          33.26596450805664,
          37.28740310668945,
          24.862709045410156,
          21.040098190307617,
          4.510501384735107,
          32.208946228027344,
          31.08879280090332,
          22.05014991760254,
          31.512969970703125,
          15.661442756652832,
          33.60547637939453,
          20.290475845336914,
          37.592159271240234,
          -2.6801114082336426,
          37.605777740478516,
          33.130950927734375,
          -0.2974390387535095,
          29.151817321777344,
          4.749741077423096,
          9.117013931274414,
          37.045719146728516,
          -32.049774169921875,
          38.58707046508789,
          38.72396469116211,
          -2.389179229736328,
          36.514495849609375,
          36.31447219848633,
          24.770082473754883,
          -1.6624925136566162,
          7.49665641784668,
          5.275834083557129,
          38.13599395751953,
          -31.12165641784668,
          25.718191146850586,
          -18.68567657470703,
          -19.00948715209961,
          -29.128032684326172,
          38.1668815612793,
          37.57676696777344,
          25.549692153930664,
          16.257925033569336,
          36.9313850402832,
          40.106380462646484,
          38.127559661865234,
          25.311307907104492,
          28.791902542114258,
          22.5577392578125,
          22.885202407836914,
          36.344947814941406,
          13.090265274047852,
          2.349648952484131,
          -20.853073120117188,
          31.65523338317871,
          -17.660547256469727,
          34.273075103759766,
          36.22855758666992,
          -16.75992202758789,
          -16.0380916595459,
          9.671323776245117,
          31.87474250793457,
          15.93043327331543,
          31.446067810058594,
          13.786750793457031,
          32.414005279541016,
          8.016850471496582,
          28.48965072631836,
          14.326072692871094,
          29.94809913635254,
          34.17873764038086,
          -5.6393609046936035,
          12.638081550598145,
          -30.906463623046875,
          40.551570892333984,
          35.512142181396484,
          -19.02393341064453,
          37.33727264404297,
          9.027329444885254,
          36.67631149291992,
          10.222245216369629,
          35.746463775634766,
          40.123592376708984,
          38.63982009887695,
          22.381006240844727,
          18.967350006103516,
          16.59732437133789,
          -11.453335762023926,
          34.267520904541016,
          35.59675598144531,
          22.8143367767334,
          33.33190155029297,
          30.115785598754883,
          33.699649810791016,
          26.13218879699707,
          26.94492530822754,
          16.260698318481445,
          33.65437316894531,
          -9.359427452087402,
          38.859031677246094,
          36.285152435302734,
          -15.875988006591797,
          37.64986038208008,
          36.90653991699219,
          5.4445881843566895,
          12.562504768371582,
          4.72002649307251,
          38.23735046386719,
          31.370481491088867,
          5.519895076751709,
          38.66896438598633,
          -21.248069763183594,
          -11.796917915344238,
          25.97248077392578,
          36.867652893066406,
          21.05699348449707,
          37.037044525146484,
          28.511943817138672,
          25.279481887817383,
          22.705364227294922,
          -9.692148208618164,
          14.464461326599121,
          36.1835823059082,
          17.29401397705078,
          38.176414489746094,
          35.93490982055664,
          13.955068588256836,
          31.04034423828125,
          -14.109501838684082,
          34.232662200927734,
          29.269655227661133,
          24.302783966064453,
          -8.05965518951416,
          17.732175827026367,
          19.850263595581055,
          -6.137049674987793,
          34.081298828125,
          36.91191482543945,
          -30.121618270874023,
          22.60733985900879,
          17.885799407958984,
          11.40019702911377,
          -27.342754364013672,
          6.032310485839844,
          37.42820739746094,
          40.2411994934082,
          28.1492919921875,
          15.464639663696289,
          -4.54620885848999,
          17.34446144104004,
          -4.048579216003418,
          33.53943634033203,
          5.139894008636475,
          40.895957946777344,
          18.87037467956543,
          24.68947410583496,
          37.45601272583008,
          20.77004623413086,
          28.634140014648438,
          18.615068435668945,
          18.45840072631836,
          38.276222229003906,
          33.143898010253906,
          7.158633708953857,
          -23.464340209960938,
          -28.245079040527344,
          -29.080896377563477,
          23.852903366088867,
          8.560145378112793,
          24.056325912475586,
          28.841157913208008,
          33.718624114990234,
          25.175399780273438,
          -30.257925033569336,
          -8.186507225036621,
          30.849027633666992,
          -12.394735336303711,
          33.38603973388672,
          -5.095117092132568,
          -21.34309959411621,
          -9.806323051452637,
          38.78195571899414,
          40.56167984008789,
          18.86642074584961,
          -23.000246047973633,
          32.88167190551758,
          39.808441162109375,
          26.877614974975586,
          -11.351815223693848,
          -37.07803726196289,
          16.479528427124023,
          22.958887100219727,
          18.919279098510742,
          13.109928131103516,
          11.293880462646484,
          -30.563491821289062,
          -1.4569144248962402,
          -38.59992599487305,
          -14.829639434814453,
          14.407383918762207,
          0.6090161800384521,
          -15.648819923400879,
          28.291091918945312,
          12.939355850219727,
          17.50979995727539,
          -9.99621868133545,
          17.7994384765625,
          -26.495952606201172,
          15.322710990905762,
          -4.252577781677246,
          -7.009757995605469,
          -1.3428256511688232,
          18.936662673950195,
          37.09095001220703,
          7.616784572601318,
          27.190670013427734,
          21.297359466552734,
          -24.706823348999023,
          8.754612922668457,
          -10.107491493225098,
          0.1355740875005722,
          32.4105339050293,
          23.233074188232422,
          22.24749183654785,
          39.01996994018555,
          -2.4142210483551025,
          31.424394607543945,
          -17.83191680908203,
          19.6123046875,
          26.50009536743164,
          -5.811788082122803,
          41.36116409301758,
          -7.344816207885742,
          -33.3818473815918,
          -9.882530212402344,
          22.064760208129883,
          17.518253326416016,
          -14.973118782043457,
          38.812965393066406,
          0.9725958108901978,
          21.307363510131836,
          -10.294975280761719,
          24.5318660736084,
          13.817744255065918,
          4.390139579772949,
          -4.852285861968994,
          32.03532791137695,
          30.82967185974121,
          38.08331298828125,
          27.277376174926758,
          36.820030212402344,
          33.483280181884766,
          18.580625534057617,
          31.007383346557617,
          31.763944625854492,
          16.731277465820312,
          -8.052446365356445,
          -18.68680763244629,
          -5.964759826660156,
          -13.523469924926758,
          5.871826171875,
          -35.55958557128906,
          19.131851196289062,
          -21.10324478149414,
          19.768033981323242,
          -16.35703468322754,
          -0.7872694134712219,
          19.758020401000977,
          9.237922668457031,
          -12.422285079956055,
          8.525077819824219,
          -9.347692489624023,
          -31.089292526245117,
          26.540447235107422,
          37.847347259521484,
          -26.674381256103516,
          11.883484840393066,
          -12.283231735229492,
          1.3694359064102173,
          -27.900596618652344,
          -1.6438190937042236,
          -10.85562801361084,
          -18.597930908203125,
          11.761673927307129,
          13.99710464477539,
          6.807441234588623,
          26.21904945373535,
          29.30398178100586,
          27.64461898803711,
          -5.754844665527344,
          3.102236032485962,
          27.866044998168945,
          29.611892700195312,
          12.382709503173828,
          16.750926971435547,
          -14.541207313537598,
          12.297919273376465,
          27.141246795654297,
          -19.196537017822266,
          19.298025131225586,
          -29.652830123901367,
          -30.375070571899414,
          0.5797160863876343,
          -18.455659866333008,
          -25.88419532775879,
          18.896528244018555,
          -19.774860382080078,
          11.689274787902832,
          20.950376510620117,
          28.895124435424805,
          -37.582916259765625,
          -2.325268030166626,
          -9.475703239440918,
          28.34689712524414,
          18.804058074951172,
          -2.9725494384765625,
          2.3623688220977783,
          23.31038475036621,
          16.62982177734375,
          -39.1666145324707,
          29.61333465576172,
          -29.5970401763916,
          15.47853946685791,
          41.54197692871094,
          -28.85401725769043,
          -32.56297302246094,
          1.5727901458740234,
          -5.215909004211426,
          8.806000709533691,
          0.9882593750953674,
          30.6879825592041,
          -34.265499114990234,
          19.192502975463867,
          7.434864044189453,
          25.899717330932617,
          12.974477767944336,
          39.08135986328125,
          23.847270965576172,
          12.580924987792969,
          25.375703811645508,
          5.895778179168701,
          11.265738487243652,
          -28.935016632080078,
          29.402502059936523,
          -17.302885055541992,
          37.42595291137695,
          36.4899787902832,
          30.135026931762695,
          38.519859313964844,
          28.259475708007812,
          9.270517349243164,
          13.493708610534668,
          5.326316833496094,
          23.2672176361084,
          -30.42226791381836,
          -11.597559928894043,
          -36.5155143737793,
          27.169374465942383,
          -17.12310218811035,
          5.442599296569824,
          -2.094452142715454,
          15.328033447265625,
          29.231943130493164,
          -7.9527177810668945,
          17.04901123046875,
          -6.969643592834473,
          34.11278533935547,
          13.016904830932617,
          15.598464965820312,
          11.784987449645996,
          24.0971736907959,
          11.528903007507324,
          36.95800018310547,
          19.863754272460938,
          32.8658332824707,
          -22.333202362060547,
          27.09495735168457,
          -36.519378662109375,
          -16.318267822265625,
          -28.226581573486328,
          -14.711333274841309,
          27.114234924316406,
          30.613731384277344,
          10.385458946228027,
          -1.765026569366455,
          -21.685344696044922,
          -5.876542091369629,
          8.144413948059082,
          -9.319902420043945,
          -28.91559410095215,
          -25.200910568237305,
          31.678529739379883,
          -15.649337768554688,
          -23.518056869506836,
          0.16664864122867584,
          -9.076753616333008,
          -34.63902282714844,
          -31.958581924438477,
          -14.627629280090332,
          -17.37566375732422,
          -20.08470916748047,
          -18.87481117248535,
          28.367265701293945,
          -24.12393569946289,
          -7.012326240539551,
          26.40464973449707,
          11.393387794494629,
          7.417564392089844,
          8.515277862548828,
          1.6300289630889893,
          32.52959442138672,
          20.458267211914062,
          6.097873687744141,
          -25.719974517822266,
          -8.162468910217285,
          -3.644162178039551,
          -2.267453670501709,
          8.407438278198242,
          8.13645076751709,
          11.61544418334961,
          -21.08411407470703,
          29.175334930419922,
          34.41905212402344,
          -17.075868606567383,
          -4.733792781829834,
          -13.787140846252441,
          -20.306650161743164,
          1.3993480205535889,
          10.177042007446289,
          -29.52004623413086,
          12.391257286071777,
          18.45118522644043,
          3.9144821166992188,
          2.01019024848938,
          -14.216063499450684,
          -3.6795380115509033,
          -27.55870819091797,
          -39.00056838989258,
          29.773855209350586,
          -37.94013595581055,
          -19.111783981323242,
          16.16260528564453,
          24.862428665161133,
          -34.57255554199219,
          -34.387367248535156,
          -12.63778305053711,
          -28.331079483032227,
          21.233320236206055,
          3.0586001873016357,
          -30.745759963989258,
          -12.626910209655762,
          -4.993643760681152,
          -7.133332252502441,
          25.439697265625,
          -25.10638427734375,
          -18.426950454711914,
          -19.393291473388672,
          25.109804153442383,
          16.728116989135742,
          -32.64485549926758,
          -1.8549915552139282,
          38.79914855957031,
          -38.38710403442383,
          -33.30885314941406,
          -17.523691177368164,
          40.71173095703125,
          -18.686201095581055,
          6.744800090789795,
          -14.605537414550781,
          -8.527661323547363,
          19.82779312133789,
          29.829891204833984,
          -28.659990310668945,
          -28.348909378051758,
          18.66071891784668,
          -37.37731170654297,
          8.039789199829102,
          -22.68754768371582,
          37.51875686645508,
          -3.0184547901153564,
          23.35716438293457,
          -33.34065628051758,
          -34.7867431640625,
          2.851367712020874,
          -22.37939453125,
          -3.9972708225250244,
          -20.873838424682617,
          -35.27960968017578,
          -20.854780197143555,
          -25.696334838867188,
          -20.778114318847656,
          -15.178598403930664,
          -35.3309440612793,
          -27.53555679321289,
          -5.254482269287109,
          36.16594314575195,
          28.218463897705078,
          0.6744902729988098,
          18.226539611816406,
          -26.93736457824707,
          34.51026153564453,
          21.51302719116211,
          -7.174545764923096,
          28.30133819580078,
          -10.907759666442871,
          18.37815284729004,
          -7.617560386657715,
          -10.366372108459473,
          -13.270197868347168,
          14.259621620178223,
          -7.213850975036621,
          -16.10051727294922,
          27.01633071899414,
          -1.3412476778030396,
          16.258914947509766,
          11.766876220703125,
          -15.79919719696045,
          -20.06700897216797,
          -35.92888259887695,
          2.3034822940826416,
          -26.828819274902344,
          4.6450066566467285,
          -18.901979446411133,
          -6.684815406799316,
          28.250123977661133,
          -20.842254638671875,
          4.1287312507629395,
          13.790451049804688,
          23.37982940673828,
          -8.127249717712402,
          -29.41454315185547,
          -28.428550720214844,
          -27.0236759185791,
          -19.5709285736084,
          -26.924928665161133,
          -14.544495582580566,
          -14.160179138183594,
          7.462110996246338,
          -37.11940002441406,
          -5.527460098266602,
          -5.222291946411133,
          -8.857620239257812,
          -18.775875091552734,
          32.8205680847168,
          2.5052542686462402,
          -29.957521438598633,
          -28.922788619995117,
          -33.948455810546875,
          -18.575790405273438,
          5.899981498718262,
          -26.1258544921875,
          -35.49715805053711,
          12.389131546020508,
          -14.671056747436523,
          -23.882232666015625,
          -8.545257568359375,
          8.918155670166016,
          -31.391660690307617,
          13.547294616699219,
          -37.77098846435547,
          -18.01422691345215,
          13.448761940002441,
          25.510608673095703,
          -7.553495407104492,
          17.66461944580078,
          -22.524648666381836,
          3.923788547515869,
          -37.223655700683594,
          -0.47068920731544495,
          -1.714388132095337,
          -32.33744430541992,
          -7.938956260681152,
          3.93861985206604,
          -26.033870697021484,
          -5.059396743774414,
          -33.261898040771484,
          0.46202579140663147,
          22.869792938232422,
          -19.492279052734375,
          10.490194320678711,
          24.260555267333984,
          22.080047607421875,
          -10.788400650024414,
          -17.879295349121094,
          12.781614303588867,
          -23.532142639160156,
          -15.507854461669922,
          15.245590209960938,
          22.510887145996094,
          9.47620677947998,
          10.034514427185059,
          -8.947148323059082,
          8.771842956542969,
          -29.61618423461914,
          -2.6314821243286133,
          -27.84762954711914,
          14.935758590698242,
          21.012189865112305,
          -24.863910675048828,
          9.153132438659668,
          20.149221420288086,
          -17.73878288269043,
          -14.302970886230469,
          -16.117536544799805,
          19.778034210205078,
          -19.311416625976562,
          -26.197195053100586,
          -28.324125289916992,
          2.978050947189331,
          38.13840866088867,
          17.572301864624023,
          23.96540641784668,
          -7.422159671783447,
          -29.70332908630371,
          -23.802356719970703,
          -12.883692741394043,
          -13.105121612548828,
          -4.582128047943115,
          -9.389278411865234,
          35.3265495300293,
          -23.46307945251465,
          -1.8725461959838867,
          17.778005599975586,
          13.229482650756836,
          -25.19207763671875,
          -36.7645378112793,
          -39.40538787841797,
          -16.982322692871094,
          -2.00130033493042,
          -32.772216796875,
          -38.656925201416016,
          22.847326278686523,
          1.1704025268554688,
          -13.719173431396484,
          1.4577715396881104,
          15.108444213867188,
          14.929259300231934,
          -13.910324096679688,
          -36.38190460205078,
          -35.050106048583984,
          -29.67279815673828,
          -19.744020462036133,
          -7.034006118774414,
          -11.2750825881958,
          -29.20009994506836,
          -11.361492156982422,
          -21.276447296142578,
          -31.607990264892578,
          1.6774885654449463,
          31.352275848388672,
          -20.15176773071289,
          -36.117061614990234,
          -34.39592361450195,
          -9.25309944152832,
          0.6283493638038635,
          -34.24634552001953,
          -36.82942199707031,
          22.908584594726562,
          -16.658687591552734,
          -37.449729919433594,
          -33.78341293334961,
          7.447916507720947,
          13.367210388183594,
          13.951016426086426,
          -12.107762336730957,
          -17.914913177490234,
          -28.865270614624023,
          -37.16293716430664,
          -31.951866149902344,
          33.03255081176758,
          -38.04145431518555,
          -30.459627151489258,
          -23.135393142700195,
          -29.300039291381836,
          -13.10558032989502,
          33.46169662475586
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3a327a42-81e8-41c2-8541-a6e2c490118d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a327a42-81e8-41c2-8541-a6e2c490118d\")) {                    Plotly.newPlot(                        \"3a327a42-81e8-41c2-8541-a6e2c490118d\",                        [{\"mode\":\"text\",\"text\":[\"the\",\"to\",\"of\",\"in\",\"and\",\"he\",\"is\",\"for\",\"on\",\"said\",\"that\",\"has\",\"says\",\"was\",\"have\",\"it\",\"be\",\"are\",\"with\",\"will\",\"at\",\"mr\",\"from\",\"by\",\"we\",\"been\",\"as\",\"an\",\"not\",\"his\",\"but\",\"they\",\"after\",\"were\",\"had\",\"there\",\"new\",\"this\",\"australia\",\"australian\",\"who\",\"palestinian\",\"people\",\"their\",\"government\",\"two\",\"up\",\"south\",\"us\",\"which\",\"year\",\"one\",\"about\",\"out\",\"if\",\"also\",\"more\",\"when\",\"its\",\"into\",\"would\",\"first\",\"last\",\"against\",\"israeli\",\"minister\",\"arafat\",\"over\",\"all\",\"three\",\"afghanistan\",\"united\",\"world\",\"no\",\"or\",\"police\",\"than\",\"attacks\",\"fire\",\"before\",\"some\",\"security\",\"day\",\"you\",\"states\",\"could\",\"them\",\"say\",\"today\",\"now\",\"told\",\"time\",\"any\",\"laden\",\"very\",\"bin\",\"just\",\"can\",\"sydney\",\"what\",\"still\",\"company\",\"president\",\"man\",\"four\",\"taliban\",\"killed\",\"our\",\"forces\",\"al\",\"around\",\"being\",\"days\",\"west\",\"old\",\"other\",\"officials\",\"where\",\"so\",\"test\",\"qaeda\",\"israel\",\"think\",\"per\",\"general\",\"next\",\"federal\",\"force\",\"cent\",\"she\",\"leader\",\"yesterday\",\"workers\",\"take\",\"him\",\"hamas\",\"under\",\"state\",\"those\",\"years\",\"meeting\",\"bank\",\"suicide\",\"back\",\"action\",\"commission\",\"made\",\"down\",\"morning\",\"re\",\"pakistan\",\"international\",\"city\",\"attack\",\"centre\",\"group\",\"afghan\",\"members\",\"while\",\"military\",\"well\",\"number\",\"through\",\"qantas\",\"five\",\"local\",\"called\",\"area\",\"union\",\"gaza\",\"week\",\"national\",\"since\",\"wales\",\"including\",\"hours\",\"september\",\"another\",\"east\",\"night\",\"report\",\"off\",\"north\",\"should\",\"get\",\"second\",\"go\",\"earlier\",\"war\",\"staff\",\"six\",\"these\",\"between\",\"islamic\",\"months\",\"further\",\"end\",\"defence\",\"do\",\"sharon\",\"near\",\"team\",\"foreign\",\"power\",\"areas\",\"work\",\"going\",\"authority\",\"because\",\"way\",\"eight\",\"india\",\"only\",\"know\",\"month\",\"during\",\"died\",\"many\",\"match\",\"make\",\"air\",\"metres\",\"left\",\"claims\",\"spokesman\",\"ve\",\"former\",\"melbourne\",\"northern\",\"good\",\"authorities\",\"most\",\"osama\",\"support\",\"prime\",\"peace\",\"like\",\"set\",\"ago\",\"expected\",\"saying\",\"given\",\"am\",\"come\",\"looking\",\"militants\",\"bora\",\"tora\",\"put\",\"place\",\"several\",\"fighters\",\"children\",\"arrested\",\"injured\",\"found\",\"river\",\"royal\",\"groups\",\"africa\",\"unions\",\"christmas\",\"troops\",\"meanwhile\",\"indian\",\"child\",\"hospital\",\"terrorist\",\"interim\",\"part\",\"reports\",\"talks\",\"official\",\"whether\",\"then\",\"yasser\",\"statement\",\"leaders\",\"economy\",\"mountains\",\"how\",\"industrial\",\"third\",\"terrorism\",\"senior\",\"start\",\"don\",\"early\",\"radio\",\"john\",\"hit\",\"trying\",\"weather\",\"public\",\"both\",\"believe\",\"family\",\"pay\",\"million\",\"army\",\"court\",\"dr\",\"long\",\"best\",\"control\",\"help\",\"however\",\"lead\",\"adelaide\",\"asked\",\"following\",\"chief\",\"pressure\",\"agreement\",\"does\",\"service\",\"firefighters\",\"close\",\"few\",\"services\",\"labor\",\"play\",\"better\",\"community\",\"taken\",\"want\",\"arrest\",\"queensland\",\"house\",\"need\",\"overnight\",\"australians\",\"high\",\"confirmed\",\"process\",\"information\",\"came\",\"believed\",\"williams\",\"must\",\"opposition\",\"detainees\",\"won\",\"secretary\",\"did\",\"peter\",\"party\",\"held\",\"damage\",\"governor\",\"maintenance\",\"released\",\"win\",\"pentagon\",\"possible\",\"her\",\"brought\",\"hicks\",\"much\",\"shot\",\"took\",\"accused\",\"nations\",\"british\",\"weekend\",\"lot\",\"violence\",\"building\",\"despite\",\"council\",\"return\",\"got\",\"airline\",\"asylum\",\"york\",\"dead\",\"kandahar\",\"conditions\",\"across\",\"hill\",\"winds\",\"safety\",\"even\",\"such\",\"change\",\"cut\",\"eastern\",\"without\",\"director\",\"armed\",\"working\",\"aircraft\",\"call\",\"here\",\"see\",\"palestinians\",\"december\",\"economic\",\"news\",\"american\",\"too\",\"home\",\"men\",\"seekers\",\"strip\",\"lee\",\"waugh\",\"role\",\"country\",\"region\",\"trade\",\"emergency\",\"crew\",\"strong\",\"race\",\"captured\",\"david\",\"southern\",\"fighting\",\"continuing\",\"fires\",\"monday\",\"far\",\"anti\",\"board\",\"cricket\",\"training\",\"key\",\"plans\",\"bush\",\"bureau\",\"act\",\"industry\",\"george\",\"head\",\"past\",\"water\",\"charged\",\"used\",\"administration\",\"received\",\"offer\",\"alliance\",\"rate\",\"zinni\",\"health\",\"least\",\"leading\",\"person\",\"captain\",\"your\",\"town\",\"boat\",\"large\",\"decision\",\"stop\",\"known\",\"airport\",\"operations\",\"may\",\"line\",\"within\",\"risk\",\"use\",\"downer\",\"israelis\",\"soldiers\",\"major\",\"britain\",\"final\",\"parliament\",\"department\",\"zealand\",\"hundreds\",\"issue\",\"strikes\",\"hih\",\"station\",\"legal\",\"shane\",\"plane\",\"might\",\"series\",\"interest\",\"un\",\"laws\",\"policy\",\"right\",\"ahead\",\"hollingworth\",\"tomorrow\",\"network\",\"pm\",\"able\",\"due\",\"kabul\",\"latest\",\"death\",\"homes\",\"weapons\",\"behind\",\"great\",\"coast\",\"western\",\"position\",\"give\",\"later\",\"late\",\"half\",\"officers\",\"my\",\"taking\",\"every\",\"remain\",\"campaign\",\"seen\",\"thought\",\"bill\",\"timor\",\"special\",\"side\",\"failed\",\"same\",\"flight\",\"along\",\"jobs\",\"storm\",\"me\",\"forced\",\"life\",\"others\",\"continue\",\"hard\",\"event\",\"abuse\",\"cup\",\"victory\",\"jihad\",\"guilty\",\"point\",\"towards\",\"really\",\"concerned\",\"heard\",\"already\",\"territory\",\"washington\",\"deaths\",\"mcgrath\",\"helicopters\",\"envoy\",\"canyoning\",\"capital\",\"bus\",\"bichel\",\"november\",\"likely\",\"details\",\"case\",\"member\",\"launched\",\"innings\",\"according\",\"enough\",\"bombings\",\"weeks\",\"countries\",\"again\",\"detention\",\"move\",\"woomera\",\"seven\",\"cabinet\",\"bowler\",\"buildings\",\"hour\",\"mark\",\"matter\",\"middle\",\"bombing\",\"th\",\"sunday\",\"situation\",\"rates\",\"space\",\"important\",\"warne\",\"dispute\",\"caught\",\"jail\",\"claimed\",\"wants\",\"perth\",\"adventure\",\"targets\",\"run\",\"swiss\",\"asio\",\"added\",\"commonwealth\",\"raids\",\"office\",\"evidence\",\"deal\",\"guides\",\"disease\",\"show\",\"boy\",\"women\",\"own\",\"freeze\",\"opened\",\"human\",\"forward\",\"carried\",\"african\",\"mission\",\"movement\",\"based\",\"sure\",\"reported\",\"immediately\",\"political\",\"warplanes\",\"young\",\"rule\",\"ms\",\"blue\",\"top\",\"justice\",\"money\",\"aedt\",\"cancer\",\"crash\",\"march\",\"banks\",\"border\",\"using\",\"although\",\"access\",\"financial\",\"allegations\",\"certainly\",\"planning\",\"probably\",\"break\",\"find\",\"wicket\",\"ground\",\"beat\",\"prepared\",\"burning\",\"become\",\"always\",\"job\",\"proposed\",\"each\",\"full\",\"reached\",\"collapse\",\"growth\",\"order\",\"island\",\"sector\",\"flying\",\"carrying\",\"result\",\"face\",\"investigation\",\"times\",\"relations\",\"militant\",\"road\",\"sex\",\"needs\",\"organisation\",\"until\",\"serious\",\"program\",\"fight\",\"calls\",\"stage\",\"getting\",\"lives\",\"responsibility\",\"reserve\",\"thursday\",\"comes\",\"management\",\"sent\",\"drop\",\"surrender\",\"allow\",\"soon\",\"afp\",\"tried\",\"post\",\"killing\",\"radical\",\"hewitt\",\"himself\",\"senator\",\"executive\",\"outside\",\"believes\",\"inquiry\",\"short\",\"caves\",\"different\",\"flights\",\"immigration\",\"tourists\",\"future\",\"inside\",\"bid\",\"energy\",\"clear\",\"trees\",\"thousands\",\"argentina\",\"militia\",\"suspected\",\"making\",\"bowling\",\"ariel\",\"went\",\"alleged\",\"rejected\",\"howard\",\"quickly\",\"wave\",\"harrison\",\"travel\",\"opening\",\"ansett\",\"kilometres\",\"declared\",\"running\",\"measures\",\"biggest\",\"list\",\"figures\",\"rise\",\"residents\",\"sea\",\"form\",\"annual\",\"anything\",\"attempt\",\"open\",\"parties\",\"available\",\"announced\",\"shortly\",\"among\",\"currently\",\"bombers\",\"circumstances\",\"accident\",\"donald\",\"ministers\",\"look\",\"brisbane\",\"decided\",\"ruddock\",\"changes\",\"yet\",\"issues\",\"address\",\"destroyed\",\"actually\",\"rights\",\"increase\",\"terms\",\"school\",\"rural\",\"fighter\",\"quite\",\"happened\",\"wounded\",\"victoria\",\"television\",\"nine\",\"something\",\"try\",\"parts\",\"white\",\"response\",\"done\",\"wickets\",\"witnesses\",\"refused\",\"karzai\",\"sentence\",\"ended\",\"tanks\",\"gunmen\",\"sources\",\"kallis\",\"agency\",\"july\",\"jewish\",\"warned\",\"directors\",\"understand\",\"meet\",\"means\",\"returned\",\"offices\",\"yacht\",\"source\",\"alexander\",\"ll\",\"fact\",\"difficult\",\"though\",\"period\",\"confidence\",\"wage\",\"airlines\",\"virus\",\"advice\",\"caused\",\"musharraf\",\"allan\",\"recession\",\"less\",\"ensure\",\"strike\",\"appeared\",\"islands\",\"crowd\",\"suharto\",\"highway\",\"afternoon\",\"step\",\"commanders\",\"began\",\"gave\",\"worst\",\"glenn\",\"bomb\",\"commissioner\",\"powell\",\"having\",\"beginning\",\"intelligence\",\"rafter\",\"prevent\",\"gives\",\"expressed\",\"huge\",\"ever\",\"big\",\"business\",\"ses\",\"media\",\"friday\",\"pacific\",\"robert\",\"expect\",\"blake\",\"runs\",\"involved\",\"followed\",\"deputy\",\"hobart\",\"whose\",\"market\",\"tour\",\"rather\",\"attorney\",\"elected\",\"beyond\",\"arrived\",\"away\",\"facility\",\"commander\",\"total\",\"law\",\"field\",\"supporters\",\"struck\",\"car\",\"cost\",\"sir\",\"negotiations\",\"nauru\",\"tennis\",\"massive\",\"entered\",\"threat\",\"plan\",\"explosives\",\"debt\",\"entitlements\",\"criticism\",\"decide\",\"quarter\",\"saturday\",\"assistance\",\"labour\",\"geoff\",\"together\",\"finished\",\"chance\",\"endeavour\",\"chairman\",\"main\",\"heavy\",\"base\",\"places\",\"tragedy\",\"sort\",\"vote\",\"giving\",\"jenin\",\"front\",\"powers\",\"anglican\",\"son\",\"zimbabwe\",\"themselves\",\"conflict\",\"yes\",\"muslim\",\"lockett\",\"daryl\",\"helicopter\",\"current\",\"fast\",\"complex\",\"terror\",\"smoke\",\"france\",\"anthony\",\"calling\",\"hearings\",\"population\",\"tasmania\",\"game\",\"jacques\",\"placed\",\"denied\",\"reid\",\"pakistani\",\"indonesia\",\"bring\",\"ballot\",\"played\",\"protect\",\"level\",\"conference\",\"organisations\",\"martin\",\"employees\",\"feel\",\"costs\",\"changed\",\"study\",\"survey\",\"brett\",\"potential\",\"macgill\",\"cannot\",\"crean\",\"lost\",\"storms\",\"round\",\"russian\",\"trip\",\"crisis\",\"nearly\",\"americans\",\"speaking\",\"ambush\",\"never\",\"significant\",\"boxing\",\"longer\",\"low\",\"tribal\",\"deadly\",\"record\",\"problem\",\"professor\",\"hayden\",\"fleeing\",\"absolutely\",\"continues\",\"fired\",\"rumsfeld\",\"claim\",\"ramallah\",\"hold\",\"anyone\",\"election\",\"construction\",\"technology\",\"doubles\",\"cities\",\"companies\",\"research\",\"whole\",\"efforts\",\"needed\",\"small\",\"moved\",\"confident\",\"land\",\"proposals\",\"sign\",\"little\",\"affected\",\"tape\",\"ruled\",\"environment\",\"everything\",\"severe\",\"led\",\"closed\",\"forecast\",\"pilot\",\"overall\",\"gillespie\",\"signed\",\"coming\",\"receive\",\"rival\",\"provide\",\"representation\",\"simon\",\"accept\",\"sides\",\"mountain\",\"receiving\",\"mean\",\"secret\",\"injuries\",\"dozens\",\"steve\",\"payment\",\"hope\",\"battle\",\"shuttle\",\"gun\",\"central\",\"bomber\",\"starting\",\"activity\",\"damaged\",\"bonn\",\"disaster\",\"problems\",\"verdict\",\"flames\",\"condition\",\"french\",\"tony\",\"resolution\",\"rest\",\"coalition\",\"richard\",\"treatment\",\"recorded\",\"grant\",\"stopped\",\"hotel\",\"insurance\",\"carry\",\"rain\",\"almost\",\"ice\",\"continued\",\"greater\",\"global\",\"share\",\"direct\",\"nation\",\"paid\",\"vaughan\",\"statistics\",\"fellow\",\"winner\",\"civil\",\"review\",\"private\",\"gas\",\"twice\",\"interlaken\",\"concern\",\"cars\",\"started\",\"red\",\"fell\",\"disappointed\",\"debate\",\"determined\",\"michael\",\"seles\",\"begin\",\"krishna\",\"didn\",\"refugees\",\"remaining\",\"tough\",\"ceremony\",\"property\",\"january\",\"qc\",\"stand\",\"operation\",\"territories\",\"above\",\"lower\",\"respond\",\"reduce\",\"resolve\",\"victims\",\"strategic\",\"asic\",\"alongside\",\"include\",\"revealed\",\"august\",\"season\",\"charge\",\"completed\",\"seeking\",\"bit\",\"park\",\"lines\",\"heritage\",\"traditional\",\"enter\",\"tuesday\",\"guard\",\"ray\",\"avoid\",\"markets\",\"visit\",\"europe\",\"winning\",\"playing\",\"self\",\"yachts\",\"met\",\"charges\",\"vice\",\"cease\",\"roads\",\"factory\",\"america\",\"itself\",\"created\",\"wake\",\"levels\",\"fall\",\"related\",\"outlook\",\"ministry\",\"lung\",\"hearing\",\"non\",\"volunteers\",\"civilians\",\"voted\",\"liquidation\",\"search\",\"provisional\",\"rescue\",\"victorian\",\"table\",\"successful\",\"track\",\"conducted\",\"heading\",\"spread\",\"accompanied\",\"delhi\",\"operating\",\"wanted\",\"expects\",\"leg\",\"ponting\",\"pulled\",\"knew\",\"heart\",\"coach\",\"confirm\",\"ball\",\"virgin\",\"press\",\"suffered\",\"illawarra\",\"approach\",\"manslaughter\",\"costello\",\"showed\",\"threatened\",\"warning\",\"helped\",\"resume\",\"japan\",\"individuals\",\"mayor\",\"giuliani\",\"friedli\",\"wind\",\"served\",\"andy\",\"range\",\"responsible\",\"unemployment\",\"mckenzie\",\"initial\",\"keep\",\"families\",\"lord\",\"incident\",\"october\",\"finance\",\"treated\",\"ian\",\"why\",\"solution\",\"apparently\",\"body\",\"club\",\"crackdown\",\"reach\",\"officer\",\"institute\",\"shaun\",\"pollock\",\"hopes\",\"structure\",\"data\",\"nice\",\"food\",\"seriously\",\"suspended\",\"attacked\",\"jason\",\"elections\",\"edge\",\"affairs\",\"nothing\",\"questions\",\"mid\",\"built\",\"negotiating\",\"peacekeepers\",\"saw\",\"issued\",\"spokeswoman\",\"assisting\",\"remains\",\"finding\",\"recovery\",\"woman\",\"gang\",\"kashmir\",\"farmers\",\"oil\",\"networks\",\"sheikh\",\"adequate\",\"doubt\",\"products\",\"secure\",\"beatle\",\"single\",\"options\",\"clearly\",\"blaze\",\"present\",\"ford\",\"cfmeu\",\"tailenders\",\"fatah\",\"scene\",\"co\",\"lording\",\"factions\",\"st\",\"raid\",\"career\",\"streets\",\"butterfly\",\"amin\",\"outcome\",\"traveland\",\"peres\",\"inappropriate\",\"austar\",\"scored\",\"champion\",\"races\",\"cave\",\"scheduled\",\"clean\",\"nearby\",\"philip\",\"shows\",\"invasion\",\"aboard\",\"coup\",\"senate\",\"doug\",\"solomon\",\"eve\",\"sarah\",\"holiday\",\"mohammad\",\"university\",\"murder\",\"whiting\",\"gorge\",\"tensions\",\"manufacturing\",\"wayne\",\"yallourn\",\"diplomatic\",\"drug\",\"promised\",\"cause\",\"natural\",\"afroz\",\"ethnic\",\"singles\",\"crews\",\"meetings\",\"toll\",\"apra\",\"administrators\",\"corporation\",\"leadership\",\"canberra\",\"exchange\",\"nuclear\",\"germany\",\"numbers\",\"attacking\",\"largest\",\"petrol\",\"customers\",\"prior\",\"internet\",\"awards\",\"extremists\",\"attempting\",\"personnel\",\"hand\",\"criminal\",\"mandate\",\"things\",\"deployed\",\"follows\",\"unrest\",\"dropped\",\"manager\",\"injury\",\"settlement\",\"roof\",\"honours\",\"appears\",\"metre\",\"boats\",\"often\",\"speech\",\"squad\",\"fair\",\"budget\",\"ready\",\"ask\",\"band\",\"proteas\",\"king\",\"grand\",\"recent\",\"happens\",\"classic\",\"suburbs\",\"resign\",\"swept\",\"collapsed\",\"true\",\"agreed\",\"batsmen\",\"presence\",\"felt\",\"billion\",\"resistance\",\"giant\",\"increased\",\"described\",\"unit\",\"create\",\"concerns\",\"protection\",\"targeted\",\"boys\",\"saudi\",\"leave\",\"unity\",\"planes\",\"halt\",\"read\",\"marine\",\"neil\",\"walk\",\"crossed\",\"fleet\",\"knowledge\",\"minute\",\"greatest\",\"extensive\",\"backed\",\"ocean\",\"assa\",\"ricky\",\"abloy\",\"light\",\"premier\",\"names\",\"explanation\",\"wall\",\"possibility\",\"real\",\"live\",\"switzerland\",\"japanese\",\"shopping\",\"reveal\",\"fierce\",\"tree\",\"elders\",\"blame\",\"tension\",\"employment\",\"detain\",\"positive\",\"income\",\"haifa\",\"jerusalem\",\"pre\",\"programs\",\"jets\",\"transport\",\"regional\",\"save\",\"hunt\",\"advance\",\"gone\",\"battling\",\"suspect\",\"representing\",\"investigating\",\"reduced\",\"acting\",\"projects\",\"investment\",\"spencer\",\"findings\",\"students\",\"nablus\",\"actions\",\"trial\",\"declaration\",\"handed\",\"custody\",\"growing\",\"system\",\"prisoners\",\"domestic\",\"education\",\"society\",\"summit\",\"assault\",\"langer\",\"matthew\",\"requested\",\"westpac\",\"doctor\",\"wing\",\"republic\",\"searching\",\"eliminated\",\"approval\",\"anz\",\"term\",\"bargaining\",\"various\",\"balls\",\"klusener\",\"boucher\",\"humanity\",\"suggested\",\"adding\",\"history\",\"normal\",\"cuts\",\"signs\",\"gunships\",\"blasted\",\"turn\",\"hare\",\"smaller\",\"guess\",\"benares\",\"ashes\",\"path\",\"terrorists\",\"blazes\",\"hijacked\",\"adam\",\"follow\",\"comment\",\"aware\",\"connection\",\"underway\",\"kieren\",\"rabbani\",\"completely\",\"tonight\",\"understanding\",\"infected\",\"masood\",\"treasurer\",\"crime\",\"gambier\",\"henderson\",\"returning\",\"results\",\"kingham\",\"question\",\"kissinger\",\"gerber\",\"stuart\",\"launceston\",\"sergeant\",\"flood\",\"committee\",\"hundred\",\"goshen\",\"handling\",\"church\",\"thing\",\"escaped\",\"injuring\",\"slightly\",\"francs\",\"hunter\",\"ahmed\",\"actor\",\"wednesday\",\"aged\",\"centrelink\",\"threatening\",\"sultan\",\"improve\",\"passed\",\"stability\",\"project\",\"dollars\",\"decades\",\"course\",\"ill\",\"faces\",\"chosen\",\"bob\",\"hamid\",\"passengers\",\"davis\",\"neville\",\"ways\",\"pace\",\"whatever\",\"headed\",\"launch\",\"replied\",\"hopefully\",\"determine\",\"archbishop\",\"unable\",\"throughout\",\"average\",\"unidentified\",\"survived\",\"approached\",\"convicted\",\"cooperation\",\"redundancy\",\"waiting\",\"request\",\"paying\",\"observers\",\"aboriginal\",\"procedures\",\"reject\",\"document\",\"improved\",\"holding\",\"mass\",\"unfortunately\",\"welcomed\",\"whereabouts\",\"appropriate\",\"lack\",\"delay\",\"trapped\",\"facilities\",\"decisions\",\"prepare\",\"medical\",\"necessary\",\"spinner\",\"examination\",\"losing\",\"channel\",\"occupation\",\"title\",\"consumers\",\"firm\",\"creditors\",\"fine\",\"vehicle\",\"staying\",\"relationship\",\"delivered\",\"begun\",\"hot\",\"coroner\",\"temperatures\",\"containment\",\"cross\",\"contested\",\"strongly\",\"experts\",\"celebrations\",\"focus\",\"named\",\"sometimes\",\"marines\",\"player\",\"jalalabad\",\"games\",\"breaking\",\"contained\",\"counts\",\"stay\",\"allowed\",\"temporary\",\"assembly\",\"draft\",\"understood\",\"toowoomba\",\"voice\",\"twenty\",\"strachan\",\"harris\",\"discussions\",\"hopman\",\"crashed\",\"farm\",\"violent\",\"communities\",\"kilometre\",\"doctors\",\"hoping\",\"ban\",\"colin\",\"effective\",\"success\",\"offered\",\"positions\",\"abu\",\"worked\",\"documents\",\"tell\",\"phillips\",\"retired\",\"choosing\",\"responding\",\"allegedly\",\"indonesian\",\"detail\",\"free\",\"bringing\",\"hiv\",\"proposal\",\"doesn\",\"mining\",\"embassy\",\"heights\",\"mt\",\"trading\",\"room\",\"fund\",\"impact\",\"male\",\"mohammed\",\"interests\",\"effort\",\"antarctic\",\"previous\",\"target\",\"words\",\"publicly\",\"walked\",\"credit\",\"provided\",\"investigate\",\"telephone\",\"eventually\",\"leaving\",\"banking\",\"interview\",\"headquarters\",\"clashes\",\"doing\",\"fear\",\"predicted\",\"picked\",\"happy\",\"visa\",\"tie\",\"putting\",\"escalating\",\"hoped\",\"landed\",\"sharing\",\"mind\",\"skipper\",\"gary\",\"soft\",\"became\",\"sending\",\"shoes\",\"paris\",\"required\",\"seemed\",\"cameron\",\"ability\",\"locked\",\"travelled\",\"finally\",\"separate\",\"owen\"],\"x\":[55.62959671020508,58.25174331665039,57.287445068359375,57.23680114746094,56.940879821777344,49.072601318359375,56.6842155456543,56.5872917175293,57.703983306884766,52.76639938354492,54.781131744384766,57.70323944091797,56.77732849121094,53.83364486694336,56.58464813232422,51.29952621459961,50.856178283691406,58.08560562133789,58.616172790527344,55.55207061767578,57.93626022338867,54.87437057495117,58.30657958984375,58.12884521484375,54.19414138793945,49.07210922241211,57.447845458984375,55.76576232910156,51.925724029541016,56.973724365234375,56.482994079589844,54.33002471923828,58.73465347290039,58.11374282836914,55.20647048950195,49.614662170410156,55.65520477294922,53.19033432006836,50.181640625,52.750770568847656,54.889442443847656,54.92460250854492,47.44418716430664,55.14533996582031,48.334510803222656,57.4003791809082,51.64601135253906,52.04490661621094,52.45989227294922,55.53887176513672,52.488380432128906,46.480194091796875,52.278018951416016,52.84587097167969,51.67063903808594,51.83039474487305,51.092018127441406,56.00668716430664,52.56639862060547,54.64967346191406,49.761016845703125,50.17380905151367,52.69435119628906,50.645668029785156,51.539005279541016,56.08518600463867,48.33510208129883,51.871158599853516,45.3217658996582,49.042274475097656,44.5504264831543,45.137794494628906,48.98528289794922,44.977867126464844,49.24569320678711,46.28532028198242,49.774295806884766,43.77195739746094,46.997989654541016,50.71452331542969,45.205753326416016,45.92426300048828,43.60847091674805,48.6707878112793,43.232582092285156,47.45182800292969,43.816532135009766,45.612483978271484,49.8828125,45.54007339477539,49.54442596435547,43.85606384277344,45.64667892456055,44.26789855957031,-1.1209492683410645,44.931156158447266,43.50965118408203,44.78970718383789,44.32978439331055,-0.8195958733558655,-1.2143555879592896,44.579952239990234,45.96660232543945,-1.9100197553634644,46.85956573486328,-0.8069230318069458,-2.9415199756622314,-1.2498385906219482,-2.0921292304992676,42.88644790649414,44.18465042114258,-0.8294044733047485,-2.4254937171936035,-3.185133695602417,-1.6112090349197388,-2.8297178745269775,-2.368699789047241,44.35597229003906,-2.6124231815338135,-2.327694892883301,-3.928333044052124,-3.1175405979156494,-2.5814127922058105,-1.7755143642425537,44.739234924316406,-2.1652767658233643,-2.7121477127075195,-2.684575080871582,-3.238539934158325,-2.507265090942383,-3.0327541828155518,-1.4790669679641724,-0.7237892746925354,-1.1563968658447266,-2.6198606491088867,-1.588295340538025,-2.41302227973938,-1.8258376121520996,-2.3341331481933594,0.001788176828995347,-1.6757028102874756,-3.2748939990997314,-2.493225336074829,-0.9801574945449829,-2.002220630645752,-1.4063514471054077,-2.7667860984802246,-1.5274983644485474,-2.315856456756592,-2.4085960388183594,-2.674729824066162,-1.0105609893798828,-3.0684010982513428,-1.0146582126617432,-1.8946055173873901,-1.9585070610046387,-2.517274856567383,-2.9147047996520996,-1.76229727268219,-2.1109883785247803,-0.5530831813812256,-2.656510591506958,-2.5414676666259766,-2.6041276454925537,-2.6034300327301025,43.665714263916016,0.4846896529197693,2.282595634460449,-1.7911313772201538,-3.213859796524048,-0.9108051061630249,-2.7427737712860107,-2.242649793624878,3.1579601764678955,-2.7273998260498047,-1.5103628635406494,15.064780235290527,-2.4526901245117188,-2.8713598251342773,-2.2349319458007812,-1.2477976083755493,-2.683516502380371,-2.0789177417755127,-0.07839041203260422,-2.5567522048950195,-2.5885097980499268,-2.241626501083374,-2.5550599098205566,13.038472175598145,-1.898974061012268,-2.800168752670288,-1.9348371028900146,-1.7882661819458008,-2.068464756011963,-0.38067352771759033,0.7627512812614441,5.726933002471924,-2.059047222137451,5.41478967666626,4.222344398498535,-2.7982120513916016,1.9962525367736816,-2.668811321258545,-1.7973449230194092,-2.202721118927002,14.781126022338867,9.040486335754395,11.995142936706543,-1.9307165145874023,20.364662170410156,-1.5972422361373901,1.5767228603363037,3.780710220336914,1.7374285459518433,-2.4644455909729004,-2.5954935550689697,-1.5812891721725464,5.181344032287598,5.253445148468018,-1.6153351068496704,-1.2180345058441162,-2.51794695854187,2.206063985824585,5.731832027435303,3.1404106616973877,8.031319618225098,0.8082072734832764,-1.3295308351516724,3.5396320819854736,12.471369743347168,15.572917938232422,1.7825706005096436,-0.7100955843925476,18.07757568359375,2.337677240371704,15.742916107177734,3.890263795852661,-1.5356013774871826,1.8733580112457275,16.808015823364258,13.551128387451172,8.58609390258789,8.649884223937988,13.395962715148926,11.630277633666992,6.529665470123291,0.9065268635749817,3.5487589836120605,3.042285680770874,4.828672409057617,-1.6954689025878906,14.807618141174316,3.118734836578369,29.822193145751953,26.235443115234375,2.8430416584014893,7.041579723358154,8.445109367370605,7.710870742797852,29.898242950439453,12.901951789855957,9.247934341430664,9.187820434570312,1.8023629188537598,5.822205066680908,-1.0129863023757935,20.8071346282959,28.93654441833496,31.208314895629883,25.454477310180664,26.008455276489258,-0.628958523273468,12.632048606872559,5.811607360839844,1.5458431243896484,18.872215270996094,7.247864246368408,26.85730743408203,30.04733657836914,12.114266395568848,9.66202163696289,2.63598370552063,5.976791858673096,26.57123565673828,9.332062721252441,8.698257446289062,14.581055641174316,26.109277725219727,11.334860801696777,4.980712413787842,1.2084754705429077,21.1138858795166,13.032801628112793,4.6378984451293945,2.9371116161346436,30.829193115234375,12.999438285827637,12.587446212768555,30.981006622314453,20.105003356933594,4.871184825897217,6.418717861175537,1.3780826330184937,19.23470115661621,29.975719451904297,17.648000717163086,15.972381591796875,27.6395263671875,13.360753059387207,20.998228073120117,-0.007735404185950756,2.1332590579986572,20.496349334716797,21.084333419799805,27.256502151489258,15.656559944152832,30.446426391601562,12.450937271118164,30.853275299072266,18.991073608398438,16.096731185913086,19.40508460998535,20.21185874938965,29.49405860900879,27.784690856933594,18.003311157226562,29.0501708984375,-0.48527416586875916,28.894683837890625,30.165813446044922,17.272174835205078,31.042741775512695,20.029382705688477,29.611675262451172,27.237743377685547,30.602689743041992,30.714982986450195,23.331331253051758,31.264148712158203,16.669214248657227,26.580759048461914,30.32659149169922,8.231629371643066,3.1717941761016846,28.979276657104492,7.143673419952393,30.227853775024414,25.907115936279297,17.121740341186523,30.27646827697754,23.96994972229004,27.220354080200195,16.904327392578125,13.964105606079102,28.46312713623047,19.34065818786621,31.373991012573242,30.718761444091797,28.8741397857666,29.460268020629883,21.81553077697754,29.034687042236328,31.94339370727539,28.115047454833984,31.414587020874023,20.64720344543457,31.880542755126953,13.721745491027832,28.526845932006836,19.358797073364258,30.480270385742188,28.983768463134766,17.217748641967773,9.078679084777832,17.499916076660156,30.92426300048828,29.811031341552734,28.076093673706055,25.504240036010742,32.018856048583984,30.2730655670166,29.582069396972656,30.369253158569336,30.960599899291992,18.950523376464844,31.37864875793457,26.99855613708496,19.145631790161133,11.916115760803223,27.70595359802246,28.305150985717773,17.939407348632812,29.475244522094727,16.056238174438477,24.946805953979492,30.361438751220703,30.40264129638672,27.48917007446289,19.964445114135742,16.728078842163086,19.688337326049805,31.406570434570312,31.178022384643555,17.337066650390625,15.7081298828125,25.083946228027344,6.475296974182129,22.265710830688477,26.39765739440918,23.816871643066406,14.252201080322266,29.87782859802246,25.827136993408203,31.383676528930664,20.438343048095703,29.422203063964844,27.686017990112305,14.323344230651855,25.08845329284668,26.491296768188477,30.57578468322754,20.473739624023438,13.922996520996094,31.108678817749023,17.06090545654297,29.67152214050293,29.659645080566406,19.348243713378906,21.766265869140625,25.535621643066406,25.696123123168945,26.785009384155273,27.007261276245117,26.98248291015625,30.875320434570312,19.939653396606445,14.515880584716797,24.964584350585938,27.35881996154785,28.342397689819336,29.772571563720703,31.739601135253906,28.945375442504883,13.559073448181152,30.383853912353516,25.44859504699707,15.320223808288574,30.865570068359375,28.0589542388916,9.544511795043945,12.569992065429688,22.827791213989258,21.065114974975586,30.77783203125,31.160860061645508,23.76905059814453,17.695796966552734,25.92347526550293,11.829035758972168,28.777341842651367,27.528772354125977,18.81589126586914,17.856534957885742,30.5435848236084,29.340587615966797,31.123233795166016,13.860021591186523,20.515125274658203,25.88664436340332,18.2695369720459,28.15155601501465,29.647768020629883,13.660282135009766,13.621223449707031,26.837623596191406,29.556310653686523,30.757238388061523,27.81635284423828,30.436155319213867,29.262887954711914,30.821603775024414,27.211788177490234,13.7709321975708,25.22516441345215,28.463661193847656,17.532695770263672,30.743122100830078,17.159976959228516,27.71466636657715,29.03765106201172,31.34149742126465,19.312034606933594,20.582643508911133,13.324617385864258,27.954364776611328,12.78392219543457,17.26319122314453,19.69967269897461,12.960994720458984,16.586034774780273,30.366226196289062,27.93490219116211,23.259252548217773,28.356348037719727,21.93136215209961,31.423397064208984,20.832103729248047,31.528249740600586,28.71299171447754,14.897936820983887,18.44479751586914,22.497093200683594,31.416677474975586,27.332590103149414,23.168794631958008,16.295791625976562,-3.9588897228240967,25.027023315429688,18.537607192993164,15.16908073425293,18.1568660736084,29.933273315429688,17.932273864746094,24.00623321533203,29.314617156982422,13.800902366638184,26.191186904907227,12.38934326171875,12.721061706542969,26.347179412841797,16.99265480041504,14.486223220825195,30.26120376586914,30.300926208496094,28.663837432861328,19.1336727142334,28.6845760345459,30.452817916870117,31.600996017456055,21.83108901977539,30.06262969970703,15.376973152160645,15.88620376586914,26.640106201171875,20.476863861083984,17.066343307495117,13.254066467285156,13.81985092163086,30.917842864990234,28.073638916015625,15.124059677124023,27.892934799194336,12.525727272033691,25.62285804748535,28.124189376831055,11.622467994689941,15.993433952331543,20.31975555419922,18.04582977294922,30.589881896972656,15.984814643859863,25.723413467407227,14.998213768005371,14.14594841003418,11.774127960205078,14.440616607666016,21.314315795898438,31.95587730407715,16.334352493286133,17.687484741210938,19.09137535095215,12.711405754089355,12.254070281982422,19.241260528564453,14.728588104248047,16.567211151123047,28.747482299804688,17.88585090637207,24.70015525817871,16.143306732177734,29.294218063354492,14.390213012695312,11.943886756896973,18.953519821166992,29.08246612548828,9.891669273376465,21.306793212890625,13.435516357421875,15.548649787902832,15.71707820892334,20.56474494934082,17.255294799804688,20.0662784576416,14.303845405578613,25.787572860717773,13.05938720703125,13.055997848510742,20.044864654541016,16.27194595336914,12.835847854614258,14.934893608093262,13.897072792053223,12.077815055847168,12.500072479248047,16.85354995727539,22.088659286499023,18.148496627807617,15.927809715270996,11.860359191894531,11.791975021362305,28.857391357421875,12.554155349731445,13.978464126586914,15.953495025634766,21.801353454589844,31.54692268371582,20.782772064208984,20.43389892578125,19.137582778930664,-5.3364105224609375,15.068244934082031,13.57296085357666,29.402938842773438,12.421014785766602,19.043893814086914,22.600622177124023,20.55112075805664,30.499256134033203,13.026572227478027,20.32019805908203,24.985132217407227,13.873624801635742,25.0418701171875,18.807331085205078,31.261886596679688,14.904316902160645,12.50338077545166,14.39312744140625,16.23789405822754,14.437299728393555,26.69397735595703,17.05126953125,12.198063850402832,17.52529525756836,12.04548168182373,18.541593551635742,17.902645111083984,12.879308700561523,16.87038230895996,16.8077449798584,4.197262287139893,18.057708740234375,16.363649368286133,14.783885955810547,30.602231979370117,15.35781478881836,23.567691802978516,15.446786880493164,15.984638214111328,14.94379711151123,16.232606887817383,11.98465347290039,11.166680335998535,19.141216278076172,11.660194396972656,16.88774871826172,14.159510612487793,24.969493865966797,14.064404487609863,15.04787540435791,13.552556991577148,13.539947509765625,12.722043991088867,11.395232200622559,12.9241361618042,5.691736698150635,12.934807777404785,17.376646041870117,12.639498710632324,13.200181007385254,18.559627532958984,12.49632453918457,11.308845520019531,-12.818475723266602,13.870956420898438,5.048379421234131,15.320544242858887,14.630876541137695,13.344326972961426,17.660385131835938,18.67965316772461,17.788721084594727,14.012785911560059,-9.142021179199219,16.931766510009766,17.546398162841797,16.129074096679688,14.292671203613281,19.560096740722656,18.186378479003906,16.81202507019043,11.494170188903809,19.767414093017578,12.981748580932617,17.143896102905273,19.24823760986328,24.406278610229492,8.741292953491211,15.290863037109375,16.37706756591797,11.508367538452148,17.8150577545166,-32.33406066894531,13.404064178466797,13.235380172729492,26.932104110717773,4.715134620666504,17.976797103881836,-0.4063328504562378,7.356654167175293,14.31165599822998,16.42043685913086,11.25585651397705,13.342555046081543,16.585508346557617,-22.474428176879883,19.433366775512695,17.09172821044922,15.038843154907227,11.015339851379395,18.91008758544922,13.539173126220703,18.1174259185791,14.57480239868164,7.481387138366699,17.79888916015625,19.58182144165039,-2.6101748943328857,17.275802612304688,14.07254409790039,18.287118911743164,12.028990745544434,11.350973129272461,17.388612747192383,14.792717933654785,-22.757442474365234,19.862401962280273,15.980634689331055,16.14280891418457,21.659751892089844,-10.871376991271973,17.496158599853516,-0.7969439029693604,16.978151321411133,14.64913272857666,13.767081260681152,16.69391632080078,1.26152765750885,14.156943321228027,11.18607234954834,18.668609619140625,-23.475343704223633,15.44373893737793,15.772281646728516,19.252769470214844,8.984917640686035,-17.468809127807617,13.643280982971191,15.25366497039795,-28.580352783203125,15.729134559631348,13.05786418914795,-0.3177850544452667,13.763980865478516,22.76610565185547,10.1514892578125,16.08761978149414,17.892061233520508,-16.704456329345703,0.7340424656867981,16.26519775390625,14.327207565307617,6.259427547454834,18.67825698852539,11.522992134094238,-8.147098541259766,11.722865104675293,11.866677284240723,15.256355285644531,16.324369430541992,16.8829345703125,-11.903935432434082,13.065629005432129,15.60111141204834,3.6068718433380127,-3.049281358718872,-28.104167938232422,18.13735008239746,25.73219108581543,14.149129867553711,14.6864652633667,18.186166763305664,13.817790985107422,14.902436256408691,-0.5903499722480774,-4.421199321746826,15.896121978759766,5.219436168670654,15.5505952835083,18.674854278564453,12.965517044067383,15.821354866027832,-1.5398554801940918,-27.167560577392578,-30.47045135498047,16.722755432128906,15.767909049987793,1.3950406312942505,17.786855697631836,7.478358268737793,18.617733001708984,8.8328857421875,10.616204261779785,-23.086788177490234,11.610026359558105,-15.537113189697266,18.888671875,8.248224258422852,-9.49953556060791,-4.250049591064453,15.171903610229492,16.377885818481445,16.7831974029541,7.955918788909912,2.8314239978790283,17.360307693481445,7.808535575866699,15.676630973815918,19.378786087036133,-24.209400177001953,11.584677696228027,4.569023609161377,19.738924026489258,-34.38258361816406,17.57550621032715,-17.90455436706543,12.886530876159668,12.799042701721191,15.072419166564941,16.09404945373535,17.44202995300293,16.991411209106445,-0.1221981793642044,18.34247398376465,6.955749034881592,13.288137435913086,17.290203094482422,19.77129554748535,12.34115219116211,1.3311537504196167,8.723352432250977,-4.1075968742370605,-33.13786697387695,7.233434200286865,11.93050479888916,16.097362518310547,18.284255981445312,27.039859771728516,4.600111484527588,-1.9574923515319824,13.822853088378906,19.031158447265625,-0.8932023048400879,17.23678207397461,4.894928455352783,13.353523254394531,18.828784942626953,19.35894012451172,-16.101337432861328,12.131532669067383,-5.748185634613037,-22.402626037597656,12.836423873901367,18.251426696777344,16.995262145996094,16.33694076538086,16.197973251342773,17.677268981933594,12.992108345031738,17.068485260009766,-33.46160125732422,16.965118408203125,-22.90386962890625,12.41738224029541,-29.368791580200195,11.540061950683594,5.031525611877441,17.45023536682129,11.525507926940918,10.586817741394043,9.13771915435791,3.671236753463745,18.847780227661133,19.407981872558594,-30.311080932617188,-18.50452423095703,5.968214988708496,9.113478660583496,16.78700828552246,-3.1586720943450928,11.112850189208984,-15.684852600097656,16.314714431762695,-31.863561630249023,-6.64375638961792,16.322628021240234,17.66949462890625,0.7277677655220032,15.489200592041016,15.025155067443848,18.082111358642578,9.602293014526367,-7.804964065551758,10.930183410644531,5.441766262054443,-5.267032146453857,16.798782348632812,14.315098762512207,-15.576130867004395,-3.4748153686523438,20.594491958618164,2.2133119106292725,-9.240655899047852,0.4969451129436493,-5.489630699157715,16.097261428833008,-29.299659729003906,14.520236015319824,13.788626670837402,-13.063963890075684,6.780779838562012,14.431600570678711,12.826601028442383,4.080182075500488,-27.381437301635742,10.151558876037598,16.365846633911133,-7.591949462890625,17.994508743286133,-11.629199981689453,16.589515686035156,18.20642852783203,1.5294276475906372,5.435586929321289,11.269118309020996,16.327320098876953,-29.123281478881836,17.87425422668457,10.689189910888672,-10.01357650756836,19.092817306518555,13.921160697937012,13.510831832885742,12.851699829101562,14.884102821350098,16.31803321838379,-12.178682327270508,17.106830596923828,1.6544088125228882,-8.923954963684082,-6.829300880432129,-14.818559646606445,5.9046502113342285,-30.817333221435547,14.450815200805664,13.930192947387695,-17.25067710876465,15.989990234375,-0.17671874165534973,-1.6129298210144043,-15.557591438293457,-16.108137130737305,7.055041790008545,-24.323150634765625,7.523252964019775,-3.686375617980957,17.311573028564453,-19.728410720825195,-25.90094757080078,-17.813627243041992,-15.06546401977539,-2.4010818004608154,-28.613056182861328,-12.798819541931152,-23.620983123779297,-25.16852378845215,-30.286588668823242,16.47834587097168,-15.368165016174316,3.4303719997406006,-25.013036727905273,-8.943653106689453,-10.111652374267578,-31.889822006225586,-11.207876205444336,-18.809852600097656,-27.434558868408203,-31.257457733154297,-32.60662078857422,-31.44466209411621,-21.1835880279541,-22.145477294921875,-13.660806655883789,9.677435874938965,4.9618239402771,-29.7550048828125,-23.437088012695312,6.479732990264893,16.214492797851562,-34.878028869628906,-30.71358871459961,9.181174278259277,-17.3967227935791,13.313405990600586,13.465574264526367,-21.88306999206543,-28.951658248901367,-20.473434448242188,11.684379577636719,-11.700606346130371,3.544398784637451,14.745113372802734,-5.737241268157959,-33.409366607666016,-8.328228950500488,-7.137378692626953,8.44044017791748,-4.380893707275391,-33.417388916015625,-31.408828735351562,18.49468231201172,-35.34012222290039,-16.48025894165039,-20.483232498168945,-0.44485145807266235,-30.989673614501953,-1.8362617492675781,18.36737060546875,-14.278438568115234,19.767194747924805,-30.694326400756836,-32.90785598754883,18.425947189331055,-18.38192367553711,-19.973926544189453,10.097620964050293,-16.9296817779541,3.6128993034362793,-21.499862670898438,-17.7208194732666,-32.588348388671875,-30.02313995361328,-33.94881820678711,-17.707847595214844,8.33209228515625,-21.645139694213867,-4.570428848266602,-2.887697458267212,16.356531143188477,-24.595211029052734,-20.001893997192383,-2.645878791809082,7.36796236038208,16.518789291381836,-7.907484531402588,11.863319396972656,-11.07480239868164,-2.4167428016662598,-18.684009552001953,-23.966447830200195,-28.764122009277344,13.404261589050293,14.676966667175293,18.371963500976562,16.909114837646484,-24.025104522705078,-13.61558723449707,-21.3689022064209,9.859331130981445,12.67223072052002,8.84974479675293,-12.792494773864746,-32.4720344543457,-14.175568580627441,-33.23604202270508,-29.907848358154297,-5.788999080657959,-28.92559242248535,0.6586169004440308,-1.6085580587387085,-31.70748519897461,10.414246559143066,6.190606594085693,-20.332792282104492,-32.08299255371094,-29.278099060058594,-29.88584327697754,-6.9524712562561035,-28.28982925415039,16.70951271057129,-34.30622863769531,-31.69029426574707,-28.444793701171875,-0.6884005665779114,-1.5447019338607788,-21.27729606628418,-24.87506103515625,-5.5493268966674805,-4.573999881744385,3.4539055824279785,-18.108606338500977,-18.951271057128906,-22.508560180664062,-17.85698890686035,-7.076883792877197,14.468528747558594,-31.90167999267578,-33.920413970947266,-11.832983016967773,-33.35187911987305,-9.987451553344727,-10.6294584274292,-32.107688903808594,-34.61046600341797,-31.50000762939453,-12.835225105285645,-28.81119155883789,14.939024925231934,-28.027402877807617,-10.9857759475708,-28.07142448425293,-20.23004913330078,-25.111434936523438,-13.80938720703125,-9.838163375854492,-32.668861389160156,-27.59136199951172,-28.699832916259766,-2.135024309158325,-8.61827278137207,-33.10991287231445,-5.111069202423096,-29.303298950195312,1.0649728775024414,-29.7393856048584,-4.620283603668213,2.080828905105591,2.727023124694824,-22.964649200439453,-26.136098861694336,-24.412303924560547,-32.129615783691406,-11.447710990905762,13.450554847717285,-20.82510757446289,12.289604187011719,-11.362724304199219,15.210970878601074,-17.31284523010254,17.514307022094727,-27.981624603271484,-12.494614601135254,-33.356468200683594,5.863317966461182,-7.637777805328369,-29.622135162353516,0.8905207514762878,4.719330787658691,-28.57453155517578,-26.693586349487305,-31.55157470703125,-7.724585056304932,-11.813648223876953,13.482329368591309,-4.6240057945251465,-34.81382369995117,-33.11952209472656,-22.169763565063477,8.144613265991211,-23.15900230407715,6.432703971862793,-21.725236892700195,-19.474254608154297,-24.871305465698242,-32.46451187133789,-27.102428436279297,-1.941635251045227,-25.41986083984375,-4.9713616371154785,-9.025236129760742,-23.627758026123047,-12.9104642868042,-35.260093688964844,-7.955969333648682,-14.532102584838867,-18.996719360351562,-33.67641067504883,-28.71811866760254,-22.051136016845703,-31.5103816986084,13.870174407958984,-4.216862678527832,-27.160749435424805,18.46084213256836,15.896502494812012,-29.621109008789062,-29.246145248413086,-30.891592025756836,0.02673014998435974,-4.586559295654297,-19.893718719482422,-25.966354370117188,-35.444820404052734,-23.086217880249023,-30.557973861694336,-8.975478172302246,-29.91909408569336,-0.2536715269088745,-24.123483657836914,-21.959224700927734,-6.50009822845459,18.248197555541992,-11.66001033782959,18.228281021118164,18.25043296813965,8.076248168945312,-16.23440933227539,-30.689504623413086,-29.342172622680664,-29.326244354248047,-30.24884796142578,-25.737730026245117,-29.961523056030273,16.047664642333984,-20.84590721130371,-9.222332954406738,-15.421037673950195,-30.053455352783203,-34.27580642700195,15.638002395629883,-34.8878059387207,-6.772500514984131,-31.537965774536133,-31.55205726623535,-31.041906356811523,5.616063594818115,1.5373109579086304,18.469985961914062,-30.60041618347168,-14.170853614807129,-2.9365947246551514,-19.7757625579834,-30.925765991210938,-26.56563949584961,-26.811494827270508,-23.52936363220215,-22.27605628967285,-23.28580665588379,-31.40090560913086,-29.17062759399414,-31.146883010864258,-25.999141693115234,-33.703369140625,-26.312288284301758,-32.318504333496094,-31.85651206970215,-13.175342559814453,-29.71141815185547,19.110431671142578,-34.25397491455078,-23.83818817138672,-29.942962646484375,-29.896324157714844,-29.917217254638672,-31.541730880737305,-29.978933334350586,-24.85822868347168,-7.4312639236450195,-29.459699630737305,-14.106328010559082,-21.31732749938965,-32.70002365112305,-29.67205047607422,-32.688106536865234,-30.792322158813477,-14.484172821044922,-19.648155212402344,-19.908302307128906,2.2558014392852783,-34.96668243408203,-15.634814262390137,-32.78310012817383,-25.17418098449707,-23.856182098388672,-31.42673683166504,-3.3136987686157227,-30.476003646850586,-28.841285705566406,-35.1773681640625,16.381486892700195,-27.154211044311523,-30.462345123291016,-3.084444284439087,-31.47987174987793,-21.0040225982666,-31.224559783935547,-19.861194610595703,-27.709320068359375,-30.159732818603516,-35.47177505493164,-17.122888565063477,-10.771171569824219,3.3136463165283203,-21.81528663635254,0.6783732175827026,-6.688207626342773,-26.624515533447266,-11.863462448120117,-9.304072380065918,-23.552207946777344,-31.624502182006836,-34.51225662231445,-34.90410232543945,-32.594886779785156,-32.34375762939453,-28.11399269104004,-20.63911247253418,-31.717939376831055,-19.197908401489258,-33.428619384765625,-33.18241500854492,-22.6614990234375,-31.510269165039062,-29.379117965698242,-31.824512481689453,-35.19915771484375,-29.294710159301758,-23.64187240600586,5.371075630187988,-30.046245574951172,-24.67861557006836,-34.681304931640625,-29.213382720947266,-28.08407211303711,-34.16594314575195,-35.03022384643555,-32.60700988769531,-29.014142990112305,-24.330167770385742,-31.46601104736328,-18.50746726989746,17.38531494140625,-20.138303756713867,-30.65497589111328,-31.937700271606445,-18.997394561767578,-17.91199493408203,-28.009544372558594,-24.48651695251465,-32.987735748291016,-26.871347427368164,-18.902414321899414,-33.393253326416016,-19.687368392944336,-28.42325782775879,-27.148481369018555,-33.62034225463867,-34.895137786865234,-29.731836318969727,-27.122257232666016,-31.015613555908203,-24.357370376586914,-26.067001342773438,-19.927831649780273,-26.90550994873047,-30.541183471679688,-31.839693069458008,-16.933799743652344,-20.77150535583496,-31.118602752685547,-30.156530380249023,-24.035242080688477,-22.524446487426758,-25.9499568939209,17.73192596435547,-31.886354446411133,-24.874305725097656,-1.3429656028747559,-30.300209045410156,-28.567550659179688,-33.41278076171875,-32.61056137084961,-26.32697296142578,-34.67296600341797,-13.860450744628906,-27.605493545532227,-27.210296630859375,-28.580638885498047,-18.415828704833984,-23.404666900634766,9.208093643188477,-17.68037223815918,-29.160831451416016,-23.653867721557617,-31.676509857177734,-28.942806243896484,-29.429676055908203,-16.780698776245117,-30.552156448364258,-8.889928817749023,13.74736213684082,-13.084389686584473,10.652175903320312,-17.376686096191406,-28.712997436523438,-27.72955322265625,-30.884971618652344,-18.926742553710938,-28.602357864379883,-34.30825424194336,-26.527921676635742,-20.71649169921875,-33.10747528076172,-33.1890983581543,-33.273529052734375,-27.862314224243164,-13.221029281616211,-32.607177734375,-29.760622024536133,-34.457801818847656,14.218025207519531,-30.57169532775879,-26.781028747558594,-27.62183380126953,-24.032310485839844,-27.10990333557129,-5.714084148406982,-23.93501091003418,-13.248218536376953,-31.562559127807617,-23.288040161132812,-25.897987365722656,-34.020938873291016,-29.849016189575195,-33.54602813720703,-16.176786422729492,-16.043209075927734,-27.342365264892578,-29.342788696289062,-32.88066864013672,-32.88155746459961,-27.83652687072754,-31.7696533203125,-28.227949142456055,-29.858858108520508,-13.626096725463867,-33.257564544677734,-32.16923522949219,-30.923011779785156,-33.13256072998047,-26.81622314453125,-27.067941665649414,-32.91187286376953,-30.330339431762695,-33.218406677246094,-36.409828186035156,-14.396818161010742,-32.90968704223633,-35.702392578125,-20.625720977783203,-25.524383544921875,-27.05634307861328,-28.881324768066406,-31.424793243408203,-15.150959014892578,-25.516389846801758,-28.791244506835938,-31.310012817382812,-34.8974609375,-34.101043701171875,-31.901546478271484,-31.85472297668457,-32.280086517333984,-31.86369514465332,-33.7266960144043,-17.37847137451172,-10.855664253234863,-32.6656379699707,-31.46525001525879,-33.7158203125,-30.77324104309082,-30.85201072692871,-28.04459571838379,-29.141578674316406,-27.825876235961914,-21.154680252075195,-31.43581771850586,-34.67069625854492,-32.71818161010742,-32.375614166259766,-30.15286636352539,-25.991527557373047,-18.67820930480957,-26.145526885986328,-29.691997528076172,-26.869762420654297,-15.79371166229248,-28.498693466186523,-27.791545867919922,-31.444461822509766,-29.58312225341797,-22.407073974609375,-33.41269302368164,-27.133243560791016,-31.448331832885742,-32.29397201538086,-35.626094818115234,-20.06760025024414,-29.403770446777344,-32.50022506713867,-31.28073501586914,-16.732458114624023,-25.872896194458008,-27.858821868896484,-30.264118194580078,-4.385774612426758,-26.455883026123047,-28.63071632385254,-34.87605667114258,-0.3274634778499603,-32.60778045654297,-30.236583709716797,-31.5858154296875,-33.29302978515625,-28.37165069580078,-16.473133087158203,-31.792095184326172,-30.4201717376709,-24.60772132873535,-26.666460037231445,-30.921476364135742,-30.981754302978516,3.3406410217285156,-35.33982849121094,-23.682344436645508,-28.94797706604004,-26.045969009399414,-31.884300231933594,-29.662811279296875,-32.664146423339844,-32.05192565917969,-26.349075317382812,-30.70130729675293,-30.401222229003906,-34.249839782714844,-30.514461517333984,-28.131275177001953,-27.955575942993164,-33.45735549926758,2.739006996154785,-14.074922561645508,-32.94305419921875,-26.151033401489258,-32.217411041259766,-6.099054336547852,18.29738998413086,-32.65118408203125,-21.834854125976562,-31.83256721496582,-25.58539390563965,-34.28262710571289,-30.390588760375977,-31.489696502685547,-28.994216918945312,-31.055191040039062,-34.408538818359375,-22.022676467895508,-32.07353210449219,-22.310171127319336,-25.80156898498535,-32.945640563964844,-34.58321762084961,-26.79009246826172,-29.67930030822754,-29.339601516723633,-33.163963317871094,-36.14051055908203,-33.81028366088867,-15.705370903015137,-32.649208068847656,-29.070531845092773,-30.997541427612305,-19.904993057250977,-32.887210845947266,-29.747833251953125,-27.39400863647461,-32.262962341308594,-30.025157928466797,-32.048797607421875,-31.51446533203125,-35.247711181640625,-30.66423988342285,-26.30963897705078,-30.32463836669922,-34.77616500854492,-30.13810920715332,-31.244884490966797,-11.960482597351074,-30.479938507080078,-30.571308135986328,-30.842891693115234,-27.014379501342773,-30.596904754638672,-32.17981719970703,-28.4558162689209,-28.35002899169922,-31.732938766479492,-35.33066177368164,-32.077178955078125,-31.661588668823242,-26.795167922973633,-27.681766510009766,-28.76331901550293,-26.23796844482422,-32.00313949584961,-25.14043426513672,-20.14621353149414,-30.86736297607422,-28.639253616333008,-30.85781478881836,-30.347393035888672,-26.869285583496094,-35.05887985229492,-33.072967529296875,-29.829669952392578,-35.19538116455078,-31.442678451538086,-31.189056396484375,-33.36214065551758,-28.9594669342041,-32.730621337890625,-20.97235679626465,-32.359066009521484,-26.08793067932129,-21.299108505249023,-24.128231048583984,-33.80507278442383,-33.531219482421875,-28.955734252929688,-33.345458984375,-31.472305297851562,-24.771621704101562,-22.534326553344727,-28.161928176879883,-27.113147735595703,-31.054391860961914,-29.58904457092285,-28.14917755126953,-33.36284255981445,-30.86042594909668,-29.387990951538086,-26.680505752563477,-30.772579193115234,-28.287071228027344,-24.995742797851562,-34.72348403930664,-34.179264068603516,-35.72634506225586,-26.361188888549805,-32.82211685180664,-29.120649337768555,-28.655540466308594,-33.05246353149414,-3.255335807800293,-27.318178176879883,-21.67326545715332,-32.756919860839844,-30.87982177734375,-31.365312576293945,-33.821083068847656,-32.55697250366211,-34.31511306762695,-36.22047424316406,-6.633201599121094,-29.881528854370117,-31.524446487426758,-24.66391372680664,-25.469148635864258,-31.302978515625,-27.07049560546875,-25.886701583862305,-35.17860794067383,-33.29360580444336,-27.598419189453125,-26.070531845092773,-17.61162757873535,-30.633323669433594,-30.11627197265625,-33.833614349365234,-29.348861694335938,-24.56534767150879,-30.32691192626953,-27.202611923217773,-27.265287399291992,-29.35553550720215,-30.342147827148438,-32.39470291137695,-33.15397262573242,-27.29109001159668,-32.25031280517578,-29.77702522277832,-27.855398178100586,-33.5924186706543,-13.887687683105469,-32.91410827636719,-26.366268157958984,-28.511476516723633,-35.33031463623047,-29.205129623413086,-26.425445556640625,-27.44217300415039,-25.04501724243164,-35.23867416381836,-26.99949836730957,-27.415943145751953,-32.29316711425781,-25.568153381347656,-23.1085205078125,-35.516639709472656,-31.76518440246582,-31.605737686157227,-26.014209747314453,-29.6401309967041,-12.114228248596191,-26.521177291870117,-30.85478973388672,-33.48488235473633,-30.958486557006836,-32.699974060058594,-11.064621925354004],\"y\":[8.574629783630371,10.272871971130371,9.500164985656738,10.092294692993164,9.355950355529785,4.637571334838867,9.476975440979004,9.500449180603027,10.445895195007324,7.08310604095459,8.42678451538086,10.45269775390625,9.190958976745605,7.4949140548706055,9.819746971130371,6.037291526794434,5.643877983093262,9.965691566467285,10.710164070129395,9.051444053649902,10.146769523620605,7.915126323699951,10.603866577148438,10.649893760681152,8.032660484313965,4.091607570648193,9.788108825683594,8.782576560974121,6.542656421661377,9.672595024108887,9.439826011657715,8.068989753723145,10.794023513793945,10.057008743286133,8.683547973632812,4.798459529876709,8.239609718322754,7.043629169464111,4.90942907333374,6.6996846199035645,8.31154727935791,7.714805603027344,3.155330181121826,8.570414543151855,3.770610809326172,10.132532119750977,5.896604061126709,5.464407444000244,6.6313886642456055,8.75312328338623,5.87841272354126,2.5088000297546387,6.433380603790283,6.808150291442871,6.308969974517822,6.100968360900879,6.053338527679443,9.119235038757324,6.516052722930908,8.076611518859863,4.923530101776123,4.932368278503418,6.424412727355957,5.161946773529053,5.631498336791992,8.570242881774902,3.7515358924865723,6.013418197631836,1.8744134902954102,4.180589199066162,1.0606435537338257,0.5657971501350403,4.2123589515686035,1.3241301774978638,4.36327600479126,2.3847362995147705,4.2462263107299805,0.7746409177780151,2.8566935062408447,5.3249711990356445,1.6826097965240479,2.11360502243042,0.8911349177360535,4.030747890472412,1.3731106519699097,3.161267042160034,0.860297679901123,1.7571049928665161,4.721892356872559,1.654163122177124,4.5388665199279785,0.9811684489250183,2.0350377559661865,0.28213387727737427,-20.292659759521484,0.6223909854888916,0.6856060028076172,1.6420974731445312,1.4472596645355225,-19.7694034576416,-20.48760414123535,1.4959626197814941,2.204069137573242,-35.581241607666016,2.7640607357025146,-19.769454956054688,-29.00425910949707,-20.496824264526367,-23.620208740234375,0.4196929335594177,1.2409210205078125,-19.80928611755371,-23.71021842956543,-25.6669979095459,-25.488731384277344,-27.783592224121094,-24.51732635498047,1.0026566982269287,-27.76382064819336,-22.127397537231445,-25.98760223388672,-28.600297927856445,-22.88784408569336,-26.09601593017578,1.5748506784439087,-22.254291534423828,-29.57825469970703,-30.263538360595703,-24.316965103149414,-28.57391357421875,-29.511615753173828,-20.94269371032715,-19.65596580505371,-35.720733642578125,-24.67058753967285,-21.64602279663086,-24.944589614868164,-22.24126434326172,-23.674806594848633,-38.36140441894531,-22.577085494995117,-26.589628219604492,-24.817087173461914,-36.42941665649414,-21.935630798339844,-21.081233978271484,-25.928417205810547,-21.17901039123535,-33.308048248291016,-32.15425491333008,-25.862571716308594,-20.152042388916016,-28.216299057006836,-36.309730529785156,-33.54946517944336,-22.932153701782227,-26.444326400756836,-27.86650276184082,-21.39191246032715,-23.05916976928711,-37.350791931152344,-30.565555572509766,-25.036455154418945,-24.827823638916016,-25.330028533935547,0.8550342321395874,-39.13967514038086,-41.22145080566406,-22.410686492919922,-29.41424560546875,-36.9384880065918,-27.16061019897461,-23.2427921295166,-43.76711654663086,-26.759397506713867,-36.24002456665039,-45.56025695800781,-31.918119430541992,-26.062664031982422,-33.58485412597656,-35.04889678955078,-29.782390594482422,-34.57994842529297,-38.257381439208984,-29.438495635986328,-26.350635528564453,-34.03168487548828,-31.415658950805664,-45.108177185058594,-34.126792907714844,-28.007966995239258,-34.104942321777344,-21.99277114868164,-22.66432762145996,-37.69607925415039,-39.490604400634766,-44.209197998046875,-35.057193756103516,-43.30933380126953,-43.891143798828125,-27.012361526489258,-41.347137451171875,-28.226062774658203,-35.118343353271484,-33.04158020019531,-44.88394546508789,-45.388328552246094,-45.65620422363281,-33.87221145629883,-42.980140686035156,-34.626224517822266,-41.416282653808594,-42.50090026855469,-41.55413818359375,-31.94048309326172,-31.1610107421875,-35.228050231933594,-43.25535583496094,-44.14769744873047,-35.597938537597656,-35.76996994018555,-31.5473575592041,-41.25700759887695,-43.72921371459961,-42.01362991333008,-44.92661666870117,-39.618247985839844,-35.34844207763672,-42.10128402709961,-44.858821868896484,-44.78894805908203,-41.08826446533203,-34.7861328125,-44.55583190917969,-42.962059020996094,-45.08890151977539,-42.5880241394043,-36.07066345214844,-40.706199645996094,-44.30899429321289,-45.36344528198242,-44.56768798828125,-45.090091705322266,-45.729652404785156,-45.15904998779297,-43.93210983276367,-40.235382080078125,-41.59992218017578,-42.454994201660156,-43.42512893676758,-34.35785675048828,-45.131465911865234,-42.561485290527344,-23.593074798583984,-38.065494537353516,-41.6924934387207,-44.582977294921875,-45.05137634277344,-44.489540100097656,-36.476715087890625,-44.836761474609375,-45.21126937866211,-44.498104095458984,-40.64068603515625,-43.70674514770508,-36.33621597290039,-42.814910888671875,-37.909820556640625,-26.87919044494629,-39.364967346191406,-38.59648895263672,-37.28032302856445,-45.48713302612305,-43.65696716308594,-40.95903015136719,-45.18778610229492,-44.5312385559082,-37.06500244140625,-24.352338790893555,-44.899662017822266,-44.91270446777344,-42.17486572265625,-44.1375617980957,-38.58884048461914,-44.728824615478516,-44.627777099609375,-44.60326385498047,-38.977294921875,-45.09194564819336,-43.51591873168945,-40.194557189941406,-42.919700622558594,-44.81172180175781,-43.03363037109375,-42.1981315612793,-29.434532165527344,-44.986576080322266,-45.604095458984375,-29.009897232055664,-12.32712459564209,-43.56262969970703,-44.328250885009766,-40.44757843017578,-9.538915634155273,-30.62936782836914,-44.43600082397461,-44.9848518371582,-38.212337493896484,-45.57974624633789,-43.337890625,-38.32857894897461,-40.854312896728516,-42.82062530517578,-42.973758697509766,-39.00816345214844,-44.521385192871094,-24.85559844970703,-45.322330474853516,-26.173572540283203,-43.60765838623047,-44.72538757324219,-43.14202880859375,-43.12983322143555,-33.62580871582031,-17.049467086791992,-44.19570541381836,-34.92049789428711,-37.53976058959961,-34.223628997802734,-33.11007308959961,-44.434844970703125,-24.86492347717285,-43.16251754760742,-32.885162353515625,-37.485870361328125,-33.13738250732422,-22.973257064819336,-14.2575044631958,-27.478784561157227,-44.75590133666992,-38.97038269042969,-29.81182289123535,-44.7381706237793,-42.311981201171875,-35.689029693603516,-44.13360595703125,-34.1682014465332,-14.957115173339844,-7.981330394744873,-28.89406967163086,-40.61979293823242,-35.90375900268555,-45.035789489746094,-4.83840274810791,-36.14848327636719,-43.19550704956055,-25.845937728881836,-29.61894989013672,-35.752384185791016,-21.834117889404297,-42.24490737915039,-17.67000389099121,-27.12844467163086,-35.71380615234375,-24.46285629272461,-11.472228050231934,-27.91571807861328,-45.01800537109375,-35.70618438720703,-43.87342071533203,-21.78550148010254,-34.73483657836914,-44.18169021606445,-45.167327880859375,-9.703246116638184,-28.328828811645508,-32.23463439941406,-37.5943489074707,-39.36065673828125,-26.272247314453125,-34.52400588989258,-21.96731948852539,-31.935686111450195,-23.730968475341797,-43.75898742675781,-30.758100509643555,-18.784360885620117,-43.862667083740234,-45.18029022216797,-35.02239990234375,-18.278621673583984,-43.90817642211914,-19.674129486083984,-7.9658989906311035,-13.753936767578125,-25.735424041748047,-23.177223205566406,-37.332698822021484,-44.260658264160156,-8.827471733093262,-44.08601760864258,-23.648601531982422,-30.024267196655273,-44.980255126953125,-2.7660422325134277,-39.895408630371094,-44.07052230834961,-11.715381622314453,-16.788818359375,-13.590599060058594,8.280402183532715,-31.937644958496094,-39.0949592590332,-30.163381576538086,-43.855709075927734,-19.339601516723633,-36.537715911865234,-5.206798553466797,-15.827568054199219,-14.724151611328125,-26.512306213378906,-43.74229431152344,-2.487067461013794,-31.720596313476562,19.539657592773438,-20.352460861206055,-35.653446197509766,-10.536920547485352,-10.79731559753418,-16.40302276611328,-38.883697509765625,-16.87676429748535,-37.46246337890625,-37.76881790161133,-23.28018569946289,-10.732453346252441,-5.9878249168396,-15.968596458435059,-15.889875411987305,-36.4415283203125,-21.947813034057617,-30.057886123657227,-33.55486297607422,-45.05427932739258,-25.301605224609375,-39.71748733520508,17.68488121032715,-30.68324851989746,-18.095417022705078,-45.16050338745117,-45.907554626464844,-13.069955825805664,-11.664366722106934,-32.66934585571289,-26.361970901489258,-13.776851654052734,15.735224723815918,-14.497995376586914,4.856130599975586,-17.80486488342285,-37.30863952636719,-7.915453910827637,-9.236189842224121,-30.597618103027344,-21.432720184326172,-21.804349899291992,-1.513877511024475,-43.24066925048828,-15.40013313293457,-7.581984996795654,-19.528356552124023,-18.759918212890625,-3.725360631942749,2.43713641166687,-16.207914352416992,-22.6186466217041,-31.44147491455078,-37.86753845214844,-33.152591705322266,-33.6156120300293,-28.36846160888672,-16.235076904296875,0.46757301688194275,-39.45839309692383,-17.1835994720459,-7.317741394042969,-27.366880416870117,-7.72216796875,-36.05339813232422,-37.00178909301758,-27.87815284729004,-11.667247772216797,-10.172476768493652,-3.490463972091675,-18.278995513916016,5.626254081726074,-6.168140888214111,-10.022398948669434,2.668581008911133,-7.361636638641357,-31.686132431030273,-18.503089904785156,-12.556568145751953,-18.7513370513916,-11.309160232543945,-25.930225372314453,-10.380800247192383,-25.454391479492188,-20.015399932861328,-3.493474006652832,25.39496421813965,-11.002331733703613,-23.481212615966797,-16.55561065673828,-14.175738334655762,12.659717559814453,35.63993835449219,-13.9353609085083,-9.679869651794434,-4.591545104980469,-7.1929240226745605,-22.45168113708496,-7.319697380065918,-14.696593284606934,-19.40477752685547,5.766711235046387,-15.922809600830078,5.394127368927002,-1.121706485748291,-16.42889976501465,-8.128063201904297,-3.8273422718048096,-22.20323944091797,-21.3642578125,-36.75178146362305,-43.636009216308594,-19.70298957824707,-21.1245059967041,-25.73166847229004,-12.034936904907227,-30.852397918701172,10.840404510498047,-5.821752548217773,-17.319217681884766,-11.202323913574219,23.722049713134766,5.114394664764404,-1.4119811058044434,-22.215137481689453,-37.718505859375,13.246133804321289,-36.44519805908203,3.869276285171509,-17.308637619018555,-19.740442276000977,1.8639800548553467,16.183305740356445,21.262310028076172,31.254430770874023,-26.561492919921875,-4.471811771392822,-16.451343536376953,16.618024826049805,-2.8290982246398926,7.977432727813721,-0.007313189096748829,-11.122190475463867,-30.660850524902344,13.499622344970703,-8.857129096984863,16.86300277709961,7.1404128074646,0.3431346118450165,-44.11223602294922,13.636750221252441,-5.96608829498291,-36.654109954833984,32.248348236083984,-15.11059856414795,-6.233989238739014,-33.877437591552734,11.771960258483887,5.414496421813965,-44.209346771240234,-35.34839630126953,34.44925308227539,-42.7163200378418,-4.829387187957764,-6.609363555908203,11.058381080627441,-9.573046684265137,-9.476951599121094,25.885393142700195,6.702848434448242,-16.20806312561035,-1.438814401626587,-3.417283535003662,-9.163920402526855,10.703822135925293,3.5235118865966797,14.907001495361328,30.71670150756836,-1.0022581815719604,7.272885799407959,-5.209935188293457,-11.690879821777344,-8.748006820678711,14.823246955871582,-0.700090229511261,0.10163289308547974,-19.422197341918945,-0.575335681438446,5.119610786437988,-7.254215717315674,-12.413403511047363,-28.89533233642578,-12.40493392944336,-10.80331802368164,24.62933921813965,38.089908599853516,14.307059288024902,1.0302531719207764,-20.583759307861328,-0.04072638973593712,26.84721565246582,-12.264108657836914,-12.331547737121582,-28.129934310913086,10.828572273254395,-11.560235023498535,-14.009937286376953,-3.7261223793029785,-15.493749618530273,14.76358699798584,-31.1004581451416,31.91609764099121,4.6476593017578125,8.064101219177246,32.9221076965332,-6.162394046783447,-15.4171724319458,-10.406198501586914,3.845520257949829,23.215620040893555,-1.6317253112792969,21.942174911499023,16.995769500732422,6.430110931396484,-6.978700637817383,18.180376052856445,39.65559387207031,14.86062240600586,11.994349479675293,-5.95509147644043,-23.909038543701172,-4.056066036224365,-12.891042709350586,-5.149336814880371,-8.146263122558594,-3.769965887069702,12.195056915283203,37.167606353759766,5.568997383117676,25.338497161865234,0.021511590108275414,14.558629035949707,3.8238909244537354,-15.251442909240723,10.1013822555542,-1.2604389190673828,-5.663856029510498,7.8488006591796875,34.81419372558594,5.67287540435791,8.433690071105957,36.199684143066406,1.7383240461349487,26.133926391601562,0.32600700855255127,34.31631851196289,29.10181427001953,36.0260124206543,3.457749128341675,32.759849548339844,9.842429161071777,35.20631408691406,28.889074325561523,12.36617374420166,3.4454197883605957,13.001957893371582,13.591771125793457,17.977397918701172,-0.8716705441474915,33.792938232421875,17.137144088745117,30.031736373901367,26.9371337890625,11.074077606201172,22.59956169128418,21.24396324157715,16.608137130737305,5.065004825592041,-11.600608825683594,7.880521297454834,21.157238006591797,15.912988662719727,-15.426154136657715,38.78827667236328,14.436089515686035,-6.839799880981445,7.426136493682861,24.150320053100586,1.756204605102539,-1.5534087419509888,7.025052547454834,-36.462772369384766,39.874595642089844,16.09578514099121,38.14820861816406,36.25474166870117,6.812577247619629,16.42123794555664,36.29288864135742,4.596611499786377,24.72056770324707,22.496461868286133,19.901918411254883,20.659404754638672,32.83430480957031,36.76348876953125,21.0698184967041,-2.3760595321655273,-9.740467071533203,-4.345455169677734,39.758724212646484,25.334245681762695,19.30828094482422,38.5462760925293,34.02610397338867,-2.3008103370666504,26.18291664123535,-1.059850811958313,3.594578504562378,31.082014083862305,-5.879230499267578,25.305625915527344,24.098297119140625,11.073482513427734,28.879297256469727,-12.734034538269043,35.094783782958984,14.95168399810791,36.780433654785156,25.359323501586914,-3.040628671646118,-0.7777708172798157,17.05976676940918,40.32474899291992,10.05036735534668,4.175654411315918,28.073396682739258,25.355876922607422,34.26531982421875,33.27202606201172,21.41895866394043,36.793601989746094,30.945240020751953,-0.3012513518333435,-7.100926876068115,6.203813076019287,10.73547077178955,7.468992710113525,39.627647399902344,32.58608627319336,-13.735197067260742,37.70819091796875,-7.998314380645752,17.537939071655273,32.194549560546875,40.62356948852539,23.610660552978516,32.87824249267578,35.308353424072266,30.161230087280273,2.0846259593963623,38.03890609741211,4.721196174621582,8.333693504333496,11.244544982910156,29.791385650634766,29.95857048034668,34.53710174560547,34.54243850708008,32.024635314941406,36.58912658691406,37.71343231201172,11.486617088317871,26.573741912841797,-16.152233123779297,6.719520568847656,7.45435094833374,16.033002853393555,12.95871639251709,9.664067268371582,40.97522735595703,36.405067443847656,9.404703140258789,38.96160888671875,35.46160125732422,15.673747062683105,34.08543014526367,20.87383270263672,39.782493591308594,19.60590171813965,13.247385025024414,28.67386245727539,32.30768585205078,39.42241668701172,-8.456403732299805,37.2249755859375,-8.880934715270996,35.687278747558594,38.76692199707031,19.792484283447266,6.70623779296875,27.066469192504883,29.22711944580078,35.399925231933594,31.290586471557617,37.1889762878418,30.181171417236328,15.215272903442383,26.540706634521484,36.31616973876953,39.896690368652344,27.322729110717773,38.586639404296875,18.138282775878906,21.409379959106445,24.6717472076416,35.06675720214844,39.26007843017578,-11.095681190490723,-19.227359771728516,13.98161506652832,25.501506805419922,5.828378677368164,2.974407196044922,33.190677642822266,31.568744659423828,26.480484008789062,18.345539093017578,36.67032241821289,20.29898452758789,39.181182861328125,36.08190155029297,31.270057678222656,26.38123893737793,6.270257949829102,38.78076934814453,35.447731018066406,38.79734802246094,3.051088809967041,36.74934768676758,37.45152282714844,20.5401554107666,19.660608291625977,-15.830499649047852,35.82097625732422,38.79975128173828,1.5747274160385132,27.590120315551758,38.07724380493164,21.05210304260254,37.628658294677734,11.201349258422852,30.62512969970703,18.292476654052734,27.588031768798828,35.36761474609375,34.46810531616211,21.157474517822266,32.82170104980469,27.133499145507812,32.796836853027344,19.54918670654297,13.633402824401855,17.279987335205078,4.021127700805664,29.11309051513672,-9.501053810119629,30.260334014892578,24.4081974029541,35.95424270629883,10.144519805908203,38.253631591796875,38.46715545654297,28.12282371520996,35.01179122924805,34.466209411621094,39.576194763183594,40.594398498535156,23.006044387817383,21.35888671875,11.48178768157959,21.902158737182617,39.70576095581055,38.367610931396484,11.866911888122559,36.56671142578125,35.51045227050781,29.129880905151367,22.810319900512695,-3.6466193199157715,36.53143310546875,13.818459510803223,22.088281631469727,39.3947868347168,16.395307540893555,12.439858436584473,23.748258590698242,37.84893798828125,34.403377532958984,35.26967239379883,39.98708724975586,38.97848892211914,16.337364196777344,36.1514892578125,30.11380386352539,41.28556442260742,20.580238342285156,41.076133728027344,32.055912017822266,38.505043029785156,38.125911712646484,28.520824432373047,7.082658290863037,35.14522933959961,14.420459747314453,29.86136245727539,37.607181549072266,12.078457832336426,37.584659576416016,38.01173782348633,-35.26069641113281,35.15172576904297,30.32480812072754,34.514976501464844,19.140085220336914,32.06404495239258,18.704492568969727,25.082340240478516,37.480979919433594,40.151206970214844,3.4063947200775146,31.452804565429688,14.082701683044434,28.77914810180664,33.54253005981445,35.17567443847656,27.93110466003418,-0.7754507064819336,33.46442794799805,1.0781753063201904,33.70756912231445,15.317376136779785,34.524940490722656,15.74460220336914,38.010990142822266,31.632593154907227,38.30498123168945,28.65715980529785,37.537742614746094,-26.28334617614746,32.46931838989258,7.025089263916016,30.73752212524414,29.807449340820312,40.69365310668945,39.47945022583008,29.086341857910156,30.034393310546875,37.27565383911133,18.14565086364746,38.03232192993164,35.402992248535156,33.99307632446289,25.770235061645508,16.450469970703125,24.961376190185547,26.20049285888672,40.163978576660156,3.153325080871582,28.11561393737793,23.713848114013672,17.46057891845703,-17.533855438232422,21.815811157226562,31.02562713623047,38.942359924316406,21.816186904907227,36.64805221557617,32.3570442199707,1.9346786737442017,30.659536361694336,21.973745346069336,15.449738502502441,-1.0195229053497314,-4.41714334487915,-17.762510299682617,25.620038986206055,18.541353225708008,29.232038497924805,37.2996826171875,37.43655014038086,0.6849755644798279,19.037031173706055,39.75754928588867,27.062828063964844,-0.1230444610118866,2.5601322650909424,35.80084991455078,26.503629684448242,11.81118392944336,12.513497352600098,19.73622703552246,-28.633291244506836,21.325489044189453,34.03525924682617,28.899707794189453,36.972957611083984,16.74858283996582,35.346763610839844,0.4780345857143402,35.34906005859375,38.385597229003906,37.965335845947266,36.759132385253906,-3.1657636165618896,-28.024354934692383,17.370004653930664,-12.971800804138184,26.612468719482422,19.931299209594727,39.871726989746094,-3.8549842834472656,37.65224075317383,26.842670440673828,31.173133850097656,23.719249725341797,13.471193313598633,-11.420659065246582,23.784868240356445,23.440126419067383,20.924549102783203,36.18611145019531,28.32847023010254,40.68014907836914,22.993314743041992,27.06184196472168,-2.795347213745117,-21.205068588256836,2.3937366008758545,27.02332878112793,37.75873947143555,23.750255584716797,39.52994155883789,39.22090148925781,17.478601455688477,20.590444564819336,22.233137130737305,36.67277908325195,36.11781311035156,18.56654930114746,36.598716735839844,36.75761795043945,33.26596450805664,37.28740310668945,24.862709045410156,21.040098190307617,4.510501384735107,32.208946228027344,31.08879280090332,22.05014991760254,31.512969970703125,15.661442756652832,33.60547637939453,20.290475845336914,37.592159271240234,-2.6801114082336426,37.605777740478516,33.130950927734375,-0.2974390387535095,29.151817321777344,4.749741077423096,9.117013931274414,37.045719146728516,-32.049774169921875,38.58707046508789,38.72396469116211,-2.389179229736328,36.514495849609375,36.31447219848633,24.770082473754883,-1.6624925136566162,7.49665641784668,5.275834083557129,38.13599395751953,-31.12165641784668,25.718191146850586,-18.68567657470703,-19.00948715209961,-29.128032684326172,38.1668815612793,37.57676696777344,25.549692153930664,16.257925033569336,36.9313850402832,40.106380462646484,38.127559661865234,25.311307907104492,28.791902542114258,22.5577392578125,22.885202407836914,36.344947814941406,13.090265274047852,2.349648952484131,-20.853073120117188,31.65523338317871,-17.660547256469727,34.273075103759766,36.22855758666992,-16.75992202758789,-16.0380916595459,9.671323776245117,31.87474250793457,15.93043327331543,31.446067810058594,13.786750793457031,32.414005279541016,8.016850471496582,28.48965072631836,14.326072692871094,29.94809913635254,34.17873764038086,-5.6393609046936035,12.638081550598145,-30.906463623046875,40.551570892333984,35.512142181396484,-19.02393341064453,37.33727264404297,9.027329444885254,36.67631149291992,10.222245216369629,35.746463775634766,40.123592376708984,38.63982009887695,22.381006240844727,18.967350006103516,16.59732437133789,-11.453335762023926,34.267520904541016,35.59675598144531,22.8143367767334,33.33190155029297,30.115785598754883,33.699649810791016,26.13218879699707,26.94492530822754,16.260698318481445,33.65437316894531,-9.359427452087402,38.859031677246094,36.285152435302734,-15.875988006591797,37.64986038208008,36.90653991699219,5.4445881843566895,12.562504768371582,4.72002649307251,38.23735046386719,31.370481491088867,5.519895076751709,38.66896438598633,-21.248069763183594,-11.796917915344238,25.97248077392578,36.867652893066406,21.05699348449707,37.037044525146484,28.511943817138672,25.279481887817383,22.705364227294922,-9.692148208618164,14.464461326599121,36.1835823059082,17.29401397705078,38.176414489746094,35.93490982055664,13.955068588256836,31.04034423828125,-14.109501838684082,34.232662200927734,29.269655227661133,24.302783966064453,-8.05965518951416,17.732175827026367,19.850263595581055,-6.137049674987793,34.081298828125,36.91191482543945,-30.121618270874023,22.60733985900879,17.885799407958984,11.40019702911377,-27.342754364013672,6.032310485839844,37.42820739746094,40.2411994934082,28.1492919921875,15.464639663696289,-4.54620885848999,17.34446144104004,-4.048579216003418,33.53943634033203,5.139894008636475,40.895957946777344,18.87037467956543,24.68947410583496,37.45601272583008,20.77004623413086,28.634140014648438,18.615068435668945,18.45840072631836,38.276222229003906,33.143898010253906,7.158633708953857,-23.464340209960938,-28.245079040527344,-29.080896377563477,23.852903366088867,8.560145378112793,24.056325912475586,28.841157913208008,33.718624114990234,25.175399780273438,-30.257925033569336,-8.186507225036621,30.849027633666992,-12.394735336303711,33.38603973388672,-5.095117092132568,-21.34309959411621,-9.806323051452637,38.78195571899414,40.56167984008789,18.86642074584961,-23.000246047973633,32.88167190551758,39.808441162109375,26.877614974975586,-11.351815223693848,-37.07803726196289,16.479528427124023,22.958887100219727,18.919279098510742,13.109928131103516,11.293880462646484,-30.563491821289062,-1.4569144248962402,-38.59992599487305,-14.829639434814453,14.407383918762207,0.6090161800384521,-15.648819923400879,28.291091918945312,12.939355850219727,17.50979995727539,-9.99621868133545,17.7994384765625,-26.495952606201172,15.322710990905762,-4.252577781677246,-7.009757995605469,-1.3428256511688232,18.936662673950195,37.09095001220703,7.616784572601318,27.190670013427734,21.297359466552734,-24.706823348999023,8.754612922668457,-10.107491493225098,0.1355740875005722,32.4105339050293,23.233074188232422,22.24749183654785,39.01996994018555,-2.4142210483551025,31.424394607543945,-17.83191680908203,19.6123046875,26.50009536743164,-5.811788082122803,41.36116409301758,-7.344816207885742,-33.3818473815918,-9.882530212402344,22.064760208129883,17.518253326416016,-14.973118782043457,38.812965393066406,0.9725958108901978,21.307363510131836,-10.294975280761719,24.5318660736084,13.817744255065918,4.390139579772949,-4.852285861968994,32.03532791137695,30.82967185974121,38.08331298828125,27.277376174926758,36.820030212402344,33.483280181884766,18.580625534057617,31.007383346557617,31.763944625854492,16.731277465820312,-8.052446365356445,-18.68680763244629,-5.964759826660156,-13.523469924926758,5.871826171875,-35.55958557128906,19.131851196289062,-21.10324478149414,19.768033981323242,-16.35703468322754,-0.7872694134712219,19.758020401000977,9.237922668457031,-12.422285079956055,8.525077819824219,-9.347692489624023,-31.089292526245117,26.540447235107422,37.847347259521484,-26.674381256103516,11.883484840393066,-12.283231735229492,1.3694359064102173,-27.900596618652344,-1.6438190937042236,-10.85562801361084,-18.597930908203125,11.761673927307129,13.99710464477539,6.807441234588623,26.21904945373535,29.30398178100586,27.64461898803711,-5.754844665527344,3.102236032485962,27.866044998168945,29.611892700195312,12.382709503173828,16.750926971435547,-14.541207313537598,12.297919273376465,27.141246795654297,-19.196537017822266,19.298025131225586,-29.652830123901367,-30.375070571899414,0.5797160863876343,-18.455659866333008,-25.88419532775879,18.896528244018555,-19.774860382080078,11.689274787902832,20.950376510620117,28.895124435424805,-37.582916259765625,-2.325268030166626,-9.475703239440918,28.34689712524414,18.804058074951172,-2.9725494384765625,2.3623688220977783,23.31038475036621,16.62982177734375,-39.1666145324707,29.61333465576172,-29.5970401763916,15.47853946685791,41.54197692871094,-28.85401725769043,-32.56297302246094,1.5727901458740234,-5.215909004211426,8.806000709533691,0.9882593750953674,30.6879825592041,-34.265499114990234,19.192502975463867,7.434864044189453,25.899717330932617,12.974477767944336,39.08135986328125,23.847270965576172,12.580924987792969,25.375703811645508,5.895778179168701,11.265738487243652,-28.935016632080078,29.402502059936523,-17.302885055541992,37.42595291137695,36.4899787902832,30.135026931762695,38.519859313964844,28.259475708007812,9.270517349243164,13.493708610534668,5.326316833496094,23.2672176361084,-30.42226791381836,-11.597559928894043,-36.5155143737793,27.169374465942383,-17.12310218811035,5.442599296569824,-2.094452142715454,15.328033447265625,29.231943130493164,-7.9527177810668945,17.04901123046875,-6.969643592834473,34.11278533935547,13.016904830932617,15.598464965820312,11.784987449645996,24.0971736907959,11.528903007507324,36.95800018310547,19.863754272460938,32.8658332824707,-22.333202362060547,27.09495735168457,-36.519378662109375,-16.318267822265625,-28.226581573486328,-14.711333274841309,27.114234924316406,30.613731384277344,10.385458946228027,-1.765026569366455,-21.685344696044922,-5.876542091369629,8.144413948059082,-9.319902420043945,-28.91559410095215,-25.200910568237305,31.678529739379883,-15.649337768554688,-23.518056869506836,0.16664864122867584,-9.076753616333008,-34.63902282714844,-31.958581924438477,-14.627629280090332,-17.37566375732422,-20.08470916748047,-18.87481117248535,28.367265701293945,-24.12393569946289,-7.012326240539551,26.40464973449707,11.393387794494629,7.417564392089844,8.515277862548828,1.6300289630889893,32.52959442138672,20.458267211914062,6.097873687744141,-25.719974517822266,-8.162468910217285,-3.644162178039551,-2.267453670501709,8.407438278198242,8.13645076751709,11.61544418334961,-21.08411407470703,29.175334930419922,34.41905212402344,-17.075868606567383,-4.733792781829834,-13.787140846252441,-20.306650161743164,1.3993480205535889,10.177042007446289,-29.52004623413086,12.391257286071777,18.45118522644043,3.9144821166992188,2.01019024848938,-14.216063499450684,-3.6795380115509033,-27.55870819091797,-39.00056838989258,29.773855209350586,-37.94013595581055,-19.111783981323242,16.16260528564453,24.862428665161133,-34.57255554199219,-34.387367248535156,-12.63778305053711,-28.331079483032227,21.233320236206055,3.0586001873016357,-30.745759963989258,-12.626910209655762,-4.993643760681152,-7.133332252502441,25.439697265625,-25.10638427734375,-18.426950454711914,-19.393291473388672,25.109804153442383,16.728116989135742,-32.64485549926758,-1.8549915552139282,38.79914855957031,-38.38710403442383,-33.30885314941406,-17.523691177368164,40.71173095703125,-18.686201095581055,6.744800090789795,-14.605537414550781,-8.527661323547363,19.82779312133789,29.829891204833984,-28.659990310668945,-28.348909378051758,18.66071891784668,-37.37731170654297,8.039789199829102,-22.68754768371582,37.51875686645508,-3.0184547901153564,23.35716438293457,-33.34065628051758,-34.7867431640625,2.851367712020874,-22.37939453125,-3.9972708225250244,-20.873838424682617,-35.27960968017578,-20.854780197143555,-25.696334838867188,-20.778114318847656,-15.178598403930664,-35.3309440612793,-27.53555679321289,-5.254482269287109,36.16594314575195,28.218463897705078,0.6744902729988098,18.226539611816406,-26.93736457824707,34.51026153564453,21.51302719116211,-7.174545764923096,28.30133819580078,-10.907759666442871,18.37815284729004,-7.617560386657715,-10.366372108459473,-13.270197868347168,14.259621620178223,-7.213850975036621,-16.10051727294922,27.01633071899414,-1.3412476778030396,16.258914947509766,11.766876220703125,-15.79919719696045,-20.06700897216797,-35.92888259887695,2.3034822940826416,-26.828819274902344,4.6450066566467285,-18.901979446411133,-6.684815406799316,28.250123977661133,-20.842254638671875,4.1287312507629395,13.790451049804688,23.37982940673828,-8.127249717712402,-29.41454315185547,-28.428550720214844,-27.0236759185791,-19.5709285736084,-26.924928665161133,-14.544495582580566,-14.160179138183594,7.462110996246338,-37.11940002441406,-5.527460098266602,-5.222291946411133,-8.857620239257812,-18.775875091552734,32.8205680847168,2.5052542686462402,-29.957521438598633,-28.922788619995117,-33.948455810546875,-18.575790405273438,5.899981498718262,-26.1258544921875,-35.49715805053711,12.389131546020508,-14.671056747436523,-23.882232666015625,-8.545257568359375,8.918155670166016,-31.391660690307617,13.547294616699219,-37.77098846435547,-18.01422691345215,13.448761940002441,25.510608673095703,-7.553495407104492,17.66461944580078,-22.524648666381836,3.923788547515869,-37.223655700683594,-0.47068920731544495,-1.714388132095337,-32.33744430541992,-7.938956260681152,3.93861985206604,-26.033870697021484,-5.059396743774414,-33.261898040771484,0.46202579140663147,22.869792938232422,-19.492279052734375,10.490194320678711,24.260555267333984,22.080047607421875,-10.788400650024414,-17.879295349121094,12.781614303588867,-23.532142639160156,-15.507854461669922,15.245590209960938,22.510887145996094,9.47620677947998,10.034514427185059,-8.947148323059082,8.771842956542969,-29.61618423461914,-2.6314821243286133,-27.84762954711914,14.935758590698242,21.012189865112305,-24.863910675048828,9.153132438659668,20.149221420288086,-17.73878288269043,-14.302970886230469,-16.117536544799805,19.778034210205078,-19.311416625976562,-26.197195053100586,-28.324125289916992,2.978050947189331,38.13840866088867,17.572301864624023,23.96540641784668,-7.422159671783447,-29.70332908630371,-23.802356719970703,-12.883692741394043,-13.105121612548828,-4.582128047943115,-9.389278411865234,35.3265495300293,-23.46307945251465,-1.8725461959838867,17.778005599975586,13.229482650756836,-25.19207763671875,-36.7645378112793,-39.40538787841797,-16.982322692871094,-2.00130033493042,-32.772216796875,-38.656925201416016,22.847326278686523,1.1704025268554688,-13.719173431396484,1.4577715396881104,15.108444213867188,14.929259300231934,-13.910324096679688,-36.38190460205078,-35.050106048583984,-29.67279815673828,-19.744020462036133,-7.034006118774414,-11.2750825881958,-29.20009994506836,-11.361492156982422,-21.276447296142578,-31.607990264892578,1.6774885654449463,31.352275848388672,-20.15176773071289,-36.117061614990234,-34.39592361450195,-9.25309944152832,0.6283493638038635,-34.24634552001953,-36.82942199707031,22.908584594726562,-16.658687591552734,-37.449729919433594,-33.78341293334961,7.447916507720947,13.367210388183594,13.951016426086426,-12.107762336730957,-17.914913177490234,-28.865270614624023,-37.16293716430664,-31.951866149902344,33.03255081176758,-38.04145431518555,-30.459627151489258,-23.135393142700195,-29.300039291381836,-13.10558032989502,33.46169662475586],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3a327a42-81e8-41c2-8541-a6e2c490118d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial we learned how to train word2vec models on your custom data\n",
    "and also how to evaluate it. Hope that you too will find this popular tool\n",
    "useful in your Machine Learning tasks!\n",
    "\n",
    "Links\n",
    "-----\n",
    "\n",
    "- API docs: :py:mod:`gensim.models.word2vec`\n",
    "- `Original C toolkit and word2vec papers by Google <https://code.google.com/archive/p/word2vec/>`_.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
